
# coding: utf-8
Support Vector Classifier

# In[1]:

import pandas as pd
import seaborn as sns
import numpy as np
import download_data as dl
import matplotlib.pyplot as plt
import sklearn.svm as svm
from sklearn import metrics
from conf_matrix import func_confusion_matrix
from sklearn.cross_validation import cross_val_score

get_ipython().magic('matplotlib inline')


# In[2]:

## step 1: load data from csv file. 
data = dl.download_data('crab.csv').values

n = 200
#split data 
S = np.random.permutation(n)
#100 training samples
Xtr = data[S[:100], :6]
Ytr = data[S[:100], 6:]
# 100 testing samples
X_test = data[S[100:], :6]
Y_test = data[S[100:], 6:].ravel()


# In[3]:

## step 2 randomly split Xtr/Ytr into two even subsets: use one for training, another for validation.

n2 = len(Xtr)
S2 = np.random.permutation(n2)

x_train = Xtr[S2[:50], :6]
y_train = Ytr[S2[:50], :6]

x_validation = Xtr[S2[:50], :6]
y_validation = Ytr[S2[:50], :6].ravel()



# In[4]:

## step 3 Model selection over validation set
# consider the parameters C, kernel types (linear, RBF etc.) and kernal
# parameters if applicable. 


# 3.1 Plot the validation errors while using different values of C ( with other hyperparameters fixed) 
#  keeping kernel = "linear"

c_range =  list(range(1,26))
svm_c_error = []
acc_score = []
for c_value in c_range:
    model = svm.SVC(kernel='linear', C=c_value)
    model.fit(X=x_train, y=y_train)
    error = 1. - model.score(x_validation, y_validation)
    svm_c_error.append(error)
    scores = cross_val_score(model, x_validation, y_validation, cv=10, scoring='accuracy')
    acc_score.append(scores.mean())
plt.plot(c_range, svm_c_error)
plt.title('Linear SVM')
plt.xlabel('c values')
plt.ylabel('error')
plt.xticks(c_range)
plt.show()

plt.plot(c_range, acc_score)
plt.title('Linear SVM')
plt.xlabel('c values')
plt.ylabel('accuracy')
plt.xticks(c_range)
plt.show()

y_pred=model.predict(X_test)

conf_matrix, accuracy, recall_array, precision_array = func_confusion_matrix(Y_test, y_pred)
print("Confusion Matrix: ")
print(conf_matrix)
print("Average Accuracy: {}".format(accuracy))
print("Per-Class Precision: {}".format(precision_array))
print("Per-Class Recall: {}".format(recall_array))

In evaluating the results of using the basic linear kernel over a range of C values, the average accuracy was surprisingly good, scoring a 0.92. The validation error score remains high until around the 7th C value, where it drops to near 0. With accuracy, the linear model maintains its highest accuracy in the C value range of 2 to 5. The best accuracy/error parameters seem to lie at the C value of 7 or 8. 
# In[5]:

import matplotlib.pyplot as plt
get_ipython().magic('matplotlib inline')

degree=[2,3,4,5,6]
svm_d_error = []
acc_score2 = []
for d in degree:
    model2 = svm.SVC(kernel='poly', degree=d)
    model2.fit(X=x_train, y=y_train)
    error = 1. - model2.score(x_validation, y_validation)
    svm_d_error.append(error)
    scores = cross_val_score(model2, x_validation, y_validation, cv=10, scoring='accuracy')
    acc_score2.append(scores.mean())
plt.plot(degree, svm_d_error)
plt.title('Polynomial SVM')
plt.xlabel('degree')
plt.ylabel('error')
plt.xticks(degree)
plt.show()

plt.plot(degree, acc_score2)
plt.title('Polynomial SVM')
plt.xlabel('degree')
plt.ylabel('accuracy')
plt.xticks(degree)
plt.show()

y_pred=model2.predict(X_test)

conf_matrix, accuracy, recall_array, precision_array = func_confusion_matrix(Y_test, y_pred)
print("Confusion Matrix: ")
print(conf_matrix)
print("Average Accuracy: {}".format(accuracy))
print("Per-Class Precision: {}".format(precision_array))
print("Per-Class Recall: {}".format(recall_array))

For the polynomial SVM model, I evaluated the range of degrees from 2 to 6. The average error remained consistent at 0, while the accuracy score appeared to exponentially ascend and normalize at a degree of 4. The polynomial model (using fixed hyperparameters) performed nearly equivalent to the basic linear model results. 
# In[6]:

gamma_range=[0.01,0.02,0.03,0.04,0.05]
acc_score3=[]
svm_g_error = []
for g in gamma_range:
    model3 = svm.SVC(kernel='rbf', gamma=g)
    model3.fit(X=x_train, y=y_train)
    error = 1. - model3.score(x_validation, y_validation)
    svm_g_error.append(error)
    scores = cross_val_score(model3, x_validation, y_validation, cv=10, scoring='accuracy')
    acc_score3.append(scores.mean())
    
plt.plot(degree, svm_g_error)
plt.title('RBF SVM')
plt.xlabel('gamma')
plt.ylabel('error')
plt.xticks(degree)
plt.show()

plt.plot(degree, acc_score3)
plt.title('RBF SVM')
plt.xlabel('gamma')
plt.ylabel('accuracy')
plt.xticks(degree)
plt.show()

y_pred=model3.predict(X_test)

conf_matrix, accuracy, recall_array, precision_array = func_confusion_matrix(Y_test, y_pred)
print("Confusion Matrix: ")
print(conf_matrix)
print("Average Accuracy: {}".format(accuracy))
print("Per-Class Precision: {}".format(precision_array))
print("Per-Class Recall: {}".format(recall_array))

In evaluating the RBF SVM model, I iterated through the gamma range of .01 to .05. This model scored the lowest in accuracy with a 0.82, appearing to optimize its paramters around a gamma value of .04. 
# In[7]:

## step 4 Select the best model and apply it over the testing subset 
best_kernel_poly = 'poly'
best_d = 2 
best_model_poly = svm.SVC(kernel=best_kernel_poly, degree=best_d)
best_model_poly.fit(X=x_train, y=y_train)


# In[8]:

## step 5 evaluate your results with the metrics you have developed in HA3,including accuracy, quantize your results. 
y_pred=best_model_poly.predict(X_test)

conf_matrix, accuracy, recall_array, precision_array = func_confusion_matrix(Y_test, y_pred)
print("Confusion Matrix: ")
print(conf_matrix)
print("Average Accuracy: {}".format(accuracy))
print("Per-Class Precision: {}".format(precision_array))
print("Per-Class Recall: {}".format(recall_array))


# In[9]:

## step 4 Select the best model and apply it over the testing subset 

best_kernel_linear = 'linear'
best_c = 5 
best_model_linear = svm.SVC(kernel=best_kernel_linear, C=best_c)
best_model_linear.fit(X=x_train, y=y_train)


# In[10]:

## step 5 evaluate your results with the metrics you have developed in HA3,including accuracy, quantize your results. 

y_pred=best_model_linear.predict(X_test)

conf_matrix, accuracy, recall_array, precision_array = func_confusion_matrix(Y_test, y_pred)
print("Confusion Matrix: ")
print(conf_matrix)
print("Average Accuracy: {}".format(accuracy))
print("Per-Class Precision: {}".format(precision_array))
print("Per-Class Recall: {}".format(recall_array))

In determining the best model, I compared the two highest performing base models, polynomial and linear, and then tweaked hyperparamters for optimization. My results show that the simple linear model (using a C value of 5) achieved a 0.96 accuracy score, significantly beating the average accuracy scores of 0.92 for the optimized polynomial model. 
# In[17]:

## step 6 Show 5 correct and 5 incorrect predictions by the best model

df = pd.DataFrame(X_test)
df["actual"] = Y_test
df["predicted"] = y_pred

correct = df[df["actual"] == df["predicted"]]
incorrect = df[df["actual"] != df["predicted"]]


# In[20]:

# 5 correct prediction samples
correct.head(n=5)


# In[21]:

# 5 incorrect prediction samples
incorrect.head(n=5)


# In[ ]:



