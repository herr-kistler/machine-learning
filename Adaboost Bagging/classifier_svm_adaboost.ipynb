{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import download_data as dl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.svm as svm\n",
    "from sklearn import metrics\n",
    "from conf_matrix import func_confusion_matrix\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## step 1: load data from csv file. \n",
    "data = dl.download_data('crab.csv').values\n",
    "\n",
    "n = 200\n",
    "#split data \n",
    "S = np.random.permutation(n)\n",
    "#100 training samples\n",
    "Xtr = data[S[:100], :6]\n",
    "Ytr = data[S[:100], 6:]\n",
    "# 100 testing samples\n",
    "X_test = data[S[100:], :6]\n",
    "Y_test = data[S[100:], 6:].ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## step 2 randomly split Xtr/Ytr into two even subsets: use one for training, another for validation.\n",
    "\n",
    "n2 = len(Xtr)\n",
    "S2 = np.random.permutation(n2)\n",
    "\n",
    "x_train = Xtr[S2[:50], :6]\n",
    "y_train = Ytr[S2[:50], :6]\n",
    "\n",
    "x_validation = Xtr[S2[:50], :6]\n",
    "y_validation = Ytr[S2[:50], :6].ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAETCAYAAADH1SqlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJElFhoUkqej/AYsgdstLuD9qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fedcba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAETCAYAAADZHBoWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ff31550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[43  5]\n",
      " [ 3 49]]\n",
      "Average Accuracy: 0.92\n",
      "Per-Class Precision: [ 0.93478261  0.90740741]\n",
      "Per-Class Recall: [ 0.89583333  0.94230769]\n"
     ]
    }
   ],
   "source": [
    "## step 3 Model selection over validation set\n",
    "# consider the parameters C, kernel types (linear, RBF etc.) and kernal\n",
    "# parameters if applicable. \n",
    "\n",
    "\n",
    "# 3.1 Plot the validation errors while using different values of C ( with other hyperparameters fixed) \n",
    "#  keeping kernel = \"linear\"\n",
    "\n",
    "c_range =  list(range(1,26))\n",
    "svm_c_error = []\n",
    "acc_score = []\n",
    "for c_value in c_range:\n",
    "    model = svm.SVC(kernel='linear', C=c_value)\n",
    "    model.fit(X=x_train, y=y_train)\n",
    "    error = 1. - model.score(x_validation, y_validation)\n",
    "    svm_c_error.append(error)\n",
    "    scores = cross_val_score(model, x_validation, y_validation, cv=10, scoring='accuracy')\n",
    "    acc_score.append(scores.mean())\n",
    "plt.plot(c_range, svm_c_error)\n",
    "plt.title('Linear SVM')\n",
    "plt.xlabel('c values')\n",
    "plt.ylabel('error')\n",
    "plt.xticks(c_range)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(c_range, acc_score)\n",
    "plt.title('Linear SVM')\n",
    "plt.xlabel('c values')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xticks(c_range)\n",
    "plt.show()\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "conf_matrix, accuracy, recall_array, precision_array = func_confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(conf_matrix)\n",
    "print(\"Average Accuracy: {}\".format(accuracy))\n",
    "print(\"Per-Class Precision: {}\".format(precision_array))\n",
    "print(\"Per-Class Recall: {}\".format(recall_array))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In evaluating the results of using the basic linear kernel over a range of C values, the average accuracy was surprisingly good, scoring a 0.92. The validation error score remains high until around the 7th C value, where it drops to near 0. With accuracy, the linear model maintains its highest accuracy in the C value range of 2 to 5. The best accuracy/error parameters seem to lie at the C value of 7 or 8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAETCAYAAADH1SqlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZFhIkooMC0lS0f8DGPjSDHO1TlwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ffad0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAETCAYAAAD3WTuEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11016af98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[41  7]\n",
      " [ 6 46]]\n",
      "Average Accuracy: 0.87\n",
      "Per-Class Precision: [ 0.87234043  0.86792453]\n",
      "Per-Class Recall: [ 0.85416667  0.88461538]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "degree=[2,3,4,5,6]\n",
    "svm_d_error = []\n",
    "acc_score2 = []\n",
    "for d in degree:\n",
    "    model2 = svm.SVC(kernel='poly', degree=d)\n",
    "    model2.fit(X=x_train, y=y_train)\n",
    "    error = 1. - model2.score(x_validation, y_validation)\n",
    "    svm_d_error.append(error)\n",
    "    scores = cross_val_score(model2, x_validation, y_validation, cv=10, scoring='accuracy')\n",
    "    acc_score2.append(scores.mean())\n",
    "plt.plot(degree, svm_d_error)\n",
    "plt.title('Polynomial SVM')\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('error')\n",
    "plt.xticks(degree)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(degree, acc_score2)\n",
    "plt.title('Polynomial SVM')\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xticks(degree)\n",
    "plt.show()\n",
    "\n",
    "y_pred=model2.predict(X_test)\n",
    "\n",
    "conf_matrix, accuracy, recall_array, precision_array = func_confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(conf_matrix)\n",
    "print(\"Average Accuracy: {}\".format(accuracy))\n",
    "print(\"Per-Class Precision: {}\".format(precision_array))\n",
    "print(\"Per-Class Recall: {}\".format(recall_array))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For the polynomial SVM model, I evaluated the range of degrees from 2 to 6. The average error remained consistent at 0, while the accuracy score appeared to exponentially ascend and normalize at a degree of 4. The polynomial model (using fixed hyperparameters) performed nearly equivalent to the basic linear model results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAETCAYAAADZHBoWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110054ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAETCAYAAADZHBoWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1100ec5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[39  9]\n",
      " [13 39]]\n",
      "Average Accuracy: 0.78\n",
      "Per-Class Precision: [ 0.75    0.8125]\n",
      "Per-Class Recall: [ 0.8125  0.75  ]\n"
     ]
    }
   ],
   "source": [
    "gamma_range=[0.01,0.02,0.03,0.04,0.05]\n",
    "acc_score3=[]\n",
    "svm_g_error = []\n",
    "for g in gamma_range:\n",
    "    model3 = svm.SVC(kernel='rbf', gamma=g)\n",
    "    model3.fit(X=x_train, y=y_train)\n",
    "    error = 1. - model3.score(x_validation, y_validation)\n",
    "    svm_g_error.append(error)\n",
    "    scores = cross_val_score(model3, x_validation, y_validation, cv=10, scoring='accuracy')\n",
    "    acc_score3.append(scores.mean())\n",
    "    \n",
    "plt.plot(degree, svm_g_error)\n",
    "plt.title('RBF SVM')\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('error')\n",
    "plt.xticks(degree)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(degree, acc_score3)\n",
    "plt.title('RBF SVM')\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xticks(degree)\n",
    "plt.show()\n",
    "\n",
    "y_pred=model3.predict(X_test)\n",
    "\n",
    "conf_matrix, accuracy, recall_array, precision_array = func_confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(conf_matrix)\n",
    "print(\"Average Accuracy: {}\".format(accuracy))\n",
    "print(\"Per-Class Precision: {}\".format(precision_array))\n",
    "print(\"Per-Class Recall: {}\".format(recall_array))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In evaluating the RBF SVM model, I iterated through the gamma range of .01 to .05. This model scored the lowest in accuracy with a 0.82, appearing to optimize its paramters around a gamma value of .04. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## step 4 Select the best model and apply it over the testing subset \n",
    "best_kernel_poly = 'poly'\n",
    "best_d = 2 \n",
    "best_model_poly = svm.SVC(kernel=best_kernel_poly, degree=best_d)\n",
    "best_model_poly.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[43  5]\n",
      " [ 5 47]]\n",
      "Average Accuracy: 0.9\n",
      "Per-Class Precision: [ 0.89583333  0.90384615]\n",
      "Per-Class Recall: [ 0.89583333  0.90384615]\n"
     ]
    }
   ],
   "source": [
    "## step 5 evaluate your results with the metrics you have developed in HA3,including accuracy, quantize your results. \n",
    "y_pred=best_model_poly.predict(X_test)\n",
    "\n",
    "conf_matrix, accuracy, recall_array, precision_array = func_confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(conf_matrix)\n",
    "print(\"Average Accuracy: {}\".format(accuracy))\n",
    "print(\"Per-Class Precision: {}\".format(precision_array))\n",
    "print(\"Per-Class Recall: {}\".format(recall_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## step 4 Select the best model and apply it over the testing subset \n",
    "\n",
    "best_kernel_linear = 'linear'\n",
    "best_c = 5 \n",
    "best_model_linear = svm.SVC(kernel=best_kernel_linear, C=best_c)\n",
    "best_model_linear.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[43  5]\n",
      " [ 3 49]]\n",
      "Average Accuracy: 0.92\n",
      "Per-Class Precision: [ 0.93478261  0.90740741]\n",
      "Per-Class Recall: [ 0.89583333  0.94230769]\n"
     ]
    }
   ],
   "source": [
    "## step 5 evaluate your results with the metrics you have developed in HA3,including accuracy, quantize your results. \n",
    "\n",
    "y_pred=best_model_linear.predict(X_test)\n",
    "\n",
    "conf_matrix, accuracy, recall_array, precision_array = func_confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(conf_matrix)\n",
    "print(\"Average Accuracy: {}\".format(accuracy))\n",
    "print(\"Per-Class Precision: {}\".format(precision_array))\n",
    "print(\"Per-Class Recall: {}\".format(recall_array))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In determining the best model, I compared the two highest performing base models, polynomial and linear, and then tweaked hyperparamters for optimization. My results show that the simple linear model (using a C value of 5) achieved a 0.96 accuracy score, significantly beating the average accuracy scores of 0.92 for the optimized polynomial model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## step 6 Show 5 correct and 5 incorrect predictions by the best model\n",
    "\n",
    "df = pd.DataFrame(X_test)\n",
    "df[\"actual\"] = Y_test\n",
    "df[\"predicted\"] = y_pred\n",
    "\n",
    "correct = df[df[\"actual\"] == df[\"predicted\"]]\n",
    "incorrect = df[df[\"actual\"] != df[\"predicted\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>15.4</td>\n",
       "      <td>45.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>20.6</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>24.2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>8.2</td>\n",
       "      <td>20.2</td>\n",
       "      <td>22.2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>14.4</td>\n",
       "      <td>42.8</td>\n",
       "      <td>46.5</td>\n",
       "      <td>19.6</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>31.9</td>\n",
       "      <td>36.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4     5  actual  predicted\n",
       "0  0.0  21.6  15.4  45.7  49.7  20.6    -1.0       -1.0\n",
       "3  0.0  12.5   9.4  24.2  27.0  11.2    -1.0       -1.0\n",
       "5  0.0  10.2   8.2  20.2  22.2   9.0    -1.0       -1.0\n",
       "6  0.0  20.6  14.4  42.8  46.5  19.6    -1.0       -1.0\n",
       "7  1.0  14.6  11.3  31.9  36.4  13.7    -1.0       -1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 correct prediction samples\n",
    "correct.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>9.9</td>\n",
       "      <td>23.8</td>\n",
       "      <td>27.1</td>\n",
       "      <td>9.8</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>19.2</td>\n",
       "      <td>22.2</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>31.5</td>\n",
       "      <td>11.4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>14.7</td>\n",
       "      <td>17.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>19.6</td>\n",
       "      <td>22.4</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5  actual  predicted\n",
       "1   1.0  11.1   9.9  23.8  27.1   9.8    -1.0        1.0\n",
       "2   1.0   9.1   8.2  19.2  22.2   7.7     1.0       -1.0\n",
       "4   1.0  12.3  11.0  26.8  31.5  11.4    -1.0        1.0\n",
       "36  1.0   7.2   6.5  14.7  17.1   6.1     1.0       -1.0\n",
       "59  1.0   9.5   8.2  19.6  22.4   7.8     1.0       -1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 incorrect prediction samples\n",
    "incorrect.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for building weak classifiers, i.e.:  stump function\n",
    "\n",
    "import numpy as py\n",
    "\n",
    "def buildWeakStump(d,l,D): # (data, label, weight)\n",
    "    dataMatrix = py.mat(d)\n",
    "    labelmatrix = py.mat(l).T\n",
    "    m,n = py.shape(dataMatrix)\n",
    "    numstep = 10.0\n",
    "    bestStump = {}\n",
    "    bestClass = py.mat(py.zeros((5,1)))\n",
    "    minErr = py.inf\n",
    "    for i in range(n):\n",
    "        datamin = dataMatrix[:,i].min()\n",
    "        datamax = dataMatrix[:,i].max()\n",
    "        stepSize = (datamax - datamin) / numstep\n",
    "        for j in range(-1,int(numstep)+1):\n",
    "            for inequal in ['lt','gt']:\n",
    "                threshold = datamin + float(j) * stepSize\n",
    "                predict = stumpClassify(dataMatrix,i,threshold,inequal)\n",
    "                err = py.mat(py.ones((m,1)))\n",
    "                err[predict == labelmatrix] = 0\n",
    "                weighted_err = D.T * err;\n",
    "                if weighted_err < minErr:\n",
    "                    minErr = weighted_err\n",
    "                    bestClass = predict.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['threshold'] = threshold\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump, minErr, bestClass\n",
    "\n",
    "# Use a weak classifier, i.e. a decision stump, to classify data\n",
    "\n",
    "def stumpClassify(datamat,dim,threshold,inequal):\n",
    "    res = py.ones((py.shape(datamat)[0],1))\n",
    "    if inequal == 'lt':\n",
    "        res[datamat[:,dim] <= threshold] = -1.0\n",
    "    else:\n",
    "        res[datamat[:,dim] > threshold] = -1.0\n",
    "    return res\n",
    "\n",
    "# Boosting Algorithm\n",
    "\n",
    "def train(data,label,numIt = 1000):\n",
    "    \n",
    "    weakClassifiers = []\n",
    "    #m is the number of samples\n",
    "    m = py.shape(data)[0]\n",
    "    # sample weights, 1/m at the beginning\n",
    "    D = py.mat(py.ones((m,1))/m) \n",
    "    \n",
    "    estStrong = py.mat(py.zeros((m,1)))\n",
    "    for i in range(numIt):\n",
    "        # bestStump: weak classifier; error: error rate\n",
    "        bestStump, error, classEstimate = buildWeakStump(data,label,D)\n",
    "        print(\"D:\",D.T)\n",
    "        \n",
    "        # calculate the weight of the selected decision stump based on its error rate\n",
    "        alpha = float(0.5*py.log((1.0-error)/max(error,1e-16)))\n",
    "        \n",
    "        # add one more field to bestStump, i.e. classifier weight\n",
    "        bestStump['alpha'] = alpha\n",
    "        # add bestStump to the list of weak classifiers\n",
    "        weakClassifiers.append(bestStump)\n",
    "        print(\"classEstimate: \",classEstimate.T)\n",
    "\n",
    "        #calculate sample weights (of all samples) \n",
    "        # set sample weights\n",
    "        expon = py.multiply(-1*alpha*py.mat(label).T,classEstimate)\n",
    "        D = py.multiply(D,py.exp(expon))\n",
    "        # normalize D\n",
    "        D = D/D.sum()\n",
    "        \n",
    "        \n",
    "        estStrong += classEstimate*alpha\n",
    "        \n",
    "        EnsembleErrors = py.multiply(py.sign(estStrong)!=py.mat(label).T,\\\n",
    "                                  py.ones((m,1)))  #Converte to float\n",
    "        \n",
    "        errorRate = EnsembleErrors.sum()/m\n",
    "        \n",
    "        print(\"current error:  \",errorRate)\n",
    "        if errorRate == 0.0:\n",
    "            break\n",
    "    return weakClassifiers\n",
    "\n",
    "# Applying an adaboost classifier for a single data sample\n",
    "\n",
    "def adaboostClassify(dataTest,classifier):\n",
    "    dataMatrix = py.mat(dataTest)\n",
    "    m = py.shape(dataMatrix)[0]\n",
    "    estStrong = py.mat(py.zeros((m,1)))\n",
    "    for i in range(len(classifier)):\n",
    "        # call the function stumpClassify()\n",
    "        classEstimate = stumpClassify(dataMatrix, \n",
    "                                      classifier[i]['dim'], \n",
    "                                      classifier[i]['threshold'], \n",
    "                                      classifier[i]['ineq'])\n",
    "        # accumulate all predictions\n",
    "        estStrong += classifier[i]['alpha']*classEstimate\n",
    "    return py.sign(estStrong)\n",
    "\n",
    "# Applying an adaboost classifier for all testing samples\n",
    "def test(dataSet,classifier):\n",
    "    label = []\n",
    "    for i in range(py.shape(dataSet)[0]):\n",
    "        label.append(adaboostClassify(dataSet[i,:],classifier))\n",
    "    return label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: [[ 0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01\n",
      "   0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01\n",
      "   0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01\n",
      "   0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01\n",
      "   0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01\n",
      "   0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01\n",
      "   0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01\n",
      "   0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01\n",
      "   0.01  0.01  0.01  0.01]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.38\n",
      "D: [[ 0.01315789  0.00806452  0.01315789  0.00806452  0.00806452  0.00806452\n",
      "   0.01315789  0.00806452  0.01315789  0.00806452  0.01315789  0.01315789\n",
      "   0.00806452  0.01315789  0.00806452  0.01315789  0.00806452  0.01315789\n",
      "   0.00806452  0.00806452  0.00806452  0.00806452  0.01315789  0.01315789\n",
      "   0.01315789  0.00806452  0.00806452  0.00806452  0.01315789  0.00806452\n",
      "   0.01315789  0.00806452  0.01315789  0.00806452  0.00806452  0.00806452\n",
      "   0.01315789  0.00806452  0.01315789  0.00806452  0.01315789  0.00806452\n",
      "   0.00806452  0.01315789  0.00806452  0.01315789  0.00806452  0.00806452\n",
      "   0.00806452  0.00806452  0.00806452  0.00806452  0.00806452  0.00806452\n",
      "   0.01315789  0.00806452  0.01315789  0.00806452  0.00806452  0.01315789\n",
      "   0.01315789  0.00806452  0.01315789  0.01315789  0.01315789  0.00806452\n",
      "   0.00806452  0.01315789  0.01315789  0.00806452  0.00806452  0.00806452\n",
      "   0.00806452  0.00806452  0.00806452  0.01315789  0.00806452  0.01315789\n",
      "   0.00806452  0.00806452  0.00806452  0.00806452  0.01315789  0.00806452\n",
      "   0.01315789  0.01315789  0.01315789  0.01315789  0.00806452  0.00806452\n",
      "   0.00806452  0.00806452  0.00806452  0.00806452  0.00806452  0.00806452\n",
      "   0.01315789  0.01315789  0.00806452  0.00806452]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1.  1. -1.  1. -1. -1.  1.\n",
      "  -1.  1. -1.  1.  1. -1. -1. -1.  1.  1. -1. -1. -1.  1. -1.  1. -1. -1.\n",
      "   1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1.\n",
      "   1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1. -1.]]\n",
      "current error:   0.42\n",
      "D: [[ 0.01002587  0.0117284   0.01002587  0.0117284   0.0117284   0.0117284\n",
      "   0.01002587  0.0117284   0.01002587  0.00614489  0.01002587  0.01002587\n",
      "   0.00614489  0.01002587  0.0117284   0.01002587  0.0117284   0.01002587\n",
      "   0.00614489  0.00614489  0.0117284   0.0117284   0.0191358   0.01002587\n",
      "   0.01002587  0.0117284   0.00614489  0.00614489  0.01002587  0.0117284\n",
      "   0.01002587  0.00614489  0.01002587  0.00614489  0.0117284   0.0117284\n",
      "   0.01002587  0.0117284   0.01002587  0.00614489  0.01002587  0.0117284\n",
      "   0.0117284   0.01002587  0.00614489  0.01002587  0.0117284   0.0117284\n",
      "   0.0117284   0.00614489  0.0117284   0.0117284   0.0117284   0.0117284\n",
      "   0.01002587  0.0117284   0.01002587  0.0117284   0.00614489  0.01002587\n",
      "   0.01002587  0.00614489  0.01002587  0.01002587  0.01002587  0.0117284\n",
      "   0.00614489  0.01002587  0.01002587  0.0117284   0.00614489  0.0117284\n",
      "   0.0117284   0.00614489  0.00614489  0.01002587  0.00614489  0.01002587\n",
      "   0.0117284   0.0117284   0.0117284   0.00614489  0.01002587  0.0117284\n",
      "   0.01002587  0.01002587  0.01002587  0.01002587  0.0117284   0.0117284\n",
      "   0.0117284   0.0117284   0.0117284   0.00614489  0.0117284   0.00614489\n",
      "   0.01002587  0.01002587  0.0117284   0.0117284 ]]\n",
      "classEstimate:  [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.22\n",
      "D: [[ 0.00765753  0.00895788  0.01451516  0.00895788  0.00895788  0.00895788\n",
      "   0.00765753  0.00895788  0.00765753  0.00889639  0.00765753  0.00765753\n",
      "   0.00889639  0.00765753  0.00895788  0.00765753  0.00895788  0.01451516\n",
      "   0.00469333  0.00889639  0.00895788  0.00895788  0.01461549  0.00765753\n",
      "   0.00765753  0.00895788  0.00889639  0.00889639  0.00765753  0.01698002\n",
      "   0.00765753  0.00889639  0.01451516  0.00889639  0.01698002  0.00895788\n",
      "   0.01451516  0.00895788  0.00765753  0.00889639  0.00765753  0.00895788\n",
      "   0.00895788  0.00765753  0.00889639  0.00765753  0.00895788  0.00895788\n",
      "   0.00895788  0.00889639  0.00895788  0.00895788  0.00895788  0.00895788\n",
      "   0.00765753  0.00895788  0.01451516  0.01698002  0.00889639  0.01451516\n",
      "   0.01451516  0.00889639  0.01451516  0.01451516  0.01451516  0.00895788\n",
      "   0.00889639  0.00765753  0.01451516  0.01698002  0.00889639  0.01698002\n",
      "   0.00895788  0.00889639  0.00889639  0.00765753  0.00889639  0.00765753\n",
      "   0.00895788  0.00895788  0.00895788  0.00889639  0.01451516  0.01698002\n",
      "   0.01451516  0.01451516  0.00765753  0.00765753  0.00895788  0.00895788\n",
      "   0.00895788  0.00895788  0.00895788  0.00889639  0.00895788  0.00889639\n",
      "   0.00765753  0.00765753  0.00895788  0.01698002]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.22\n",
      "D: [[ 0.00631758  0.0113693   0.01197522  0.0113693   0.0113693   0.0113693\n",
      "   0.00631758  0.0113693   0.00971891  0.00733965  0.00971891  0.00631758\n",
      "   0.00733965  0.00631758  0.0113693   0.00631758  0.00739038  0.01197522\n",
      "   0.00595675  0.00733965  0.00739038  0.0113693   0.01854991  0.00971891\n",
      "   0.00971891  0.00739038  0.00733965  0.00733965  0.00631758  0.01400877\n",
      "   0.00631758  0.00733965  0.01197522  0.00733965  0.01400877  0.0113693\n",
      "   0.01197522  0.0113693   0.00971891  0.00733965  0.00971891  0.0113693\n",
      "   0.0113693   0.00971891  0.00733965  0.00971891  0.0113693   0.0113693\n",
      "   0.0113693   0.00733965  0.0113693   0.0113693   0.0113693   0.00739038\n",
      "   0.00971891  0.0113693   0.01197522  0.01400877  0.00733965  0.01197522\n",
      "   0.01197522  0.00733965  0.01197522  0.01197522  0.01197522  0.00739038\n",
      "   0.00733965  0.00971891  0.01197522  0.01400877  0.00733965  0.01400877\n",
      "   0.0113693   0.00733965  0.00733965  0.00971891  0.00733965  0.00631758\n",
      "   0.0113693   0.0113693   0.0113693   0.00733965  0.01197522  0.01400877\n",
      "   0.01197522  0.01197522  0.00971891  0.00971891  0.0113693   0.0113693\n",
      "   0.0113693   0.0113693   0.0113693   0.00733965  0.0113693   0.00733965\n",
      "   0.00971891  0.00971891  0.0113693   0.01400877]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1.  1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1.  1.  1. -1.  1.]]\n",
      "current error:   0.23\n",
      "D: [[ 0.00838584  0.00911997  0.0158957   0.00911997  0.00911997  0.00911997\n",
      "   0.00838584  0.00911997  0.01290071  0.00974253  0.01290071  0.00838584\n",
      "   0.00588756  0.00838584  0.00911997  0.00838584  0.00592825  0.0158957\n",
      "   0.00477825  0.00974253  0.00592825  0.00911997  0.01487995  0.00779609\n",
      "   0.00779609  0.00592825  0.00588756  0.00588756  0.00838584  0.01123724\n",
      "   0.00838584  0.00588756  0.0158957   0.00588756  0.01123724  0.00911997\n",
      "   0.0158957   0.00911997  0.01290071  0.00588756  0.00779609  0.00911997\n",
      "   0.00911997  0.00779609  0.00588756  0.01290071  0.00911997  0.00911997\n",
      "   0.00911997  0.00588756  0.00911997  0.00911997  0.00911997  0.00592825\n",
      "   0.00779609  0.00911997  0.0158957   0.01123724  0.00974253  0.0158957\n",
      "   0.0158957   0.00974253  0.0158957   0.0158957   0.0158957   0.00592825\n",
      "   0.00974253  0.00779609  0.0158957   0.01123724  0.00588756  0.01123724\n",
      "   0.00911997  0.00974253  0.00974253  0.00779609  0.00974253  0.00838584\n",
      "   0.00911997  0.00911997  0.00911997  0.00974253  0.0158957   0.01123724\n",
      "   0.0158957   0.0158957   0.01290071  0.01290071  0.00911997  0.00911997\n",
      "   0.00911997  0.00911997  0.00911997  0.00974253  0.00911997  0.00974253\n",
      "   0.01290071  0.01290071  0.00911997  0.01123724]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1.  1. -1.  1. -1. -1.  1.\n",
      "   1.  1. -1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1.  1.  1. -1.]]\n",
      "current error:   0.19\n",
      "D: [[ 0.00671925  0.01212816  0.0127366   0.01212816  0.01212816  0.01212816\n",
      "   0.00671925  0.01212816  0.01033683  0.0078063   0.01033683  0.00671925\n",
      "   0.00471747  0.00671925  0.01212816  0.00671925  0.00788367  0.0127366\n",
      "   0.00635434  0.0078063   0.00788367  0.01212816  0.01978805  0.01036761\n",
      "   0.0062467   0.00788367  0.00471747  0.00471747  0.00671925  0.00900396\n",
      "   0.00671925  0.00471747  0.0127366   0.00471747  0.00900396  0.01212816\n",
      "   0.0127366   0.01212816  0.01033683  0.00471747  0.0062467   0.01212816\n",
      "   0.01212816  0.0062467   0.00471747  0.01033683  0.01212816  0.01212816\n",
      "   0.01212816  0.00471747  0.01212816  0.01212816  0.01212816  0.00788367\n",
      "   0.0062467   0.01212816  0.0127366   0.00900396  0.0078063   0.0127366\n",
      "   0.0127366   0.0078063   0.0127366   0.0127366   0.0127366   0.00788367\n",
      "   0.0078063   0.0062467   0.0127366   0.00900396  0.00471747  0.0149438\n",
      "   0.01212816  0.0078063   0.0078063   0.01036761  0.0078063   0.00671925\n",
      "   0.01212816  0.01212816  0.01212816  0.0078063   0.0127366   0.0149438\n",
      "   0.0127366   0.0127366   0.01033683  0.01033683  0.01212816  0.01212816\n",
      "   0.01212816  0.01212816  0.01212816  0.0078063   0.01212816  0.0078063\n",
      "   0.01033683  0.01715596  0.01212816  0.0149438 ]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.]]\n",
      "current error:   0.17\n",
      "D: [[ 0.00879044  0.00981546  0.01666262  0.00981546  0.00981546  0.00981546\n",
      "   0.00543796  0.00981546  0.00836571  0.01021257  0.00836571  0.00543796\n",
      "   0.00617161  0.00879044  0.00981546  0.00879044  0.00638034  0.01666262\n",
      "   0.00514264  0.01021257  0.00638034  0.00981546  0.0160147   0.00839062\n",
      "   0.00505553  0.00638034  0.00617161  0.00617161  0.00543796  0.0117794\n",
      "   0.00879044  0.00617161  0.01666262  0.00617161  0.007287    0.00981546\n",
      "   0.01666262  0.00981546  0.00836571  0.00617161  0.00505553  0.00981546\n",
      "   0.00981546  0.00505553  0.00617161  0.00836571  0.00981546  0.00981546\n",
      "   0.00981546  0.00617161  0.00981546  0.00981546  0.00981546  0.00638034\n",
      "   0.00505553  0.00981546  0.01666262  0.0117794   0.01021257  0.01666262\n",
      "   0.01666262  0.01021257  0.01666262  0.01666262  0.01666262  0.00638034\n",
      "   0.01021257  0.00505553  0.01666262  0.0117794   0.00617161  0.01955018\n",
      "   0.00981546  0.01021257  0.01021257  0.00839062  0.01021257  0.00879044\n",
      "   0.00981546  0.00981546  0.00981546  0.01021257  0.01666262  0.01209419\n",
      "   0.01666262  0.01666262  0.00836571  0.00836571  0.00981546  0.00981546\n",
      "   0.00981546  0.00981546  0.00981546  0.01021257  0.00981546  0.01021257\n",
      "   0.00836571  0.01388451  0.00981546  0.01209419]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1. -1. -1.  1.\n",
      "   1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1.  1.]]\n",
      "current error:   0.17\n",
      "D: [[ 0.00743178  0.01201132  0.01408724  0.01201132  0.01201132  0.01201132\n",
      "   0.00459747  0.01201132  0.01023725  0.00863411  0.00707271  0.00459747\n",
      "   0.00521773  0.00743178  0.01201132  0.00743178  0.00780772  0.01408724\n",
      "   0.00629313  0.00863411  0.00780772  0.01201132  0.01959742  0.01026773\n",
      "   0.00618653  0.00780772  0.00521773  0.00521773  0.00459747  0.00995877\n",
      "   0.00743178  0.00521773  0.01408724  0.00521773  0.00616072  0.01201132\n",
      "   0.01408724  0.01201132  0.01023725  0.00521773  0.00618653  0.01201132\n",
      "   0.01201132  0.00618653  0.00521773  0.00707271  0.01201132  0.01201132\n",
      "   0.01201132  0.00521773  0.01201132  0.01201132  0.01201132  0.00780772\n",
      "   0.00618653  0.01201132  0.01408724  0.00995877  0.00863411  0.01408724\n",
      "   0.01408724  0.00863411  0.01408724  0.01408724  0.01408724  0.00780772\n",
      "   0.00863411  0.00618653  0.01408724  0.00995877  0.00521773  0.0165285\n",
      "   0.01201132  0.00863411  0.00863411  0.01026773  0.00863411  0.00743178\n",
      "   0.01201132  0.01201132  0.01201132  0.00863411  0.01408724  0.01479984\n",
      "   0.01408724  0.01408724  0.00707271  0.00707271  0.01201132  0.01201132\n",
      "   0.01201132  0.01201132  0.01201132  0.00863411  0.01201132  0.00863411\n",
      "   0.00707271  0.01173852  0.01201132  0.01022491]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.17\n",
      "D: [[ 0.00960639  0.00979421  0.01820928  0.00979421  0.00979421  0.00979421\n",
      "   0.00594273  0.00979421  0.01323275  0.00704038  0.00914224  0.00594273\n",
      "   0.00425461  0.00960639  0.00979421  0.00960639  0.00636653  0.01820928\n",
      "   0.0051315   0.00704038  0.00636653  0.00979421  0.0253318   0.01327216\n",
      "   0.00799676  0.00636653  0.00425461  0.00425461  0.00594273  0.00812053\n",
      "   0.00960639  0.00425461  0.01820928  0.00425461  0.00502354  0.00979421\n",
      "   0.01820928  0.00979421  0.01323275  0.00425461  0.00799676  0.00979421\n",
      "   0.00979421  0.00799676  0.00425461  0.00914224  0.00979421  0.00979421\n",
      "   0.00979421  0.00425461  0.00979421  0.00979421  0.00979421  0.00636653\n",
      "   0.00799676  0.00979421  0.01820928  0.00812053  0.00704038  0.01820928\n",
      "   0.01820928  0.00704038  0.01820928  0.01820928  0.01820928  0.00636653\n",
      "   0.00704038  0.00799676  0.01820928  0.00812053  0.00425461  0.01347758\n",
      "   0.00979421  0.00704038  0.00704038  0.01327216  0.00704038  0.00960639\n",
      "   0.00979421  0.00979421  0.00979421  0.00704038  0.01820928  0.012068\n",
      "   0.01820928  0.01820928  0.00914224  0.00914224  0.00979421  0.00979421\n",
      "   0.00979421  0.00979421  0.00979421  0.00704038  0.00979421  0.00704038\n",
      "   0.00914224  0.01517331  0.00979421  0.00833754]]\n",
      "classEstimate:  [[-1.  1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1.  1. -1. -1.  1.  1. -1.  1.  1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.15\n",
      "D: [[ 0.00733533  0.01418639  0.0139044   0.00747874  0.00747874  0.01418639\n",
      "   0.0045378   0.00747874  0.01010438  0.01019762  0.00698091  0.0045378\n",
      "   0.00616258  0.00733533  0.00747874  0.00733533  0.00922158  0.0139044\n",
      "   0.00391836  0.01019762  0.00922158  0.00747874  0.01934307  0.01013447\n",
      "   0.00610623  0.00922158  0.00616258  0.00616258  0.0045378   0.01176216\n",
      "   0.00733533  0.00616258  0.0139044   0.00616258  0.00727634  0.01418639\n",
      "   0.0139044   0.00747874  0.01010438  0.00616258  0.00610623  0.00747874\n",
      "   0.00747874  0.00610623  0.00616258  0.00698091  0.00747874  0.01418639\n",
      "   0.01418639  0.00616258  0.00747874  0.00747874  0.01418639  0.00922158\n",
      "   0.00610623  0.00747874  0.0139044   0.01176216  0.01019762  0.0139044\n",
      "   0.0139044   0.01019762  0.0139044   0.0139044   0.02637519  0.00922158\n",
      "   0.01019762  0.00610623  0.0139044   0.01176216  0.00616258  0.01952157\n",
      "   0.00747874  0.01019762  0.01019762  0.01013447  0.01019762  0.00733533\n",
      "   0.00747874  0.01418639  0.01418639  0.01019762  0.0139044   0.01747987\n",
      "   0.0139044   0.02637519  0.00698091  0.00698091  0.00747874  0.00747874\n",
      "   0.01418639  0.00747874  0.01418639  0.01019762  0.00747874  0.01019762\n",
      "   0.00698091  0.01158617  0.00747874  0.01207648]]\n",
      "classEstimate:  [[ 1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.\n",
      "   1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.15\n",
      "D: [[ 0.00920467  0.01179167  0.01744781  0.0062163   0.00938464  0.01179167\n",
      "   0.00569422  0.00938464  0.01267939  0.00847622  0.00875993  0.00569422\n",
      "   0.00512231  0.00920467  0.0062163   0.00920467  0.00766494  0.01744781\n",
      "   0.00491692  0.00847622  0.00766494  0.0062163   0.02427248  0.01271715\n",
      "   0.00766235  0.00766494  0.00512231  0.00512231  0.00569422  0.00977665\n",
      "   0.00920467  0.00512231  0.01744781  0.00512231  0.00604806  0.01179167\n",
      "   0.01744781  0.00938464  0.01267939  0.00512231  0.00766235  0.00938464\n",
      "   0.00938464  0.00766235  0.00512231  0.00875993  0.0062163   0.01179167\n",
      "   0.01179167  0.00512231  0.00938464  0.0062163   0.01179167  0.00766494\n",
      "   0.00766235  0.00938464  0.01155728  0.00977665  0.00847622  0.01744781\n",
      "   0.01744781  0.00847622  0.01155728  0.01155728  0.02192294  0.00766494\n",
      "   0.00847622  0.00766235  0.01744781  0.00977665  0.00512231  0.01622624\n",
      "   0.0062163   0.00847622  0.00847622  0.01271715  0.00847622  0.00920467\n",
      "   0.00938464  0.01179167  0.01179167  0.00847622  0.01744781  0.01452919\n",
      "   0.01744781  0.02192294  0.00875993  0.00875993  0.00938464  0.00938464\n",
      "   0.01179167  0.00938464  0.01179167  0.00847622  0.0062163   0.00847622\n",
      "   0.00875993  0.0145388   0.0062163   0.01003792]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1.  1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1. -1.\n",
      "   1. -1. -1.  1. -1. -1.  1. -1. -1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1.\n",
      "   1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1. -1. -1.  1. -1.]]\n",
      "current error:   0.15\n",
      "D: [[ 0.00755036  0.01510018  0.014312    0.00796047  0.01201778  0.01510018\n",
      "   0.00467082  0.01201778  0.01040058  0.00695283  0.00718555  0.00467082\n",
      "   0.00655953  0.00755036  0.00796047  0.00755036  0.00981557  0.014312\n",
      "   0.00403322  0.00695283  0.00981557  0.00796047  0.0199101   0.01043155\n",
      "   0.00628523  0.00981557  0.0042017   0.00655953  0.00467082  0.01251979\n",
      "   0.00755036  0.0042017   0.014312    0.0042017   0.00774503  0.01510018\n",
      "   0.014312    0.00769798  0.01040058  0.0042017   0.00628523  0.00769798\n",
      "   0.01201778  0.00628523  0.00655953  0.00718555  0.00796047  0.01510018\n",
      "   0.01510018  0.0042017   0.01201778  0.00796047  0.01510018  0.00981557\n",
      "   0.00628523  0.01201778  0.00948014  0.01251979  0.00695283  0.014312\n",
      "   0.014312    0.00695283  0.00948014  0.00948014  0.01798283  0.00981557\n",
      "   0.00695283  0.00628523  0.014312    0.01251979  0.0042017   0.020779\n",
      "   0.00796047  0.00695283  0.00695283  0.01043155  0.00695283  0.00755036\n",
      "   0.01201778  0.01510018  0.01510018  0.00695283  0.014312    0.01860579\n",
      "   0.014312    0.01798283  0.00718555  0.00718555  0.01201778  0.01201778\n",
      "   0.01510018  0.01201778  0.01510018  0.00695283  0.00796047  0.01085448\n",
      "   0.00718555  0.01192581  0.00796047  0.01285436]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.15\n",
      "D: [[ 0.0097845   0.01229321  0.01854691  0.0064807   0.00978379  0.01229321\n",
      "   0.00605292  0.00978379  0.01347811  0.00566036  0.00931175  0.00605292\n",
      "   0.00534018  0.0097845   0.0064807   0.0097845   0.00799095  0.01854691\n",
      "   0.00328349  0.00566036  0.00799095  0.0064807   0.02580148  0.01351824\n",
      "   0.00814503  0.00799095  0.00342064  0.00534018  0.00605292  0.01019249\n",
      "   0.0097845   0.00342064  0.01854691  0.00342064  0.0063053   0.01229321\n",
      "   0.01854691  0.006267    0.01347811  0.00342064  0.00814503  0.006267\n",
      "   0.00978379  0.00814503  0.00534018  0.00931175  0.0064807   0.01229321\n",
      "   0.01229321  0.00342064  0.00978379  0.0064807   0.01229321  0.00799095\n",
      "   0.00814503  0.00978379  0.01228531  0.01019249  0.00566036  0.01854691\n",
      "   0.01854691  0.00566036  0.01228531  0.01228531  0.02330394  0.00799095\n",
      "   0.00566036  0.00814503  0.01854691  0.01019249  0.00342064  0.01691639\n",
      "   0.0064807   0.00566036  0.00566036  0.01351824  0.00566036  0.0097845\n",
      "   0.00978379  0.01229321  0.01229321  0.00566036  0.01854691  0.01514716\n",
      "   0.01854691  0.02330394  0.00931175  0.00931175  0.00978379  0.00978379\n",
      "   0.01229321  0.00978379  0.01229321  0.00566036  0.0064807   0.00883674\n",
      "   0.00931175  0.01545465  0.0064807   0.01046486]]\n",
      "classEstimate:  [[-1.  1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1.  1.  1. -1. -1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1.  1. -1.]]\n",
      "current error:   0.15\n",
      "D: [[ 0.00794342  0.01600208  0.01505707  0.00843593  0.00794285  0.01600208\n",
      "   0.00491398  0.00794285  0.01094203  0.0073681   0.00755962  0.00491398\n",
      "   0.00695131  0.00794342  0.00526127  0.00794342  0.01040183  0.01505707\n",
      "   0.00266566  0.0073681   0.01040183  0.00843593  0.0209466   0.01097461\n",
      "   0.00661243  0.01040183  0.00445266  0.00695131  0.00491398  0.01326757\n",
      "   0.00794342  0.00445266  0.01505707  0.00445266  0.00820762  0.01600208\n",
      "   0.01505707  0.00508778  0.01094203  0.00445266  0.00661243  0.00508778\n",
      "   0.00794285  0.00661243  0.00695131  0.00755962  0.00526127  0.01600208\n",
      "   0.01600208  0.00445266  0.00794285  0.00526127  0.01600208  0.01040183\n",
      "   0.00661243  0.01273557  0.00997367  0.01326757  0.0073681   0.01505707\n",
      "   0.01505707  0.0073681   0.00997367  0.00997367  0.018919    0.01040183\n",
      "   0.00459529  0.00661243  0.01505707  0.01326757  0.00445266  0.02202009\n",
      "   0.00843593  0.0073681   0.0073681   0.01097461  0.0073681   0.00794342\n",
      "   0.00794285  0.01600208  0.01600208  0.0073681   0.01505707  0.01971707\n",
      "   0.01505707  0.018919    0.00755962  0.00755962  0.00794285  0.01273557\n",
      "   0.01600208  0.00794285  0.01600208  0.0073681   0.00526127  0.01150279\n",
      "   0.00755962  0.01254665  0.00843593  0.01362212]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.14\n",
      "D: [[ 0.0097845   0.01346791  0.01854691  0.00709998  0.00668498  0.01346791\n",
      "   0.00605292  0.00668498  0.01347811  0.00620126  0.00931175  0.00605292\n",
      "   0.00585047  0.0097845   0.00442807  0.0097845   0.00875455  0.01854691\n",
      "   0.00224351  0.00620126  0.00875455  0.00709998  0.02580148  0.01351824\n",
      "   0.00814503  0.00875455  0.00374751  0.00585047  0.00605292  0.01116645\n",
      "   0.0097845   0.00374751  0.01854691  0.00374751  0.00690782  0.01346791\n",
      "   0.01854691  0.00428206  0.01347811  0.00374751  0.00814503  0.00428206\n",
      "   0.00668498  0.00814503  0.00585047  0.00931175  0.00442807  0.01346791\n",
      "   0.01346791  0.00374751  0.00668498  0.00442807  0.01346791  0.00875455\n",
      "   0.00814503  0.01071871  0.01228531  0.01116645  0.00620126  0.01854691\n",
      "   0.01854691  0.00620126  0.01228531  0.01228531  0.02330394  0.00875455\n",
      "   0.00386756  0.00814503  0.01854691  0.01116645  0.00374751  0.01853288\n",
      "   0.00709998  0.00620126  0.00620126  0.01351824  0.00620126  0.0097845\n",
      "   0.00668498  0.01346791  0.01346791  0.00620126  0.01854691  0.01659459\n",
      "   0.01854691  0.02330394  0.00931175  0.00931175  0.00668498  0.01071871\n",
      "   0.01346791  0.00668498  0.01346791  0.00620126  0.00442807  0.00968116\n",
      "   0.00931175  0.01545465  0.00709998  0.01146486]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1.  1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1. -1.\n",
      "   1. -1. -1.  1. -1. -1.  1. -1. -1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1.\n",
      "   1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1. -1. -1.  1. -1.]]\n",
      "current error:   0.15\n",
      "D: [[ 0.0082504   0.01654419  0.01563896  0.00872172  0.00821193  0.01654419\n",
      "   0.00510388  0.00821193  0.01136489  0.00522897  0.00785177  0.00510388\n",
      "   0.00718681  0.0082504   0.00543951  0.0082504   0.01075422  0.01563896\n",
      "   0.00189175  0.00522897  0.01075422  0.00872172  0.02175609  0.01139873\n",
      "   0.00686797  0.01075422  0.00315994  0.00718681  0.00510388  0.01371704\n",
      "   0.0082504   0.00315994  0.01563896  0.00315994  0.00848567  0.01654419\n",
      "   0.01563896  0.00361068  0.01136489  0.00315994  0.00686797  0.00361068\n",
      "   0.00821193  0.00686797  0.00718681  0.00785177  0.00543951  0.01654419\n",
      "   0.01654419  0.00315994  0.00821193  0.00543951  0.01654419  0.01075422\n",
      "   0.00686797  0.01316703  0.0103591   0.01371704  0.00522897  0.01563896\n",
      "   0.01563896  0.00522897  0.0103591   0.0103591   0.01965014  0.01075422\n",
      "   0.00326117  0.00686797  0.01563896  0.01371704  0.00315994  0.02276608\n",
      "   0.00872172  0.00522897  0.00522897  0.01139873  0.00522897  0.0082504\n",
      "   0.00821193  0.01654419  0.01654419  0.00522897  0.01563896  0.02038505\n",
      "   0.01563896  0.01965014  0.00785177  0.00785177  0.00821193  0.01316703\n",
      "   0.01654419  0.00821193  0.01654419  0.00522897  0.00543951  0.01189248\n",
      "   0.00785177  0.01303152  0.00872172  0.01408361]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1.  1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1.  1.  1. -1.  1.]]\n",
      "current error:   0.14\n",
      "D: [[ 0.01018753  0.01390096  0.01931087  0.00732827  0.00689993  0.01390096\n",
      "   0.00630224  0.00689993  0.01403328  0.00645669  0.00969531  0.00630224\n",
      "   0.00603859  0.01018753  0.00457045  0.01018753  0.00903604  0.01931087\n",
      "   0.00158951  0.00645669  0.00903604  0.00732827  0.01828016  0.00957758\n",
      "   0.00577069  0.00903604  0.00265509  0.00603859  0.00630224  0.0115255\n",
      "   0.01018753  0.00265509  0.01931087  0.00265509  0.00712994  0.01390096\n",
      "   0.01931087  0.00303381  0.01403328  0.00265509  0.00577069  0.00303381\n",
      "   0.00689993  0.00577069  0.00603859  0.00969531  0.00457045  0.01390096\n",
      "   0.01390096  0.00265509  0.00689993  0.00457045  0.01390096  0.00903604\n",
      "   0.00577069  0.01106336  0.01279135  0.0115255   0.00645669  0.01931087\n",
      "   0.01931087  0.00645669  0.01279135  0.01279135  0.02426384  0.00903604\n",
      "   0.00402687  0.00577069  0.01931087  0.0115255   0.00265509  0.01912879\n",
      "   0.00732827  0.00645669  0.00645669  0.00957758  0.00645669  0.01018753\n",
      "   0.00689993  0.01390096  0.01390096  0.00645669  0.01931087  0.01712817\n",
      "   0.01931087  0.02426384  0.00969531  0.00969531  0.00689993  0.01106336\n",
      "   0.01390096  0.00689993  0.01390096  0.00645669  0.00457045  0.01468475\n",
      "   0.00969531  0.01609123  0.00732827  0.0118335 ]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1.  1. -1.  1. -1. -1.  1.\n",
      "   1.  1. -1.  1.  1. -1. -1. -1.  1.  1. -1.  1. -1.  1. -1.  1. -1. -1.\n",
      "   1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1. -1.]]\n",
      "current error:   0.15\n",
      "D: [[ 0.00855336  0.0171841   0.01621322  0.00905907  0.00852956  0.0171841\n",
      "   0.0052913   0.00852956  0.01178221  0.00542097  0.00814009  0.0052913\n",
      "   0.00506994  0.00855336  0.0056499   0.00855336  0.01117018  0.01621322\n",
      "   0.00196492  0.00542097  0.01117018  0.00905907  0.02259758  0.00804124\n",
      "   0.00484502  0.01117018  0.00222919  0.00506994  0.0052913   0.0096767\n",
      "   0.00855336  0.00222919  0.01621322  0.00222919  0.00881389  0.0171841\n",
      "   0.01621322  0.00375033  0.01178221  0.00222919  0.00484502  0.00375033\n",
      "   0.00852956  0.00484502  0.00506994  0.00814009  0.0056499   0.0171841\n",
      "   0.0171841   0.00222919  0.00852956  0.0056499   0.0171841   0.01117018\n",
      "   0.00484502  0.01367631  0.01073949  0.0096767   0.00542097  0.01621322\n",
      "   0.01621322  0.00542097  0.01073949  0.01073949  0.0203717   0.01117018\n",
      "   0.00338092  0.00484502  0.01621322  0.0142476   0.00222919  0.02364664\n",
      "   0.00905907  0.00542097  0.00542097  0.01183961  0.00542097  0.00855336\n",
      "   0.00852956  0.0171841   0.0171841   0.00542097  0.01621322  0.02117351\n",
      "   0.01621322  0.0203717   0.00814009  0.00814009  0.00852956  0.01367631\n",
      "   0.0171841   0.00852956  0.0171841   0.00542097  0.0056499   0.01232918\n",
      "   0.00814009  0.01351005  0.00905907  0.01462835]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.]]\n",
      "current error:   0.15\n",
      "D: [[ 0.01038081  0.01461181  0.01967724  0.00770301  0.00725277  0.01461181\n",
      "   0.00449924  0.00725277  0.01001853  0.00657919  0.0069216   0.00449924\n",
      "   0.00615315  0.01038081  0.00480417  0.01038081  0.00949811  0.01967724\n",
      "   0.00167079  0.00657919  0.00949811  0.00770301  0.01921495  0.00683755\n",
      "   0.00411977  0.00949811  0.00270546  0.00615315  0.00449924  0.01174417\n",
      "   0.01038081  0.00270546  0.01967724  0.00270546  0.00749454  0.01461181\n",
      "   0.01967724  0.00318894  0.01001853  0.00270546  0.00411977  0.00318894\n",
      "   0.00725277  0.00411977  0.00615315  0.0069216   0.00480417  0.01461181\n",
      "   0.01461181  0.00270546  0.00725277  0.00480417  0.01461181  0.00949811\n",
      "   0.00411977  0.0116291   0.01303403  0.01174417  0.00657919  0.01967724\n",
      "   0.01967724  0.00657919  0.01303403  0.01303403  0.02472419  0.00949811\n",
      "   0.00410327  0.00411977  0.01967724  0.01729165  0.00270546  0.02869883\n",
      "   0.00770301  0.00657919  0.00657919  0.01006734  0.00657919  0.01038081\n",
      "   0.00725277  0.01461181  0.01461181  0.00657919  0.01967724  0.01800404\n",
      "   0.01967724  0.02472419  0.0069216   0.0069216   0.00725277  0.0116291\n",
      "   0.01461181  0.00725277  0.01461181  0.00657919  0.00480417  0.01496335\n",
      "   0.0069216   0.01148773  0.00770301  0.01243863]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.14\n",
      "D: [[ 0.0086662   0.01821583  0.01642712  0.00960297  0.00904167  0.01821583\n",
      "   0.0037561   0.00904167  0.01248961  0.00549249  0.00862882  0.0037561\n",
      "   0.00513683  0.0086662   0.00598912  0.0086662   0.00792929  0.01642712\n",
      "   0.0020829   0.00549249  0.00792929  0.00960297  0.02395434  0.00852404\n",
      "   0.00513591  0.00792929  0.00225859  0.00513683  0.0037561   0.00980436\n",
      "   0.0086662   0.00225859  0.01642712  0.00225859  0.00625665  0.01821583\n",
      "   0.01642712  0.0039755   0.01248961  0.00225859  0.00513591  0.0039755\n",
      "   0.00904167  0.00513591  0.00513683  0.00862882  0.00598912  0.01821583\n",
      "   0.01821583  0.00225859  0.00904167  0.00598912  0.01821583  0.00792929\n",
      "   0.00513591  0.01449743  0.01088118  0.00980436  0.00549249  0.01642712\n",
      "   0.01642712  0.00549249  0.01088118  0.01088118  0.02064045  0.00792929\n",
      "   0.00342552  0.00513591  0.01642712  0.01443556  0.00225859  0.0239586\n",
      "   0.00960297  0.00549249  0.00549249  0.01255046  0.00549249  0.0086662\n",
      "   0.00904167  0.01821583  0.01821583  0.00549249  0.01642712  0.01503029\n",
      "   0.01642712  0.02064045  0.00862882  0.00862882  0.00904167  0.01449743\n",
      "   0.01821583  0.00904167  0.01821583  0.00549249  0.00598912  0.01249183\n",
      "   0.00862882  0.01432119  0.00960297  0.01038412]]\n",
      "classEstimate:  [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.15\n",
      "D: [[ 0.00729176  0.01532685  0.02024269  0.00807997  0.00760769  0.01532685\n",
      "   0.00316039  0.00760769  0.01050879  0.00676825  0.00726031  0.00316039\n",
      "   0.00632997  0.00729176  0.00503926  0.00729176  0.00667173  0.02024269\n",
      "   0.00175255  0.00676825  0.00667173  0.00807997  0.02015524  0.00717215\n",
      "   0.00432137  0.00667173  0.0027832   0.00632997  0.00316039  0.01208165\n",
      "   0.00729176  0.0027832   0.02024269  0.0027832   0.0077099   0.01532685\n",
      "   0.02024269  0.003345    0.01050879  0.0027832   0.00432137  0.003345\n",
      "   0.00760769  0.00432137  0.00632997  0.00726031  0.00503926  0.01532685\n",
      "   0.01532685  0.0027832   0.00760769  0.00503926  0.01532685  0.00667173\n",
      "   0.00432137  0.01219818  0.01340858  0.01208165  0.00676825  0.02024269\n",
      "   0.02024269  0.00676825  0.01340858  0.01340858  0.02543467  0.00667173\n",
      "   0.00422118  0.00432137  0.02024269  0.01778855  0.0027832   0.02952353\n",
      "   0.00807997  0.00676825  0.00676825  0.01055999  0.00676825  0.00729176\n",
      "   0.00760769  0.01532685  0.01532685  0.00676825  0.02024269  0.01852142\n",
      "   0.02024269  0.02543467  0.00726031  0.00726031  0.00760769  0.01219818\n",
      "   0.01532685  0.00760769  0.01532685  0.00676825  0.00503926  0.01539335\n",
      "   0.00726031  0.01204989  0.00807997  0.01279607]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.12\n",
      "D: [[ 0.00622283  0.01850566  0.01727523  0.00975576  0.00918553  0.01850566\n",
      "   0.00381586  0.00918553  0.01268833  0.00577606  0.00876611  0.00381586\n",
      "   0.00540204  0.00880409  0.00608442  0.00880409  0.00569369  0.01727523\n",
      "   0.00211604  0.00577606  0.00569369  0.00975576  0.02433548  0.00865967\n",
      "   0.00521763  0.00569369  0.0023752   0.00540204  0.00381586  0.01031055\n",
      "   0.00622283  0.0023752   0.01727523  0.0023752   0.00657968  0.01850566\n",
      "   0.01727523  0.00403876  0.01268833  0.0023752   0.00521763  0.00403876\n",
      "   0.00918553  0.00521763  0.00540204  0.00876611  0.00608442  0.01850566\n",
      "   0.01308002  0.0023752   0.00918553  0.00608442  0.01850566  0.00569369\n",
      "   0.00521763  0.0147281   0.01144296  0.01031055  0.00577606  0.01727523\n",
      "   0.01727523  0.00577606  0.01144296  0.01144296  0.0217061   0.00569369\n",
      "   0.00360238  0.00521763  0.01727523  0.01518086  0.0023752   0.02519556\n",
      "   0.00975576  0.00577606  0.00577606  0.01275015  0.00577606  0.00622283\n",
      "   0.00918553  0.01850566  0.01308002  0.00577606  0.01727523  0.01580629\n",
      "   0.01727523  0.0217061   0.00876611  0.00876611  0.00918553  0.0147281\n",
      "   0.01850566  0.00918553  0.01850566  0.00577606  0.00608442  0.01313677\n",
      "   0.00876611  0.01454905  0.00975576  0.01092024]]\n",
      "classEstimate:  [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.14\n",
      "D: [[ 0.00542723  0.01613968  0.02024269  0.00850847  0.00801115  0.01613968\n",
      "   0.003328    0.00801115  0.01106611  0.00676825  0.00764535  0.003328\n",
      "   0.00632997  0.00767847  0.00530651  0.00767847  0.00496574  0.02024269\n",
      "   0.0018455   0.00676825  0.00496574  0.00850847  0.02122414  0.00755251\n",
      "   0.00455055  0.00496574  0.0027832   0.00632997  0.003328    0.01208165\n",
      "   0.00542723  0.0027832   0.02024269  0.0027832   0.0077099   0.01613968\n",
      "   0.02024269  0.00352239  0.01106611  0.0027832   0.00455055  0.00352239\n",
      "   0.00801115  0.00455055  0.00632997  0.00764535  0.00530651  0.01613968\n",
      "   0.01140772  0.0027832   0.00801115  0.00530651  0.01613968  0.00496574\n",
      "   0.00455055  0.01284509  0.01340858  0.01208165  0.00676825  0.02024269\n",
      "   0.02024269  0.00676825  0.01340858  0.01340858  0.02543467  0.00496574\n",
      "   0.00422118  0.00455055  0.02024269  0.01778855  0.0027832   0.02952353\n",
      "   0.00850847  0.00676825  0.00676825  0.01112002  0.00676825  0.00542723\n",
      "   0.00801115  0.01613968  0.01140772  0.00676825  0.02024269  0.01852142\n",
      "   0.02024269  0.02543467  0.00764535  0.00764535  0.00801115  0.01284509\n",
      "   0.01613968  0.00801115  0.01613968  0.00676825  0.00530651  0.01539335\n",
      "   0.00764535  0.01268893  0.00850847  0.01279607]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1.\n",
      "   1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.12\n",
      "D: [[ 0.00467314  0.01924522  0.01743006  0.01014564  0.00955262  0.01924522\n",
      "   0.00286559  0.00955262  0.00952852  0.00582783  0.00911644  0.00286559\n",
      "   0.00545045  0.00661158  0.00632757  0.00661158  0.00427578  0.01743006\n",
      "   0.0022006   0.00582783  0.00592123  0.01014564  0.02530801  0.00900574\n",
      "   0.00542615  0.00592123  0.00239649  0.00545045  0.00396836  0.01040296\n",
      "   0.00467314  0.00239649  0.01743006  0.00239649  0.00663865  0.01924522\n",
      "   0.01743006  0.00420016  0.00952852  0.00239649  0.00542615  0.00420016\n",
      "   0.00955262  0.00542615  0.00545045  0.00658306  0.00632757  0.01924522\n",
      "   0.01360275  0.00239649  0.00955262  0.00632757  0.01924522  0.00592123\n",
      "   0.00542615  0.01531669  0.01154552  0.01040296  0.00582783  0.01743006\n",
      "   0.01743006  0.00582783  0.01154552  0.01154552  0.02190064  0.00592123\n",
      "   0.00363467  0.00542615  0.01743006  0.01531691  0.00239649  0.02542137\n",
      "   0.01014564  0.00582783  0.00582783  0.0132597   0.00582783  0.00467314\n",
      "   0.00955262  0.01924522  0.01360275  0.00582783  0.01743006  0.01594795\n",
      "   0.01743006  0.02190064  0.00658306  0.00911644  0.00955262  0.01531669\n",
      "   0.01924522  0.00955262  0.01924522  0.00582783  0.00632757  0.01325451\n",
      "   0.00911644  0.01513049  0.01014564  0.01101811]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1.  1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1.  1.  1. -1.  1.]]\n",
      "current error:   0.13\n",
      "D: [[ 0.0056128   0.01648534  0.02093484  0.0086907   0.00818272  0.01648534\n",
      "   0.00344179  0.00818272  0.01144449  0.00699967  0.01094954  0.00344179\n",
      "   0.00466883  0.00794101  0.00542016  0.00794101  0.00366261  0.02093484\n",
      "   0.00188502  0.00699967  0.0050721   0.0086907   0.0216787   0.00771426\n",
      "   0.00464801  0.0050721   0.00205282  0.00466883  0.0047663   0.00891112\n",
      "   0.0056128   0.00205282  0.02093484  0.00205282  0.00568663  0.01648534\n",
      "   0.02093484  0.00359783  0.01144449  0.00205282  0.00464801  0.00359783\n",
      "   0.00818272  0.00464801  0.00466883  0.00790676  0.00542016  0.01648534\n",
      "   0.01165204  0.00205282  0.00818272  0.00542016  0.01648534  0.0050721\n",
      "   0.00464801  0.01312019  0.01386705  0.00891112  0.00699967  0.02093484\n",
      "   0.02093484  0.00699967  0.01386705  0.01386705  0.02630435  0.0050721\n",
      "   0.00436551  0.00464801  0.02093484  0.01312038  0.00205282  0.0217758\n",
      "   0.0086907   0.00699967  0.00699967  0.01135818  0.00699967  0.0056128\n",
      "   0.00818272  0.01648534  0.01165204  0.00699967  0.02093484  0.01366092\n",
      "   0.02093484  0.02630435  0.00790676  0.01094954  0.00818272  0.01312019\n",
      "   0.01648534  0.00818272  0.01648534  0.00699967  0.00542016  0.01591968\n",
      "   0.01094954  0.01817287  0.0086907   0.00943805]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1.  1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1.\n",
      "   1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1. -1.]]\n",
      "current error:   0.11\n",
      "D: [[ 0.00484832  0.01957135  0.01808345  0.01031757  0.0097145   0.01957135\n",
      "   0.00297301  0.00706821  0.00988571  0.00830999  0.00945818  0.00297301\n",
      "   0.00554282  0.00685942  0.0064348   0.00685942  0.00434823  0.01808345\n",
      "   0.00162828  0.0060463   0.00602158  0.01031757  0.01872599  0.00666356\n",
      "   0.00401493  0.00602158  0.0024371   0.00554282  0.00411712  0.01057925\n",
      "   0.00484832  0.0024371   0.01808345  0.0024371   0.00675114  0.01957135\n",
      "   0.01808345  0.00427134  0.00988571  0.0024371   0.00401493  0.0031078\n",
      "   0.0097145   0.00401493  0.00554282  0.00682984  0.0064348   0.01957135\n",
      "   0.01383326  0.0024371   0.00706821  0.0064348   0.01957135  0.00602158\n",
      "   0.00401493  0.01557625  0.01197832  0.01057925  0.0060463   0.01808345\n",
      "   0.01808345  0.0060463   0.01197832  0.01197832  0.02272161  0.00602158\n",
      "   0.00377092  0.00401493  0.01808345  0.01557648  0.0024371   0.02585216\n",
      "   0.01031757  0.0060463   0.0060463   0.00981116  0.0060463   0.00484832\n",
      "   0.0097145   0.01957135  0.01383326  0.0060463   0.01808345  0.0162182\n",
      "   0.01808345  0.02272161  0.00682984  0.00945818  0.0097145   0.01557625\n",
      "   0.01957135  0.0097145   0.01957135  0.0060463   0.0064348   0.01375137\n",
      "   0.00945818  0.01569767  0.01031757  0.01120483]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.13\n",
      "D: [[ 0.00583805  0.01673437  0.02177497  0.00882198  0.00830633  0.01673437\n",
      "   0.00357991  0.00604363  0.01190376  0.00710541  0.01138895  0.00357991\n",
      "   0.00473935  0.00825969  0.00550204  0.00825969  0.00371793  0.02177497\n",
      "   0.00139225  0.00516985  0.00514871  0.00882198  0.02254868  0.00802384\n",
      "   0.00483453  0.00514871  0.00208383  0.00473935  0.00495757  0.00904573\n",
      "   0.00583805  0.00208383  0.02177497  0.00208383  0.00577253  0.01673437\n",
      "   0.02177497  0.00365218  0.01190376  0.00208383  0.00483453  0.0026573\n",
      "   0.00830633  0.00483453  0.00473935  0.00822407  0.00550204  0.01673437\n",
      "   0.01182805  0.00208383  0.00604363  0.00550204  0.01673437  0.00514871\n",
      "   0.00483453  0.01331838  0.01442354  0.00904573  0.00516985  0.02177497\n",
      "   0.02177497  0.00516985  0.01442354  0.01442354  0.02735995  0.00514871\n",
      "   0.0032243   0.00483453  0.02177497  0.01331857  0.00208383  0.02210474\n",
      "   0.00882198  0.00516985  0.00516985  0.01181399  0.00516985  0.00583805\n",
      "   0.00830633  0.01673437  0.01182805  0.00516985  0.02177497  0.01386728\n",
      "   0.02177497  0.02735995  0.00822407  0.01138895  0.00830633  0.01331838\n",
      "   0.01673437  0.00830633  0.01673437  0.00516985  0.00550204  0.01175803\n",
      "   0.01138895  0.01890216  0.00882198  0.00958062]]\n",
      "classEstimate:  [[-1.  1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1.  1. -1. -1.  1.  1. -1.  1.  1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.11\n",
      "D: [[ 0.00494303  0.02043435  0.01843669  0.0074695   0.0070329   0.02043435\n",
      "   0.00303108  0.00511709  0.01007882  0.00867642  0.00964293  0.00303108\n",
      "   0.00578723  0.00699341  0.00465853  0.00699341  0.00453997  0.01843669\n",
      "   0.00117881  0.00631291  0.0062871   0.0074695   0.01909178  0.00679372\n",
      "   0.00409336  0.0062871   0.00254457  0.00578723  0.00419754  0.01104575\n",
      "   0.00494303  0.00254457  0.01843669  0.00254457  0.00704884  0.02043435\n",
      "   0.01843669  0.00309227  0.01007882  0.00254457  0.00409336  0.00224992\n",
      "   0.0070329   0.00409336  0.00578723  0.00696325  0.00465853  0.02043435\n",
      "   0.01444325  0.00254457  0.00511709  0.00465853  0.02043435  0.0062871\n",
      "   0.00409336  0.01127657  0.0122123   0.01104575  0.00631291  0.01843669\n",
      "   0.01843669  0.00631291  0.0122123   0.0122123   0.03340927  0.0062871\n",
      "   0.0039372   0.00409336  0.01843669  0.01626333  0.00254457  0.02699213\n",
      "   0.0074695   0.00631291  0.00631291  0.01000281  0.00631291  0.00494303\n",
      "   0.0070329   0.02043435  0.01444325  0.00631291  0.01843669  0.01693335\n",
      "   0.01843669  0.03340927  0.00696325  0.00964293  0.0070329   0.01127657\n",
      "   0.02043435  0.0070329   0.02043435  0.00631291  0.00465853  0.01435775\n",
      "   0.00964293  0.01600431  0.0074695   0.01169891]]\n",
      "classEstimate:  [[ 1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.\n",
      "   1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.13\n",
      "D: [[ 0.0059576   0.01746081  0.02222086  0.00638256  0.00847642  0.01746081\n",
      "   0.00365322  0.00616739  0.01214752  0.00741386  0.01162216  0.00365322\n",
      "   0.00494509  0.00842883  0.00398064  0.00842883  0.00387933  0.02222086\n",
      "   0.00142076  0.00539427  0.00537222  0.00638256  0.02301041  0.00818815\n",
      "   0.00493353  0.00537222  0.00217429  0.00494509  0.00505909  0.00943841\n",
      "   0.0059576   0.00217429  0.02222086  0.00217429  0.00602312  0.01746081\n",
      "   0.02222086  0.00372697  0.01214752  0.00217429  0.00493353  0.00271172\n",
      "   0.00847642  0.00493353  0.00494509  0.00839247  0.00398064  0.01746081\n",
      "   0.01234151  0.00217429  0.00616739  0.00398064  0.01746081  0.00537222\n",
      "   0.00493353  0.0135911   0.0104352   0.00943841  0.00539427  0.02222086\n",
      "   0.02222086  0.00539427  0.0104352   0.0104352   0.02854766  0.00537222\n",
      "   0.00336427  0.00493353  0.02222086  0.01389674  0.00217429  0.02306432\n",
      "   0.00638256  0.00539427  0.00539427  0.01205591  0.00539427  0.0059576\n",
      "   0.00847642  0.01746081  0.01234151  0.00539427  0.02222086  0.01446927\n",
      "   0.02222086  0.02854766  0.00839247  0.01162216  0.00847642  0.0135911\n",
      "   0.01746081  0.00847642  0.01746081  0.00539427  0.00398064  0.01226845\n",
      "   0.01162216  0.01928922  0.00638256  0.00999652]]\n",
      "classEstimate:  [[-1.  1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1.  1.  1. -1. -1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1.  1. -1.]]\n",
      "current error:   0.11\n",
      "D: [[ 0.00513139  0.02081173  0.01913923  0.00760744  0.00730089  0.02081173\n",
      "   0.00314658  0.00531208  0.01046288  0.00883666  0.01001038  0.00314658\n",
      "   0.00589411  0.0072599   0.00342859  0.0072599   0.00462382  0.01913923\n",
      "   0.00122372  0.00642949  0.00640321  0.00760744  0.01981929  0.0070526\n",
      "   0.00424934  0.00640321  0.00259156  0.00589411  0.00435749  0.01124974\n",
      "   0.00513139  0.00259156  0.01913923  0.00259156  0.00717902  0.02081173\n",
      "   0.01913923  0.0032101   0.01046288  0.00259156  0.00424934  0.00233565\n",
      "   0.00730089  0.00424934  0.00589411  0.00722859  0.00342859  0.02081173\n",
      "   0.01470998  0.00259156  0.00531208  0.00342859  0.02081173  0.00640321\n",
      "   0.00424934  0.01619938  0.00898803  0.01124974  0.00642949  0.01913923\n",
      "   0.01913923  0.00642949  0.00898803  0.00898803  0.02458862  0.00640321\n",
      "   0.00289771  0.00424934  0.01913923  0.01656367  0.00259156  0.02749061\n",
      "   0.00760744  0.00642949  0.00642949  0.01038397  0.00642949  0.00513139\n",
      "   0.00730089  0.02081173  0.01470998  0.00642949  0.01913923  0.01724607\n",
      "   0.01913923  0.02458862  0.00722859  0.01001038  0.00730089  0.01619938\n",
      "   0.02081173  0.00730089  0.02081173  0.00642949  0.00342859  0.0146229\n",
      "   0.01001038  0.01661416  0.00760744  0.01191496]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.13\n",
      "D: [[ 0.00597382  0.01823958  0.02228135  0.00666723  0.00639856  0.01823958\n",
      "   0.00366316  0.00465555  0.01218059  0.00774452  0.01165381  0.00366316\n",
      "   0.00516564  0.00845177  0.00300485  0.00845177  0.00405235  0.02228135\n",
      "   0.00107248  0.00563486  0.00561183  0.00666723  0.02307306  0.00821044\n",
      "   0.00494696  0.00561183  0.00227126  0.00516564  0.00507286  0.00985937\n",
      "   0.00597382  0.00227126  0.02228135  0.00227126  0.00629175  0.01823958\n",
      "   0.02228135  0.00281336  0.01218059  0.00227126  0.00494696  0.00204699\n",
      "   0.00639856  0.00494696  0.00516564  0.00841532  0.00300485  0.01823958\n",
      "   0.01289195  0.00227126  0.00465555  0.00300485  0.01823958  0.00561183\n",
      "   0.00494696  0.01419728  0.01046361  0.00985937  0.00563486  0.02228135\n",
      "   0.02228135  0.00563486  0.01046361  0.01046361  0.02862538  0.00561183\n",
      "   0.00253957  0.00494696  0.02228135  0.01451655  0.00227126  0.02409301\n",
      "   0.00666723  0.00563486  0.00563486  0.01208873  0.00563486  0.00597382\n",
      "   0.00639856  0.01823958  0.01289195  0.00563486  0.02228135  0.01511461\n",
      "   0.02228135  0.02862538  0.00841532  0.01165381  0.00639856  0.01419728\n",
      "   0.01823958  0.00639856  0.01823958  0.00563486  0.00300485  0.01281564\n",
      "   0.01165381  0.01934174  0.00666723  0.01044237]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1.  1. -1.  1. -1. -1.  1.\n",
      "   1.  1. -1.  1.  1. -1. -1. -1.  1.  1. -1.  1. -1.  1. -1.  1. -1. -1.\n",
      "   1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1. -1.]]\n",
      "current error:   0.12\n",
      "D: [[ 0.00513338  0.02181038  0.01914666  0.00797248  0.00765122  0.02181038\n",
      "   0.0031478   0.00556698  0.01046694  0.00665497  0.01001427  0.0031478\n",
      "   0.00443891  0.00726272  0.00359311  0.00726272  0.00484569  0.01914666\n",
      "   0.00128244  0.00484211  0.00671047  0.00797248  0.02759012  0.00705534\n",
      "   0.00425099  0.00671047  0.00195173  0.00443891  0.00435918  0.00847228\n",
      "   0.00513338  0.00195173  0.01914666  0.00195173  0.0075235   0.02181038\n",
      "   0.01914666  0.00336414  0.01046694  0.00195173  0.00425099  0.00244773\n",
      "   0.00765122  0.00425099  0.00443891  0.00723139  0.00359311  0.02181038\n",
      "   0.01541584  0.00195173  0.00556698  0.00359311  0.02181038  0.00671047\n",
      "   0.00425099  0.01697671  0.00899152  0.00847228  0.00484211  0.01914666\n",
      "   0.01914666  0.00484211  0.00899152  0.00899152  0.02459817  0.00671047\n",
      "   0.00218229  0.00425099  0.01914666  0.01735848  0.00195173  0.02880974\n",
      "   0.00797248  0.00484211  0.00484211  0.01445537  0.00484211  0.00513338\n",
      "   0.00765122  0.02181038  0.01541584  0.00484211  0.01914666  0.01807362\n",
      "   0.01914666  0.02459817  0.00723139  0.01001427  0.00765122  0.01697671\n",
      "   0.02181038  0.00765122  0.02181038  0.00484211  0.00359311  0.01101264\n",
      "   0.01001427  0.01662061  0.00797248  0.0124867 ]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.]]\n",
      "current error:   0.13\n",
      "D: [[ 0.00603724  0.01897027  0.0225179   0.00693432  0.00665489  0.01897027\n",
      "   0.0027379   0.00484206  0.00910395  0.00782674  0.00871023  0.0027379\n",
      "   0.00522048  0.0085415   0.00312523  0.0085415   0.00421469  0.0225179\n",
      "   0.00111545  0.00569469  0.00583664  0.00693432  0.02399738  0.0061366\n",
      "   0.00369743  0.00583664  0.00229538  0.00522048  0.00379153  0.00996404\n",
      "   0.00603724  0.00229538  0.0225179   0.00229538  0.0065438   0.01897027\n",
      "   0.0225179   0.00292607  0.00910395  0.00229538  0.00369743  0.00212899\n",
      "   0.00665489  0.00369743  0.00522048  0.00628973  0.00312523  0.01897027\n",
      "   0.01340841  0.00229538  0.00484206  0.00312523  0.01897027  0.00583664\n",
      "   0.00369743  0.01476603  0.0105747   0.00996404  0.00569469  0.0225179\n",
      "   0.0225179   0.00569469  0.0105747   0.0105747   0.02892928  0.00583664\n",
      "   0.00256654  0.00369743  0.0225179   0.02041487  0.00229538  0.03388241\n",
      "   0.00693432  0.00569469  0.00569469  0.01257301  0.00569469  0.00603724\n",
      "   0.00665489  0.01897027  0.01340841  0.00569469  0.0225179   0.01572011\n",
      "   0.0225179   0.02892928  0.00628973  0.00871023  0.00665489  0.01476603\n",
      "   0.01897027  0.00665489  0.01897027  0.00569469  0.00312523  0.01295169\n",
      "   0.00871023  0.0144563   0.00693432  0.0108607 ]]\n",
      "classEstimate:  [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.1\n",
      "D: [[ 0.00724155  0.02275449  0.01930702  0.00831759  0.00798242  0.02275449\n",
      "   0.00328406  0.00580796  0.01092002  0.0067107   0.01044776  0.00328406\n",
      "   0.00447608  0.01024537  0.00374865  0.01024537  0.00361371  0.01930702\n",
      "   0.00133796  0.00488267  0.00500438  0.00831759  0.02878441  0.00736074\n",
      "   0.004435    0.00500438  0.00196807  0.00447608  0.00454788  0.00854324\n",
      "   0.00724155  0.00196807  0.02700981  0.00196807  0.00561071  0.01626525\n",
      "   0.02700981  0.00350976  0.01092002  0.00196807  0.004435    0.00255368\n",
      "   0.00798242  0.004435    0.00447608  0.00754442  0.00374865  0.02275449\n",
      "   0.01149647  0.00196807  0.00580796  0.00374865  0.01626525  0.00500438\n",
      "   0.004435    0.01771158  0.00906683  0.00854324  0.00488267  0.01930702\n",
      "   0.01930702  0.00488267  0.00906683  0.00906683  0.02480418  0.00500438\n",
      "   0.00220057  0.004435    0.01930702  0.01750386  0.00196807  0.02905104\n",
      "   0.00831759  0.00488267  0.00488267  0.0150811   0.00488267  0.00724155\n",
      "   0.00798242  0.02275449  0.01149647  0.00488267  0.01930702  0.01347854\n",
      "   0.01930702  0.02480418  0.00754442  0.01044776  0.00798242  0.01771158\n",
      "   0.01626525  0.00798242  0.01626525  0.00488267  0.00374865  0.01110488\n",
      "   0.01044776  0.01734007  0.00831759  0.00931205]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classEstimate:  [[-1.  1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1.  1. -1. -1.  1.  1. -1.  1.  1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.1\n",
      "D: [[ 0.00633743  0.0265409   0.01689651  0.00727912  0.0069858   0.0265409\n",
      "   0.00287404  0.00508283  0.00955664  0.00782739  0.00914334  0.00287404\n",
      "   0.00522092  0.00896622  0.00328063  0.00896622  0.00421504  0.01689651\n",
      "   0.00117091  0.00569516  0.00583712  0.00727912  0.02519063  0.00644174\n",
      "   0.00388129  0.00583712  0.00229557  0.00522092  0.00398007  0.00996486\n",
      "   0.00633743  0.00229557  0.02363759  0.00229557  0.00654434  0.01897184\n",
      "   0.02363759  0.00307156  0.00955664  0.00229557  0.00388129  0.00223485\n",
      "   0.0069858   0.00388129  0.00522092  0.00660249  0.00328063  0.0265409\n",
      "   0.01340952  0.00229557  0.00508283  0.00328063  0.01897184  0.00583712\n",
      "   0.00388129  0.01550026  0.00793482  0.00996486  0.00569516  0.01689651\n",
      "   0.01689651  0.00569516  0.00793482  0.00793482  0.02893167  0.00583712\n",
      "   0.00256675  0.00388129  0.01689651  0.02041656  0.00229557  0.03388521\n",
      "   0.00727912  0.00569516  0.00569516  0.0131982   0.00569516  0.00633743\n",
      "   0.0069858   0.0265409   0.01340952  0.00569516  0.01689651  0.01572141\n",
      "   0.01689651  0.02893167  0.00660249  0.00914334  0.0069858   0.01550026\n",
      "   0.01897184  0.0069858   0.01897184  0.00569516  0.00328063  0.01295276\n",
      "   0.00914334  0.01517513  0.00727912  0.0108616 ]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.1\n",
      "D: [[ 0.00731718  0.02340681  0.01950864  0.00641957  0.00616088  0.02340681\n",
      "   0.00331836  0.00448262  0.01103406  0.00690309  0.01055686  0.00331836\n",
      "   0.0046044   0.01035237  0.00289323  0.01035237  0.00371731  0.01950864\n",
      "   0.00103264  0.00502264  0.00514784  0.00641957  0.02908501  0.00743761\n",
      "   0.00448132  0.00514784  0.00202449  0.0046044   0.00459537  0.00878816\n",
      "   0.00731718  0.00202449  0.02729187  0.00202449  0.00577155  0.01673154\n",
      "   0.02729187  0.00270886  0.01103406  0.00202449  0.00448132  0.00197095\n",
      "   0.00616088  0.00448132  0.0046044   0.00762321  0.00289323  0.02340681\n",
      "   0.01182605  0.00202449  0.00448262  0.00289323  0.01673154  0.00514784\n",
      "   0.00448132  0.01366991  0.00916151  0.00878816  0.00502264  0.01950864\n",
      "   0.01950864  0.00502264  0.00916151  0.00916151  0.0334044   0.00514784\n",
      "   0.00226365  0.00448132  0.01950864  0.01800566  0.00202449  0.02988387\n",
      "   0.00641957  0.00502264  0.00502264  0.01523859  0.00502264  0.00731718\n",
      "   0.00616088  0.02340681  0.01182605  0.00502264  0.01950864  0.01386494\n",
      "   0.01950864  0.0334044   0.00762321  0.01055686  0.00616088  0.01366991\n",
      "   0.01673154  0.00616088  0.01673154  0.00502264  0.00289323  0.01142323\n",
      "   0.01055686  0.01752115  0.00641957  0.00957901]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1. -1. -1.  1.\n",
      "   1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1.  1.]]\n",
      "current error:   0.1\n",
      "D: [[ 0.00640384  0.02730051  0.01707355  0.00748746  0.00718574  0.02730051\n",
      "   0.00290416  0.0052283   0.01286956  0.00604144  0.00923914  0.00290416\n",
      "   0.00402968  0.00906017  0.00337452  0.00906017  0.00433567  0.01707355\n",
      "   0.00120442  0.00439571  0.00600418  0.00748746  0.03392327  0.00867485\n",
      "   0.00522678  0.00600418  0.0017718   0.00402968  0.00402177  0.00769121\n",
      "   0.00640384  0.0017718   0.02388527  0.0017718   0.00505114  0.01951482\n",
      "   0.02388527  0.00315947  0.01286956  0.0017718   0.00522678  0.00229881\n",
      "   0.00718574  0.00522678  0.00402968  0.00667167  0.00337452  0.02730051\n",
      "   0.01379331  0.0017718   0.0052283   0.00337452  0.01951482  0.00600418\n",
      "   0.00522678  0.01594388  0.00801796  0.00769121  0.00439571  0.01707355\n",
      "   0.01707355  0.00439571  0.00801796  0.00801796  0.02923483  0.00600418\n",
      "   0.0019811   0.00522678  0.01707355  0.01575818  0.0017718   0.02615373\n",
      "   0.00748746  0.00439571  0.00439571  0.01777351  0.00439571  0.00640384\n",
      "   0.00718574  0.02730051  0.01379331  0.00439571  0.01707355  0.01617136\n",
      "   0.01707355  0.02923483  0.00667167  0.00923914  0.00718574  0.01594388\n",
      "   0.01951482  0.00718574  0.01951482  0.00439571  0.00337452  0.00999737\n",
      "   0.00923914  0.01533414  0.00748746  0.00838334]]\n",
      "classEstimate:  [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.1\n",
      "D: [[ 0.00545114  0.023239    0.02068947  0.00637354  0.00611672  0.023239\n",
      "   0.0024721   0.00445048  0.01095495  0.00732092  0.00786463  0.0024721\n",
      "   0.0048831   0.00771229  0.00287249  0.00771229  0.00369066  0.02068947\n",
      "   0.00102524  0.00532666  0.00511094  0.00637354  0.02887649  0.00738429\n",
      "   0.00444919  0.00511094  0.00214703  0.0048831   0.00342345  0.00932009\n",
      "   0.00545114  0.00214703  0.02894381  0.00214703  0.0061209   0.01661159\n",
      "   0.02894381  0.00268944  0.01095495  0.00214703  0.00444919  0.00195682\n",
      "   0.00611672  0.00444919  0.0048831   0.00567912  0.00287249  0.023239\n",
      "   0.01174127  0.00214703  0.00445048  0.00287249  0.01661159  0.00511094\n",
      "   0.00444919  0.01357191  0.00971605  0.00932009  0.00532666  0.02068947\n",
      "   0.02068947  0.00532666  0.00971605  0.00971605  0.03542632  0.00511094\n",
      "   0.00240067  0.00444919  0.02068947  0.01909552  0.00214703  0.0316927\n",
      "   0.00637354  0.00532666  0.00532666  0.01512934  0.00532666  0.00545114\n",
      "   0.00611672  0.023239    0.01174127  0.00532666  0.02068947  0.01959621\n",
      "   0.02068947  0.03542632  0.00567912  0.00786463  0.00611672  0.01357191\n",
      "   0.01661159  0.00611672  0.01661159  0.00532666  0.00287249  0.01211466\n",
      "   0.00786463  0.01305288  0.00637354  0.01015881]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1.\n",
      "   1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.1\n",
      "D: [[ 0.00475102  0.02725542  0.01803221  0.00747509  0.00717387  0.02725542\n",
      "   0.0021546   0.00521966  0.00954795  0.00638065  0.00922388  0.0021546\n",
      "   0.00425594  0.00672176  0.00336894  0.00672176  0.00321664  0.01803221\n",
      "   0.00120243  0.00464252  0.00599427  0.00747509  0.03386724  0.00866052\n",
      "   0.00521815  0.00599427  0.00187128  0.00425594  0.00401513  0.00812306\n",
      "   0.00475102  0.00187128  0.02522639  0.00187128  0.00533476  0.01948259\n",
      "   0.02522639  0.00315426  0.00954795  0.00187128  0.00521815  0.00229502\n",
      "   0.00717387  0.00521815  0.00425594  0.00494972  0.00336894  0.02725542\n",
      "   0.01377052  0.00187128  0.00521966  0.00336894  0.01948259  0.00599427\n",
      "   0.00521815  0.01591755  0.00846816  0.00812306  0.00464252  0.01803221\n",
      "   0.01803221  0.00464252  0.00846816  0.00846816  0.03087632  0.00599427\n",
      "   0.00209234  0.00521815  0.01803221  0.01664298  0.00187128  0.02762223\n",
      "   0.00747509  0.00464252  0.00464252  0.01774415  0.00464252  0.00475102\n",
      "   0.00717387  0.02725542  0.01377052  0.00464252  0.01803221  0.01707936\n",
      "   0.01803221  0.03087632  0.00494972  0.00922388  0.00717387  0.01591755\n",
      "   0.01948259  0.00717387  0.01948259  0.00464252  0.00336894  0.01055871\n",
      "   0.00922388  0.01530881  0.00747509  0.00885406]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1.  1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1.  1.  1. -1.  1.]]\n",
      "current error:   0.1\n",
      "D: [[ 0.0055502   0.02382483  0.02106547  0.00653421  0.00627091  0.02382483\n",
      "   0.00251703  0.00456268  0.01115404  0.00745397  0.01077546  0.00251703\n",
      "   0.00372025  0.00785245  0.0029449   0.00785245  0.00281177  0.02106547\n",
      "   0.00105109  0.00542346  0.00523978  0.00653421  0.02960443  0.00757044\n",
      "   0.00456135  0.00523978  0.00163574  0.00372025  0.00469053  0.00710063\n",
      "   0.0055502   0.00163574  0.02946981  0.00163574  0.00466328  0.01703035\n",
      "   0.02946981  0.00275724  0.01115404  0.00163574  0.00456135  0.00200615\n",
      "   0.00627091  0.00456135  0.00372025  0.00578233  0.0029449   0.02382483\n",
      "   0.01203725  0.00163574  0.00456268  0.0029449   0.01703035  0.00523978\n",
      "   0.00456135  0.01391404  0.00989262  0.00710063  0.00542346  0.02106547\n",
      "   0.02106547  0.00542346  0.00989262  0.00989262  0.03607013  0.00523978\n",
      "   0.0024443   0.00456135  0.02106547  0.01454816  0.00163574  0.02414547\n",
      "   0.00653421  0.00542346  0.00542346  0.01551073  0.00542346  0.0055502\n",
      "   0.00627091  0.02382483  0.01203725  0.00542346  0.02106547  0.01492961\n",
      "   0.02106547  0.03607013  0.00578233  0.01077546  0.00627091  0.01391404\n",
      "   0.01703035  0.00627091  0.01703035  0.00542346  0.0029449   0.01233483\n",
      "   0.01077546  0.01788396  0.00653421  0.00773961]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1.  1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1.\n",
      "   1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1. -1.]]\n",
      "current error:   0.1\n",
      "D: [[ 0.00478284  0.02837782  0.01815297  0.00778292  0.0074693   0.02837782\n",
      "   0.00216903  0.00393184  0.00961189  0.00887844  0.00928566  0.00216903\n",
      "   0.0044312   0.00676677  0.00350768  0.00676677  0.00334911  0.01815297\n",
      "   0.00090576  0.00467362  0.00624112  0.00778292  0.02551135  0.00652375\n",
      "   0.0039307   0.00624112  0.00194834  0.0044312   0.00404202  0.00845758\n",
      "   0.00478284  0.00194834  0.02539534  0.00194834  0.00555445  0.0202849\n",
      "   0.02539534  0.00328415  0.00961189  0.00194834  0.0039307   0.00172878\n",
      "   0.0074693   0.0039307   0.0044312   0.00498287  0.00350768  0.02837782\n",
      "   0.01433761  0.00194834  0.00393184  0.00350768  0.0202849   0.00624112\n",
      "   0.0039307   0.01657305  0.00852487  0.00845758  0.00467362  0.01815297\n",
      "   0.01815297  0.00467362  0.00852487  0.00852487  0.0310831   0.00624112\n",
      "   0.00210635  0.0039307   0.01815297  0.01732835  0.00194834  0.02875974\n",
      "   0.00778292  0.00467362  0.00467362  0.01336623  0.00467362  0.00478284\n",
      "   0.0074693   0.02837782  0.01433761  0.00467362  0.01815297  0.0177827\n",
      "   0.01815297  0.0310831   0.00498287  0.00928566  0.0074693   0.01657305\n",
      "   0.0202849   0.0074693   0.0202849   0.00467362  0.00350768  0.01062942\n",
      "   0.00928566  0.01541134  0.00778292  0.00921868]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1.  1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1.  1.  1. -1.  1.]]\n",
      "current error:   0.09\n",
      "D: [[ 0.00551876  0.02503891  0.02094612  0.00686719  0.00659047  0.02503891\n",
      "   0.00250277  0.00346922  0.01109085  0.01024454  0.01071442  0.00250277\n",
      "   0.00390983  0.00780796  0.00309497  0.00780796  0.00295505  0.02094612\n",
      "   0.00079919  0.00539273  0.00550679  0.00686719  0.02250969  0.00575617\n",
      "   0.00346822  0.00550679  0.0017191   0.00390983  0.00466395  0.00746246\n",
      "   0.00551876  0.0017191   0.02930285  0.0017191   0.00490091  0.01789819\n",
      "   0.02930285  0.00289774  0.01109085  0.0017191   0.00346822  0.00152537\n",
      "   0.00659047  0.00346822  0.00390983  0.00574957  0.00309497  0.02503891\n",
      "   0.01265065  0.0017191   0.00346922  0.00309497  0.01789819  0.00550679\n",
      "   0.00346822  0.01462308  0.00983657  0.00746246  0.00539273  0.02094612\n",
      "   0.02094612  0.00539273  0.00983657  0.00983657  0.03586577  0.00550679\n",
      "   0.00243045  0.00346822  0.02094612  0.01528951  0.0017191   0.02537589\n",
      "   0.00686719  0.00539273  0.00539273  0.01179357  0.00539273  0.00551876\n",
      "   0.00659047  0.02503891  0.01265065  0.00539273  0.02094612  0.0156904\n",
      "   0.02094612  0.03586577  0.00574957  0.01071442  0.00659047  0.01462308\n",
      "   0.01789819  0.00659047  0.01789819  0.00539273  0.00309497  0.01226494\n",
      "   0.01071442  0.01778264  0.00686719  0.00813401]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1. -1. -1.  1.\n",
      "   1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1.  1.]]\n",
      "current error:   0.09\n",
      "D: [[ 0.00485389  0.02901296  0.01842267  0.00795711  0.00763647  0.02901296\n",
      "   0.00220125  0.00401984  0.01285114  0.00901035  0.00942361  0.00220125\n",
      "   0.0034388   0.00686731  0.00358619  0.00686731  0.00342407  0.01842267\n",
      "   0.00092604  0.00474305  0.0063808   0.00795711  0.02608233  0.00666977\n",
      "   0.00401868  0.0063808   0.00151199  0.0034388   0.00410207  0.00656344\n",
      "   0.00485389  0.00151199  0.02577264  0.00151199  0.00431048  0.02073891\n",
      "   0.02577264  0.00335766  0.01285114  0.00151199  0.00401868  0.00176747\n",
      "   0.00763647  0.00401868  0.0034388   0.0050569   0.00358619  0.02901296\n",
      "   0.01465851  0.00151199  0.00401984  0.00358619  0.02073891  0.0063808\n",
      "   0.00401868  0.01694398  0.00865153  0.00656344  0.00474305  0.01842267\n",
      "   0.01842267  0.00474305  0.00865153  0.00865153  0.0315449   0.0063808\n",
      "   0.00213764  0.00401868  0.01842267  0.01344753  0.00151199  0.02231877\n",
      "   0.00795711  0.00474305  0.00474305  0.01366539  0.00474305  0.00485389\n",
      "   0.00763647  0.02901296  0.01465851  0.00474305  0.01842267  0.01818071\n",
      "   0.01842267  0.0315449   0.0050569   0.00942361  0.00763647  0.01694398\n",
      "   0.02073891  0.00763647  0.02073891  0.00474305  0.00358619  0.01078734\n",
      "   0.00942361  0.0156403   0.00795711  0.00715408]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.]]\n",
      "current error:   0.09\n",
      "D: [[ 0.00569698  0.02527288  0.02162255  0.00693136  0.00665205  0.02527288\n",
      "   0.00191749  0.00350164  0.01119449  0.01057538  0.00820881  0.00191749\n",
      "   0.00403609  0.00806011  0.00312389  0.00806011  0.00298267  0.02162255\n",
      "   0.00080666  0.00556688  0.00555825  0.00693136  0.02272003  0.00580996\n",
      "   0.00350062  0.00555825  0.00177462  0.00403609  0.00357327  0.00770346\n",
      "   0.00569698  0.00177462  0.03024915  0.00177462  0.00375482  0.01806543\n",
      "   0.03024915  0.00292482  0.01119449  0.00177462  0.00350062  0.00153963\n",
      "   0.00665205  0.00350062  0.00403609  0.00440501  0.00312389  0.02527288\n",
      "   0.01276887  0.00177462  0.00350164  0.00312389  0.01806543  0.00555825\n",
      "   0.00350062  0.01475972  0.01015423  0.00770346  0.00556688  0.02162255\n",
      "   0.02162255  0.00556688  0.01015423  0.01015423  0.03702402  0.00555825\n",
      "   0.00250894  0.00350062  0.02162255  0.01578327  0.00177462  0.02619537\n",
      "   0.00693136  0.00556688  0.00556688  0.01190377  0.00556688  0.00569698\n",
      "   0.00665205  0.02527288  0.01276887  0.00556688  0.02162255  0.01583702\n",
      "   0.02162255  0.03702402  0.00440501  0.00820881  0.00665205  0.01475972\n",
      "   0.01806543  0.00665205  0.01806543  0.00556688  0.00312389  0.01266103\n",
      "   0.00820881  0.0136241   0.00693136  0.00623184]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1. -1. -1.  1.\n",
      "   1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1.  1.]]\n",
      "current error:   0.09\n",
      "D: [[ 0.00504644  0.02901296  0.01915346  0.00795711  0.00763647  0.02901296\n",
      "   0.00169853  0.00401984  0.01285114  0.00936777  0.00727144  0.00169853\n",
      "   0.00357521  0.00713972  0.00358619  0.00713972  0.00342407  0.01915346\n",
      "   0.00092604  0.0049312   0.0063808   0.00795711  0.02608233  0.00666977\n",
      "   0.00401868  0.0063808   0.00157197  0.00357521  0.00316523  0.00682379\n",
      "   0.00504644  0.00157197  0.02679499  0.00157197  0.00332605  0.02073891\n",
      "   0.02679499  0.00335766  0.01285114  0.00157197  0.00401868  0.00176747\n",
      "   0.00763647  0.00401868  0.00357521  0.003902    0.00358619  0.02901296\n",
      "   0.01465851  0.00157197  0.00401984  0.00358619  0.02073891  0.0063808\n",
      "   0.00401868  0.01694398  0.00899472  0.00682379  0.0049312   0.01915346\n",
      "   0.01915346  0.0049312   0.00899472  0.00899472  0.03279623  0.0063808\n",
      "   0.00222244  0.00401868  0.01915346  0.01398097  0.00157197  0.02320411\n",
      "   0.00795711  0.0049312   0.0049312   0.01366539  0.0049312   0.00504644\n",
      "   0.00763647  0.02901296  0.01465851  0.0049312   0.01915346  0.01818071\n",
      "   0.01915346  0.03279623  0.003902    0.00727144  0.00763647  0.01694398\n",
      "   0.02073891  0.00763647  0.02073891  0.0049312   0.00358619  0.01121526\n",
      "   0.00727144  0.01206836  0.00795711  0.00552022]]\n",
      "classEstimate:  [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.09\n",
      "D: [[ 0.00450988  0.02592818  0.02173995  0.00711108  0.00682453  0.02592818\n",
      "   0.00151793  0.00359244  0.01148475  0.0106328   0.00649831  0.00151793\n",
      "   0.00405801  0.00638059  0.00320489  0.00638059  0.00306001  0.02173995\n",
      "   0.00082758  0.00559711  0.00570237  0.00711108  0.02330915  0.00596061\n",
      "   0.00359139  0.00570237  0.00178425  0.00405801  0.00282869  0.00774528\n",
      "   0.00450988  0.00178425  0.03041339  0.00178425  0.0037752   0.01853386\n",
      "   0.03041339  0.00300066  0.01148475  0.00178425  0.00359139  0.00157955\n",
      "   0.00682453  0.00359139  0.00405801  0.00348712  0.00320489  0.02592818\n",
      "   0.01309995  0.00178425  0.00359244  0.00320489  0.01853386  0.00570237\n",
      "   0.00359139  0.01514243  0.01020937  0.00774528  0.00559711  0.02173995\n",
      "   0.02173995  0.00559711  0.01020937  0.01020937  0.03722504  0.00570237\n",
      "   0.00252256  0.00359139  0.02173995  0.01586896  0.00178425  0.0263376\n",
      "   0.00711108  0.00559711  0.00559711  0.01221242  0.00559711  0.00450988\n",
      "   0.00682453  0.02592818  0.01309995  0.00559711  0.02173995  0.02063584\n",
      "   0.02173995  0.03722504  0.00348712  0.00649831  0.00682453  0.01514243\n",
      "   0.01853386  0.00682453  0.01853386  0.00559711  0.00320489  0.01272977\n",
      "   0.00649831  0.0107852   0.00711108  0.00626568]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.09\n",
      "D: [[ 0.00397367  0.02997268  0.01915516  0.00822033  0.00788908  0.02997268\n",
      "   0.00175471  0.00415282  0.01327624  0.0093686   0.00751197  0.00175471\n",
      "   0.00357553  0.00562197  0.00370482  0.00737589  0.00269618  0.01915516\n",
      "   0.00095667  0.00493164  0.00502438  0.00822033  0.0269451   0.00689039\n",
      "   0.00415161  0.00502438  0.00157211  0.00357553  0.00326994  0.0068244\n",
      "   0.00521337  0.00157211  0.02679737  0.00157211  0.00332635  0.02142493\n",
      "   0.02679737  0.00346872  0.01327624  0.00157211  0.00415161  0.00182594\n",
      "   0.00788908  0.00415161  0.00357553  0.00403108  0.00370482  0.02997268\n",
      "   0.01154242  0.00157211  0.00415282  0.00370482  0.02142493  0.00502438\n",
      "   0.00415161  0.01750447  0.00899552  0.0068244   0.00493164  0.01915516\n",
      "   0.01915516  0.00493164  0.00899552  0.00899552  0.03279914  0.00502438\n",
      "   0.00222264  0.00415161  0.01915516  0.01398221  0.00157211  0.02320617\n",
      "   0.00822033  0.00493164  0.00493164  0.01411742  0.00493164  0.00397367\n",
      "   0.00788908  0.02997268  0.01154242  0.00493164  0.01915516  0.01818232\n",
      "   0.01915516  0.03279914  0.00403108  0.00751197  0.00788908  0.01750447\n",
      "   0.02142493  0.00788908  0.02142493  0.00493164  0.00370482  0.01121625\n",
      "   0.00751197  0.01246756  0.00822033  0.00552071]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.]]\n",
      "current error:   0.09\n",
      "D: [[ 0.00451881  0.0267461   0.02178301  0.0073354   0.00703982  0.0267461\n",
      "   0.00156582  0.00370576  0.01184704  0.01065386  0.0067033   0.00156582\n",
      "   0.00406604  0.00639323  0.00330599  0.00838777  0.00240594  0.02178301\n",
      "   0.00085368  0.0056082   0.0044835   0.0073354   0.02404445  0.00614864\n",
      "   0.00370469  0.0044835   0.00178778  0.00406604  0.00291793  0.00776062\n",
      "   0.00592858  0.00178778  0.03047363  0.00178778  0.00296826  0.01911852\n",
      "   0.03047363  0.00309531  0.01184704  0.00178778  0.00370469  0.00162937\n",
      "   0.00703982  0.00370469  0.00406604  0.00359713  0.00330599  0.0267461\n",
      "   0.01029987  0.00178778  0.00370576  0.00330599  0.01911852  0.0044835\n",
      "   0.00370469  0.0156201   0.01022959  0.00776062  0.0056082   0.02178301\n",
      "   0.02178301  0.0056082   0.01022959  0.01022959  0.03729877  0.0044835\n",
      "   0.00252755  0.00370469  0.02178301  0.01590039  0.00178778  0.02638976\n",
      "   0.0073354   0.0056082   0.0056082   0.01259767  0.0056082   0.00451881\n",
      "   0.00703982  0.0267461   0.01029987  0.0056082   0.02178301  0.01622498\n",
      "   0.02178301  0.03729877  0.00359713  0.0067033   0.00703982  0.0156201\n",
      "   0.01911852  0.00703982  0.01911852  0.0056082   0.00330599  0.01275498\n",
      "   0.0067033   0.01112542  0.0073354   0.00492641]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1.\n",
      "   1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.09\n",
      "D: [[ 0.00403073  0.03043103  0.01943019  0.00834603  0.00800972  0.03043103\n",
      "   0.00139669  0.00421632  0.01056742  0.00950311  0.00762685  0.00139669\n",
      "   0.00362686  0.00570269  0.00376147  0.00748179  0.00214607  0.01943019\n",
      "   0.0009713   0.00500244  0.00510121  0.00834603  0.02735715  0.00699576\n",
      "   0.0042151   0.00510121  0.00159468  0.00362686  0.00331994  0.00692238\n",
      "   0.00528822  0.00159468  0.02718211  0.00159468  0.00264766  0.02175256\n",
      "   0.02718211  0.00352177  0.01056742  0.00159468  0.0042151   0.00185386\n",
      "   0.00800972  0.0042151   0.00362686  0.0032086   0.00376147  0.03043103\n",
      "   0.01171893  0.00159468  0.00421632  0.00376147  0.02175256  0.00510121\n",
      "   0.0042151   0.01777215  0.00912467  0.00692238  0.00500244  0.01943019\n",
      "   0.01943019  0.00500244  0.00912467  0.00912467  0.03327006  0.00510121\n",
      "   0.00225455  0.0042151   0.01943019  0.01418296  0.00159468  0.02353935\n",
      "   0.00834603  0.00500244  0.00500244  0.01433331  0.00500244  0.00403073\n",
      "   0.00800972  0.03043103  0.01171893  0.00500244  0.01943019  0.01447249\n",
      "   0.01943019  0.03327006  0.0032086   0.00762685  0.00800972  0.01777215\n",
      "   0.02175256  0.00800972  0.02175256  0.00500244  0.00376147  0.01137729\n",
      "   0.00762685  0.01265822  0.00834603  0.0043943 ]]\n",
      "classEstimate:  [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.09\n",
      "D: [[ 0.00360514  0.02721792  0.02203097  0.0074648   0.007164    0.02721792\n",
      "   0.00124922  0.00377113  0.00945164  0.01077513  0.00682155  0.00124922\n",
      "   0.00411233  0.00510056  0.00336431  0.00669182  0.00191947  0.02203097\n",
      "   0.00086874  0.00567203  0.00456259  0.0074648   0.0244686   0.00625711\n",
      "   0.00377004  0.00456259  0.00180814  0.00411233  0.0029694   0.00784896\n",
      "   0.00472986  0.00180814  0.03082051  0.00180814  0.00300205  0.01945578\n",
      "   0.03082051  0.00314992  0.00945164  0.00180814  0.00377004  0.00165812\n",
      "   0.007164    0.00377004  0.00411233  0.00286981  0.00336431  0.02721792\n",
      "   0.01048157  0.00180814  0.00377113  0.00336431  0.01945578  0.00456259\n",
      "   0.00377004  0.01589565  0.01034603  0.00784896  0.00567203  0.02203097\n",
      "   0.02203097  0.00567203  0.01034603  0.01034603  0.03772335  0.00456259\n",
      "   0.00255633  0.00377004  0.02203097  0.01608139  0.00180814  0.02669016\n",
      "   0.0074648   0.00567203  0.00567203  0.0128199   0.00567203  0.00360514\n",
      "   0.007164    0.02721792  0.01048157  0.00567203  0.02203097  0.01640968\n",
      "   0.02203097  0.03772335  0.00286981  0.00682155  0.007164    0.01589565\n",
      "   0.01945578  0.007164    0.01945578  0.00567203  0.00336431  0.01290017\n",
      "   0.00682155  0.01132168  0.0074648   0.00498248]]\n",
      "classEstimate:  [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current error:   0.09\n",
      "D: [[ 0.0040719   0.03074187  0.01976527  0.00843128  0.00809154  0.03074187\n",
      "   0.00141096  0.00425939  0.01067536  0.009667    0.00770475  0.00141096\n",
      "   0.00368941  0.00576094  0.00379989  0.00755822  0.00172207  0.01976527\n",
      "   0.00098122  0.00508871  0.00409337  0.00843128  0.02763659  0.00706722\n",
      "   0.00425815  0.00409337  0.00162218  0.00368941  0.00335385  0.00704176\n",
      "   0.00534224  0.00162218  0.03481089  0.00162218  0.00269332  0.01745492\n",
      "   0.03481089  0.00355774  0.01067536  0.00162218  0.00425815  0.0018728\n",
      "   0.00809154  0.00425815  0.00368941  0.00324137  0.00379989  0.03074187\n",
      "   0.00940363  0.00162218  0.00425939  0.00379989  0.01745492  0.00409337\n",
      "   0.00425815  0.01795368  0.00928203  0.00704176  0.00508871  0.01976527\n",
      "   0.01976527  0.00508871  0.00928203  0.00928203  0.03384383  0.00409337\n",
      "   0.00229343  0.00425815  0.01976527  0.01442755  0.00162218  0.02394531\n",
      "   0.00843128  0.00508871  0.00508871  0.01447971  0.00508871  0.0040719\n",
      "   0.00809154  0.03074187  0.00940363  0.00508871  0.01976527  0.01472208\n",
      "   0.01976527  0.03384383  0.00324137  0.00770475  0.00809154  0.01795368\n",
      "   0.01745492  0.00809154  0.01745492  0.00508871  0.00379989  0.0115735\n",
      "   0.00770475  0.01278752  0.00843128  0.00447008]]\n",
      "classEstimate:  [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.1\n",
      "D: [[ 0.00368588  0.0278275   0.02207743  0.00763199  0.00732445  0.0278275\n",
      "   0.0012772   0.00385559  0.00966333  0.01079786  0.00697433  0.0012772\n",
      "   0.004121    0.00521479  0.00343966  0.00684169  0.00192352  0.02207743\n",
      "   0.0008882   0.005684    0.00457222  0.00763199  0.02501661  0.00639724\n",
      "   0.00385447  0.00457222  0.00181195  0.004121    0.0030359   0.00786552\n",
      "   0.00483579  0.00181195  0.03151078  0.00181195  0.00300838  0.01949681\n",
      "   0.03151078  0.00322046  0.00966333  0.00181195  0.00385447  0.00169525\n",
      "   0.00732445  0.00385447  0.004121    0.00293408  0.00343966  0.0278275\n",
      "   0.01050368  0.00181195  0.00385559  0.00343966  0.01580018  0.00457222\n",
      "   0.00385447  0.01625166  0.01036785  0.00786552  0.005684    0.02207743\n",
      "   0.02207743  0.005684    0.01036785  0.01036785  0.03780291  0.00457222\n",
      "   0.00256172  0.00385447  0.02207743  0.0161153   0.00181195  0.02674645\n",
      "   0.00763199  0.005684    0.005684    0.01310702  0.005684    0.00368588\n",
      "   0.00732445  0.0278275   0.01050368  0.005684    0.02207743  0.01644428\n",
      "   0.02207743  0.03780291  0.00293408  0.00697433  0.00732445  0.01625166\n",
      "   0.01580018  0.00732445  0.01580018  0.005684    0.00343966  0.01292738\n",
      "   0.00697433  0.01157525  0.00763199  0.00499299]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1.\n",
      "   1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.09\n",
      "D: [[ 0.0033132   0.03135435  0.01984518  0.00859927  0.00825275  0.03135435\n",
      "   0.00114806  0.00434425  0.00868626  0.00970608  0.00785826  0.00114806\n",
      "   0.00370433  0.00468752  0.0038756   0.00614992  0.00172903  0.01984518\n",
      "   0.00100077  0.00510929  0.0051517   0.00859927  0.02818721  0.00720803\n",
      "   0.00434299  0.0051517   0.00162874  0.00370433  0.00342067  0.00707023\n",
      "   0.00434684  0.00162874  0.02832472  0.00162874  0.0027042   0.02196783\n",
      "   0.02832472  0.00362862  0.00868626  0.00162874  0.00434299  0.00191011\n",
      "   0.00825275  0.00434299  0.00370433  0.00263742  0.0038756   0.03135435\n",
      "   0.01183491  0.00162874  0.00434425  0.0038756   0.01780268  0.0051517\n",
      "   0.00434299  0.01831139  0.00931955  0.00707023  0.00510929  0.01984518\n",
      "   0.01984518  0.00510929  0.00931955  0.00931955  0.03398064  0.0051517\n",
      "   0.0023027   0.00434299  0.01984518  0.01448588  0.00162874  0.02404211\n",
      "   0.00859927  0.00510929  0.00510929  0.0147682   0.00510929  0.0033132\n",
      "   0.00825275  0.03135435  0.01183491  0.00510929  0.01984518  0.0147816\n",
      "   0.01984518  0.03398064  0.00263742  0.00785826  0.00825275  0.01831139\n",
      "   0.01780268  0.00825275  0.01780268  0.00510929  0.0038756   0.01162029\n",
      "   0.00785826  0.01304229  0.00859927  0.00448815]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1.  1. -1.  1. -1.  1. -1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1.  1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.]]\n",
      "current error:   0.09\n",
      "D: [[ 0.00374721  0.02809975  0.02244481  0.00770666  0.00739611  0.02809975\n",
      "   0.00129845  0.00389331  0.00982413  0.01097754  0.00704256  0.00129845\n",
      "   0.00418958  0.00530157  0.00347331  0.00695554  0.00195553  0.02244481\n",
      "   0.00089689  0.00577858  0.00461695  0.00770666  0.02526136  0.00645983\n",
      "   0.00389218  0.00461695  0.0018421   0.00418958  0.00386877  0.0079964\n",
      "   0.00491626  0.0018421   0.03203513  0.0018421   0.00305844  0.01968756\n",
      "   0.03203513  0.00325197  0.00778462  0.0018421   0.00389218  0.00171184\n",
      "   0.00739611  0.00389218  0.00418958  0.00298291  0.00347331  0.02809975\n",
      "   0.01060644  0.0018421   0.00389331  0.00347331  0.01595475  0.00461695\n",
      "   0.00389218  0.01641065  0.01054037  0.0079964   0.00577858  0.02244481\n",
      "   0.02244481  0.00577858  0.01054037  0.01054037  0.03843196  0.00582655\n",
      "   0.00260435  0.00389218  0.02244481  0.01298223  0.0018421   0.02154652\n",
      "   0.00770666  0.00577858  0.00577858  0.01323525  0.00577858  0.00374721\n",
      "   0.00739611  0.02809975  0.01060644  0.00577858  0.02244481  0.01324726\n",
      "   0.02244481  0.03843196  0.00298291  0.00704256  0.00739611  0.01641065\n",
      "   0.01595475  0.00739611  0.01595475  0.00577858  0.00347331  0.0131425\n",
      "   0.00704256  0.01168849  0.00770666  0.00402228]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1.  1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1. -1.\n",
      "   1. -1. -1.  1. -1. -1.  1. -1. -1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1.\n",
      "   1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1. -1. -1.  1. -1.]]\n",
      "current error:   0.08\n",
      "D: [[ 0.00335571  0.03181111  0.02009979  0.00872454  0.00837297  0.03181111\n",
      "   0.00116279  0.00440754  0.00879771  0.00983061  0.00630676  0.00116279\n",
      "   0.00474293  0.00474767  0.00393206  0.00622883  0.00221381  0.02009979\n",
      "   0.00080318  0.00517484  0.00522675  0.00872454  0.02262207  0.00578491\n",
      "   0.00348553  0.00522675  0.00164964  0.00474293  0.00346456  0.00905255\n",
      "   0.00440261  0.00164964  0.02868813  0.00164964  0.0034624   0.02228785\n",
      "   0.02868813  0.00291221  0.00697129  0.00164964  0.00348553  0.00153299\n",
      "   0.00837297  0.00348553  0.00474293  0.00267126  0.00393206  0.03181111\n",
      "   0.01200731  0.00164964  0.00440754  0.00393206  0.01806202  0.00522675\n",
      "   0.00348553  0.01857814  0.00943912  0.00905255  0.00517484  0.02009979\n",
      "   0.02009979  0.00517484  0.00943912  0.00943912  0.03441662  0.00659611\n",
      "   0.00233225  0.00348553  0.02009979  0.0146969   0.00164964  0.02439234\n",
      "   0.00872454  0.00517484  0.00517484  0.01185244  0.00517484  0.00335571\n",
      "   0.00837297  0.03181111  0.01200731  0.00517484  0.02009979  0.01499693\n",
      "   0.02009979  0.03441662  0.00267126  0.00630676  0.00837297  0.01857814\n",
      "   0.01806202  0.00837297  0.01806202  0.00517484  0.00393206  0.01487833\n",
      "   0.00630676  0.01046729  0.00872454  0.00455353]]\n",
      "classEstimate:  [[ 1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.\n",
      "   1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.09\n",
      "D: [[ 0.00392732  0.02776935  0.02352359  0.00761604  0.00979923  0.02776935\n",
      "   0.00136086  0.00515832  0.01029631  0.00858158  0.00738106  0.00136086\n",
      "   0.00414031  0.00555638  0.00343247  0.00728985  0.00193253  0.02352359\n",
      "   0.00094     0.00451735  0.00456266  0.00761604  0.02647552  0.00677031\n",
      "   0.00407926  0.00456266  0.00144004  0.00414031  0.00405472  0.00790238\n",
      "   0.00515255  0.00144004  0.03357487  0.00144004  0.00302248  0.01945606\n",
      "   0.03357487  0.00340827  0.00815878  0.00144004  0.00407926  0.00179412\n",
      "   0.00979923  0.00407926  0.00414031  0.00312628  0.00343247  0.02776935\n",
      "   0.01048172  0.00144004  0.00515832  0.00343247  0.01576715  0.00456266\n",
      "   0.00407926  0.02174274  0.00823984  0.00790238  0.00451735  0.02352359\n",
      "   0.02352359  0.00451735  0.00823984  0.00823984  0.03004381  0.00575804\n",
      "   0.00203592  0.00407926  0.02352359  0.01282959  0.00144004  0.02129317\n",
      "   0.00761604  0.00451735  0.00451735  0.01387139  0.00451735  0.00392732\n",
      "   0.00979923  0.02776935  0.01048172  0.00451735  0.02352359  0.01309149\n",
      "   0.02352359  0.03004381  0.00312628  0.00738106  0.00979923  0.02174274\n",
      "   0.01576715  0.00979923  0.01576715  0.00451735  0.00343247  0.01298796\n",
      "   0.00738106  0.01225029  0.00761604  0.00397498]]\n",
      "classEstimate:  [[-1.  1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1.  1. -1. -1.  1.  1. -1.  1.  1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.08\n",
      "D: [[ 0.0034516   0.03220856  0.02067414  0.00669349  0.00861223  0.03220856\n",
      "   0.00119602  0.00453348  0.0090491   0.00995344  0.00648698  0.00119602\n",
      "   0.00480218  0.00488333  0.00301669  0.00640681  0.00224147  0.02067414\n",
      "   0.00082613  0.00523949  0.00529205  0.00669349  0.02326849  0.00595021\n",
      "   0.00358513  0.00529205  0.00167025  0.00480218  0.00356356  0.00916565\n",
      "   0.00452841  0.00167025  0.02950788  0.00167025  0.00350566  0.02256631\n",
      "   0.02950788  0.00299542  0.0071705   0.00167025  0.00358513  0.00157679\n",
      "   0.00861223  0.00358513  0.00480218  0.00274759  0.00301669  0.03220856\n",
      "   0.01215733  0.00167025  0.00453348  0.00301669  0.01828769  0.00529205\n",
      "   0.00358513  0.019109    0.00724173  0.00916565  0.00523949  0.02067414\n",
      "   0.02067414  0.00523949  0.00724173  0.00724173  0.03484662  0.00667852\n",
      "   0.00236138  0.00358513  0.02067414  0.01488053  0.00167025  0.0246971\n",
      "   0.00669349  0.00523949  0.00523949  0.01219112  0.00523949  0.0034516\n",
      "   0.00861223  0.03220856  0.01215733  0.00523949  0.02067414  0.0151843\n",
      "   0.02067414  0.03484662  0.00274759  0.00648698  0.00861223  0.019109\n",
      "   0.01828769  0.00861223  0.01828769  0.00523949  0.00301669  0.01506422\n",
      "   0.00648698  0.01076639  0.00669349  0.00461042]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.09\n",
      "D: [[ 0.00396637  0.0285086   0.02375748  0.00592458  0.0076229   0.0285086\n",
      "   0.00137439  0.0040127   0.01039868  0.00881004  0.00745444  0.00137439\n",
      "   0.00425053  0.00561163  0.00267015  0.00736233  0.00198398  0.02375748\n",
      "   0.00073123  0.00463761  0.00468412  0.00592458  0.02673875  0.00683763\n",
      "   0.00411981  0.00468412  0.00147838  0.00425053  0.00409503  0.00811275\n",
      "   0.00520378  0.00147838  0.03390868  0.00147838  0.00310294  0.01997401\n",
      "   0.03390868  0.00265132  0.0082399   0.00147838  0.00411981  0.00139566\n",
      "   0.0076229   0.00411981  0.00425053  0.00315736  0.00267015  0.0285086\n",
      "   0.01076076  0.00147838  0.0040127   0.00267015  0.01618689  0.00468412\n",
      "   0.00411981  0.01691386  0.00832176  0.00811275  0.00463761  0.02375748\n",
      "   0.02375748  0.00463761  0.00832176  0.00832176  0.04004364  0.00591132\n",
      "   0.00209012  0.00411981  0.02375748  0.01317113  0.00147838  0.02186002\n",
      "   0.00592458  0.00463761  0.00463761  0.01400931  0.00463761  0.00396637\n",
      "   0.0076229   0.0285086   0.01076076  0.00463761  0.02375748  0.01344\n",
      "   0.02375748  0.04004364  0.00315736  0.00745444  0.0076229   0.01691386\n",
      "   0.01618689  0.0076229   0.01618689  0.00463761  0.00267015  0.01333372\n",
      "   0.00745444  0.01237208  0.00592458  0.0040808 ]]\n",
      "classEstimate:  [[-1.  1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1.  1.  1. -1. -1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1.  1. -1.]]\n",
      "current error:   0.08\n",
      "D: [[ 0.00351822  0.03267003  0.02107322  0.0067894   0.00676162  0.03267003\n",
      "   0.0012191   0.00355932  0.00922378  0.01009605  0.0066122   0.0012191\n",
      "   0.00487099  0.00497759  0.00236846  0.00653049  0.00227358  0.02107322\n",
      "   0.00064861  0.00531456  0.00536787  0.0067894   0.02371765  0.00606507\n",
      "   0.00365433  0.00536787  0.00169418  0.00487099  0.00363235  0.00929697\n",
      "   0.00461583  0.00169418  0.03007749  0.00169418  0.00355588  0.02288964\n",
      "   0.03007749  0.00235176  0.00730891  0.00169418  0.00365433  0.00123797\n",
      "   0.00676162  0.00365433  0.00487099  0.00280062  0.00236846  0.03267003\n",
      "   0.01233152  0.00169418  0.00355932  0.00236846  0.01854971  0.00536787\n",
      "   0.00365433  0.01938279  0.00738152  0.00929697  0.00531456  0.02107322\n",
      "   0.02107322  0.00531456  0.00738152  0.00738152  0.03551928  0.00677421\n",
      "   0.00185397  0.00365433  0.02107322  0.01509373  0.00169418  0.02505095\n",
      "   0.0067894   0.00531456  0.00531456  0.01242646  0.00531456  0.00351822\n",
      "   0.00676162  0.03267003  0.01233152  0.00531456  0.02107322  0.01540186\n",
      "   0.02107322  0.03551928  0.00280062  0.0066122   0.00676162  0.01938279\n",
      "   0.01854971  0.00676162  0.01854971  0.00531456  0.00236846  0.01528006\n",
      "   0.0066122   0.01097421  0.0067894   0.00467648]]\n",
      "classEstimate:  [[ 1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.\n",
      "   1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.09\n",
      "D: [[ 0.00405087  0.02887344  0.02426366  0.0060004   0.00778532  0.02887344\n",
      "   0.00140367  0.00409819  0.01062024  0.00892278  0.00761327  0.00140367\n",
      "   0.00430493  0.00573119  0.00209322  0.00751919  0.00200937  0.02426366\n",
      "   0.00074681  0.00469696  0.00474407  0.0060004   0.02730846  0.00698331\n",
      "   0.00420759  0.00474407  0.0014973   0.00430493  0.00418228  0.00821657\n",
      "   0.00531465  0.0014973   0.03463116  0.0014973   0.00314265  0.02022963\n",
      "   0.03463116  0.00270781  0.00841547  0.0014973   0.00420759  0.00142539\n",
      "   0.00778532  0.00420759  0.00430493  0.00322463  0.00209322  0.02887344\n",
      "   0.01089847  0.0014973   0.00409819  0.00209322  0.01639405  0.00474407\n",
      "   0.00420759  0.02231731  0.00652371  0.00821657  0.00469696  0.02426366\n",
      "   0.02426366  0.00469696  0.00652371  0.00652371  0.03139158  0.00598697\n",
      "   0.00163852  0.00420759  0.02426366  0.01333968  0.0014973   0.02213978\n",
      "   0.0060004   0.00469696  0.00469696  0.0143078   0.00469696  0.00405087\n",
      "   0.00778532  0.02887344  0.01089847  0.00469696  0.02426366  0.013612\n",
      "   0.02426366  0.03139158  0.00322463  0.00761327  0.00778532  0.02231731\n",
      "   0.01639405  0.00778532  0.01639405  0.00469696  0.00209322  0.01350436\n",
      "   0.00761327  0.01263569  0.0060004   0.00413302]]\n",
      "classEstimate:  [[-1.  1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1.  1. -1. -1.  1.  1. -1.  1.  1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.08\n",
      "D: [[ 0.00366963  0.03222091  0.02198012  0.00543568  0.00705261  0.03222091\n",
      "   0.00127157  0.0037125   0.00962073  0.00995725  0.00689676  0.00127157\n",
      "   0.00480403  0.00519181  0.00189622  0.00681153  0.00224233  0.02198012\n",
      "   0.00067653  0.0052415   0.00529408  0.00543568  0.02473836  0.00632609\n",
      "   0.0038116   0.00529408  0.00167089  0.00480403  0.00378867  0.00916917\n",
      "   0.00481447  0.00167089  0.0313719   0.00167089  0.003507    0.02257497\n",
      "   0.0313719   0.00245297  0.00762346  0.00167089  0.0038116   0.00129125\n",
      "   0.00705261  0.0038116   0.00480403  0.00292115  0.00189622  0.03222091\n",
      "   0.012162    0.00167089  0.0037125   0.00189622  0.01829471  0.00529408\n",
      "   0.0038116   0.02021694  0.00590974  0.00916917  0.0052415   0.02198012\n",
      "   0.02198012  0.0052415   0.00590974  0.00590974  0.03503099  0.00668108\n",
      "   0.00182848  0.0038116   0.02198012  0.01488623  0.00167089  0.02470657\n",
      "   0.00543568  0.0052415   0.0052415   0.01296124  0.0052415   0.00366963\n",
      "   0.00705261  0.03222091  0.012162    0.0052415   0.02198012  0.01519013\n",
      "   0.02198012  0.03503099  0.00292115  0.00689676  0.00705261  0.02021694\n",
      "   0.01829471  0.00705261  0.01829471  0.0052415   0.00189622  0.01507\n",
      "   0.00689676  0.0114465   0.00543568  0.00461219]]\n",
      "classEstimate:  [[ 1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.09\n",
      "D: [[ 0.00409054  0.03591664  0.02450124  0.00605915  0.00786154  0.02921479\n",
      "   0.00141742  0.00413832  0.01072423  0.00902827  0.00768781  0.00141742\n",
      "   0.00435582  0.00578731  0.00211371  0.00759281  0.00203313  0.01992944\n",
      "   0.00075412  0.00475248  0.00480016  0.00605915  0.02757584  0.00705169\n",
      "   0.00424879  0.00480016  0.001515    0.00435582  0.00422323  0.00831371\n",
      "   0.00536669  0.001515    0.03497024  0.001515    0.00317981  0.02046879\n",
      "   0.03497024  0.00273433  0.00849786  0.001515    0.00424879  0.00143935\n",
      "   0.00786154  0.00424879  0.00435582  0.00325621  0.00211371  0.02921479\n",
      "   0.01102731  0.001515    0.00413832  0.00211371  0.01658786  0.00480016\n",
      "   0.00424879  0.02253582  0.00535838  0.00831371  0.00475248  0.02450124\n",
      "   0.01992944  0.00475248  0.00535838  0.00535838  0.03176269  0.00605775\n",
      "   0.00165789  0.00424879  0.01992944  0.01349739  0.001515    0.02240152\n",
      "   0.00605915  0.00475248  0.00475248  0.01444789  0.00475248  0.00409054\n",
      "   0.00786154  0.02921479  0.01102731  0.00475248  0.02450124  0.01377293\n",
      "   0.02450124  0.03176269  0.00325621  0.00768781  0.00786154  0.02253582\n",
      "   0.01658786  0.00786154  0.01658786  0.00475248  0.00211371  0.01366401\n",
      "   0.00768781  0.01275941  0.00605915  0.00418189]]\n",
      "classEstimate:  [[-1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.07\n",
      "D: [[ 0.00372447  0.03270237  0.02230856  0.0055169   0.00715799  0.03239926\n",
      "   0.00129057  0.00376797  0.00976449  0.01001237  0.00699981  0.00129057\n",
      "   0.00483062  0.00526939  0.00192455  0.00691331  0.00225474  0.02210179\n",
      "   0.00068663  0.00527052  0.00532338  0.0055169   0.02510802  0.00642062\n",
      "   0.00386856  0.00532338  0.00168014  0.00483062  0.00384528  0.00921992\n",
      "   0.00488641  0.00168014  0.03184067  0.00168014  0.00352641  0.02269993\n",
      "   0.03184067  0.00248963  0.00773737  0.00168014  0.00386856  0.00131054\n",
      "   0.00715799  0.00386856  0.00483062  0.0029648   0.00192455  0.03239926\n",
      "   0.01222931  0.00168014  0.00376797  0.00192455  0.01839597  0.00532338\n",
      "   0.00386856  0.02051904  0.00594245  0.00921992  0.00527052  0.02230856\n",
      "   0.02210179  0.00527052  0.00594245  0.00594245  0.03522489  0.00671806\n",
      "   0.0018386   0.00386856  0.0181459   0.01496863  0.00168014  0.02484333\n",
      "   0.0055169   0.00527052  0.00527052  0.01315491  0.00527052  0.00372447\n",
      "   0.00715799  0.02660029  0.01222931  0.00527052  0.02230856  0.01527421\n",
      "   0.02230856  0.03522489  0.0029648   0.00699981  0.00715799  0.02051904\n",
      "   0.01839597  0.00715799  0.01839597  0.00527052  0.00192455  0.01515341\n",
      "   0.00699981  0.01161754  0.0055169   0.00463772]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.08\n",
      "D: [[ 0.00409677  0.02997805  0.02453855  0.00505731  0.00656169  0.02970019\n",
      "   0.00141958  0.00345408  0.01074056  0.00917827  0.00769952  0.00141958\n",
      "   0.0044282   0.00579612  0.00176422  0.00760438  0.00206691  0.02431111\n",
      "   0.00062943  0.00483145  0.00487991  0.00505731  0.02761785  0.00706243\n",
      "   0.00425526  0.00487991  0.00154017  0.0044282   0.00422966  0.00845184\n",
      "   0.00537487  0.00154017  0.03502351  0.00154017  0.00323264  0.02080888\n",
      "   0.03502351  0.00228222  0.00851081  0.00154017  0.00425526  0.00120136\n",
      "   0.00656169  0.00425526  0.0044282   0.00326117  0.00176422  0.02970019\n",
      "   0.01121053  0.00154017  0.00345408  0.00176422  0.01686347  0.00487991\n",
      "   0.00425526  0.01880967  0.00653647  0.00845184  0.00483145  0.02453855\n",
      "   0.02431111  0.00483145  0.00653647  0.00653647  0.03874602  0.0061584\n",
      "   0.00168543  0.00425526  0.01995979  0.01372165  0.00154017  0.02277372\n",
      "   0.00505731  0.00483145  0.00483145  0.01446989  0.00483145  0.00409677\n",
      "   0.00656169  0.02438431  0.01121053  0.00483145  0.02453855  0.01400177\n",
      "   0.02453855  0.03874602  0.00326117  0.00769952  0.00656169  0.01880967\n",
      "   0.01686347  0.00656169  0.01686347  0.00483145  0.00176422  0.01389104\n",
      "   0.00769952  0.01277884  0.00505731  0.00425137]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1.  1. -1.  1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1.  1. -1. -1.\n",
      "   1.  1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1.  1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1.\n",
      "   1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1. -1.]]\n",
      "current error:   0.08\n",
      "D: [[ 0.00363467  0.03434443  0.02177074  0.00579392  0.00751741  0.03402609\n",
      "   0.00125945  0.00395717  0.00952908  0.01051511  0.00683106  0.00125945\n",
      "   0.00507317  0.00514235  0.00202119  0.00674665  0.00236796  0.02156895\n",
      "   0.00055844  0.00428649  0.00559068  0.00579392  0.0245027   0.00626582\n",
      "   0.00377529  0.00559068  0.00136645  0.00392872  0.00375258  0.00968287\n",
      "   0.00476861  0.0017645   0.03107304  0.00136645  0.00370348  0.02383974\n",
      "   0.03107304  0.00261463  0.00755083  0.0017645   0.00377529  0.00106586\n",
      "   0.00751741  0.00377529  0.00507317  0.00289332  0.00202119  0.03402609\n",
      "   0.01284337  0.0017645   0.00395717  0.00202119  0.01931967  0.00559068\n",
      "   0.00377529  0.02154934  0.00579919  0.00968287  0.00428649  0.02177074\n",
      "   0.02156895  0.00428649  0.00579919  0.00579919  0.03437568  0.00705539\n",
      "   0.00149533  0.00377529  0.01770843  0.01572024  0.0017645   0.02609076\n",
      "   0.00579392  0.00428649  0.00428649  0.01283777  0.00428649  0.00363467\n",
      "   0.00751741  0.02793594  0.01284337  0.00428649  0.02177074  0.01604115\n",
      "   0.02177074  0.03437568  0.00289332  0.00683106  0.00751741  0.02154934\n",
      "   0.01931967  0.00751741  0.01931967  0.00428649  0.00202119  0.0123242\n",
      "   0.00683106  0.01133746  0.00579392  0.00487059]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1.  1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1.  1.  1. -1.  1.]]\n",
      "current error:   0.07\n",
      "D: [[ 0.00413269  0.03065079  0.02475374  0.0051708   0.00670894  0.03036669\n",
      "   0.00143202  0.00353159  0.01083475  0.01195588  0.00776704  0.00143202\n",
      "   0.00452757  0.00584695  0.00180382  0.00767106  0.00211329  0.0245243\n",
      "   0.00049838  0.00487382  0.00498942  0.0051708   0.02186751  0.00559195\n",
      "   0.00336927  0.00498942  0.00121949  0.0035062   0.00426675  0.00864151\n",
      "   0.005422    0.00157474  0.03533063  0.00121949  0.00330518  0.02127584\n",
      "   0.03533063  0.00233344  0.00858544  0.00157474  0.00336927  0.00095123\n",
      "   0.00670894  0.00336927  0.00452757  0.00328976  0.00180382  0.03036669\n",
      "   0.01146211  0.00157474  0.00353159  0.00180382  0.0172419   0.00498942\n",
      "   0.00336927  0.01923177  0.00659379  0.00864151  0.00487382  0.02475374\n",
      "   0.0245243   0.00487382  0.00659379  0.00659379  0.03908579  0.0062966\n",
      "   0.00170021  0.00336927  0.02013482  0.01402957  0.00157474  0.02328478\n",
      "   0.0051708   0.00487382  0.00487382  0.0114571   0.00487382  0.00413269\n",
      "   0.00670894  0.02493152  0.01146211  0.00487382  0.02475374  0.01431598\n",
      "   0.02475374  0.03908579  0.00328976  0.00776704  0.00670894  0.01923177\n",
      "   0.0172419   0.00670894  0.0172419   0.00487382  0.00180382  0.01401285\n",
      "   0.00776704  0.0128909   0.0051708   0.00434677]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1. -1. -1.  1.\n",
      "   1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1.  1.]]\n",
      "current error:   0.08\n",
      "D: [[ 0.0036629   0.03516034  0.02193981  0.00593156  0.007696    0.03483444\n",
      "   0.00126924  0.00405118  0.01242883  0.01059677  0.00688411  0.00126924\n",
      "   0.00401289  0.00518229  0.00206921  0.00679904  0.00242421  0.02173645\n",
      "   0.0005717   0.00431978  0.0057235   0.00593156  0.02508481  0.00641468\n",
      "   0.00386498  0.0057235   0.00108086  0.00310762  0.00378172  0.00765917\n",
      "   0.00480564  0.00139572  0.03131436  0.00108086  0.00292946  0.02440609\n",
      "   0.03131436  0.00267675  0.00984859  0.00139572  0.00386498  0.00109118\n",
      "   0.007696    0.00386498  0.00401289  0.00291579  0.00206921  0.03483444\n",
      "   0.01314849  0.00139572  0.00405118  0.00206921  0.01977865  0.0057235\n",
      "   0.00386498  0.02206128  0.00584423  0.00765917  0.00431978  0.02193981\n",
      "   0.02173645  0.00431978  0.00584423  0.00584423  0.03464264  0.007223\n",
      "   0.00150694  0.00386498  0.01784596  0.01243473  0.00139572  0.02063784\n",
      "   0.00593156  0.00431978  0.00431978  0.01314275  0.00431978  0.0036629\n",
      "   0.007696    0.02859961  0.01314849  0.00431978  0.02193981  0.01642224\n",
      "   0.02193981  0.03464264  0.00291579  0.00688411  0.007696    0.02206128\n",
      "   0.01977865  0.007696    0.01977865  0.00431978  0.00206921  0.01241991\n",
      "   0.00688411  0.0114255   0.00593156  0.00385264]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classEstimate:  [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.07\n",
      "D: [[ 0.00331833  0.03185274  0.02448203  0.00537357  0.00697203  0.0315575\n",
      "   0.00114984  0.00367008  0.01125963  0.01182465  0.00623651  0.00114984\n",
      "   0.00447787  0.00469478  0.00187455  0.00615944  0.00219616  0.02425511\n",
      "   0.00051792  0.00482032  0.00518508  0.00537357  0.02272503  0.00581124\n",
      "   0.00350139  0.00518508  0.00120611  0.00346771  0.00342597  0.00854665\n",
      "   0.00435357  0.00155745  0.03494283  0.00120611  0.0032689   0.02211017\n",
      "   0.03494283  0.00242494  0.00892211  0.00155745  0.00350139  0.00098853\n",
      "   0.00697203  0.00350139  0.00447787  0.0026415   0.00187455  0.0315575\n",
      "   0.01191159  0.00155745  0.00367008  0.00187455  0.01791803  0.00518508\n",
      "   0.00350139  0.01998594  0.00652141  0.00854665  0.00482032  0.02448203\n",
      "   0.02425511  0.00482032  0.00652141  0.00652141  0.03865677  0.00654352\n",
      "   0.00168155  0.00350139  0.01991381  0.01387558  0.00155745  0.0230292\n",
      "   0.00537357  0.00482032  0.00482032  0.01190639  0.00482032  0.00331833\n",
      "   0.00697203  0.02590919  0.01191159  0.00482032  0.02448203  0.01832513\n",
      "   0.02448203  0.03865677  0.0026415   0.00623651  0.00697203  0.01998594\n",
      "   0.01791803  0.00697203  0.01791803  0.00482032  0.00187455  0.01385904\n",
      "   0.00623651  0.01035069  0.00537357  0.00429906]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.08\n",
      "D: [[ 0.00296571  0.03615107  0.02188046  0.0060987   0.00791286  0.03581599\n",
      "   0.001305    0.00416533  0.01277904  0.01056811  0.00707809  0.001305\n",
      "   0.00400203  0.00419589  0.00212751  0.00699062  0.00196279  0.02167766\n",
      "   0.00058781  0.00430809  0.00463409  0.0060987   0.02579163  0.00659543\n",
      "   0.00397389  0.00463409  0.00107794  0.00309922  0.00388828  0.00763845\n",
      "   0.00494105  0.00139195  0.03122965  0.00107794  0.00292154  0.02509379\n",
      "   0.03122965  0.00275217  0.0101261   0.00139195  0.00397389  0.00112192\n",
      "   0.00791286  0.00397389  0.00400203  0.00299795  0.00212751  0.03581599\n",
      "   0.01064581  0.00139195  0.00416533  0.00212751  0.02033596  0.00463409\n",
      "   0.00397389  0.02268291  0.00582842  0.00763845  0.00430809  0.02188046\n",
      "   0.02167766  0.00430809  0.00582842  0.00582842  0.03454893  0.00584818\n",
      "   0.00150286  0.00397389  0.01779769  0.0124011   0.00139195  0.02058202\n",
      "   0.0060987   0.00430809  0.00430809  0.01351308  0.00430809  0.00296571\n",
      "   0.00791286  0.02940548  0.01064581  0.00430809  0.02188046  0.01637782\n",
      "   0.02188046  0.03454893  0.00299795  0.00707809  0.00791286  0.02268291\n",
      "   0.02033596  0.00791286  0.02033596  0.00430809  0.00212751  0.01238632\n",
      "   0.00707809  0.01174745  0.0060987   0.00384222]]\n",
      "classEstimate:  [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.00266395  0.03247276  0.02467555  0.00547817  0.00710774  0.03217178\n",
      "   0.00117222  0.00374152  0.0114788   0.01191812  0.0063579   0.00117222\n",
      "   0.00451327  0.00376897  0.00191104  0.00627934  0.00221352  0.02444684\n",
      "   0.000528    0.00485842  0.00522606  0.00547817  0.02316738  0.00592436\n",
      "   0.00356955  0.00522606  0.00121564  0.00349512  0.00349265  0.00861421\n",
      "   0.00443831  0.00156976  0.02805209  0.00121564  0.00329474  0.02254054\n",
      "   0.03521904  0.00247214  0.00909578  0.00156976  0.00356955  0.00100777\n",
      "   0.00710774  0.00356955  0.00451327  0.00269292  0.00191104  0.03217178\n",
      "   0.00956262  0.00156976  0.00374152  0.00191104  0.01826681  0.00416258\n",
      "   0.00356955  0.02037497  0.00657296  0.00861421  0.00485842  0.02467555\n",
      "   0.02444684  0.00485842  0.00657296  0.00657296  0.03896234  0.00659525\n",
      "   0.00169484  0.00356955  0.02007123  0.01398526  0.00156976  0.02321124\n",
      "   0.00547817  0.00485842  0.00485842  0.01213815  0.00485842  0.00266395\n",
      "   0.00710774  0.02641352  0.01200575  0.00485842  0.02467555  0.01846998\n",
      "   0.02467555  0.03896234  0.00269292  0.0063579   0.00710774  0.02037497\n",
      "   0.01826681  0.00710774  0.01826681  0.00485842  0.00191104  0.01396859\n",
      "   0.0063579   0.01055216  0.00547817  0.00433304]]\n",
      "classEstimate:  [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.08\n",
      "D: [[ 0.00299891  0.03655584  0.02219635  0.00616698  0.00800145  0.03621701\n",
      "   0.00131961  0.00421197  0.01292213  0.01072068  0.00715733  0.00131961\n",
      "   0.00405981  0.00424287  0.00215133  0.00706889  0.00199112  0.02199062\n",
      "   0.00059439  0.00437029  0.00470099  0.00616698  0.02608041  0.00666928\n",
      "   0.00401838  0.00470099  0.0010935   0.00314396  0.00393182  0.00774873\n",
      "   0.00499638  0.00141204  0.03157932  0.0010935   0.00296371  0.02027585\n",
      "   0.03964743  0.00278299  0.01023947  0.00141204  0.00401838  0.00113449\n",
      "   0.00800145  0.00401838  0.00405981  0.00303152  0.00215133  0.03621701\n",
      "   0.00860184  0.00141204  0.00421197  0.00215133  0.0164315   0.00374435\n",
      "   0.00401838  0.02293688  0.00591256  0.00774873  0.00437029  0.02219635\n",
      "   0.02199062  0.00437029  0.00591256  0.00591256  0.03504771  0.00593261\n",
      "   0.00152456  0.00401838  0.01805463  0.01258013  0.00141204  0.02087916\n",
      "   0.00616698  0.00437029  0.00437029  0.01366438  0.00437029  0.00299891\n",
      "   0.00800145  0.02973471  0.0107995   0.00437029  0.02219635  0.01661427\n",
      "   0.02219635  0.03504771  0.00303152  0.00715733  0.00800145  0.02293688\n",
      "   0.0164315   0.00800145  0.0164315   0.00437029  0.00215133  0.01256514\n",
      "   0.00715733  0.01187898  0.00616698  0.00389769]]\n",
      "classEstimate:  [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.07\n",
      "D: [[ 0.00272978  0.03327526  0.02462401  0.00561355  0.00728339  0.03296684\n",
      "   0.00120119  0.00383398  0.01176247  0.01189322  0.00651503  0.00120119\n",
      "   0.00450384  0.00386211  0.00195827  0.00643452  0.0022089   0.02439577\n",
      "   0.00054105  0.00484827  0.00521515  0.00561355  0.02373992  0.00607077\n",
      "   0.00365776  0.00521515  0.0012131   0.00348782  0.00357897  0.00859622\n",
      "   0.00454799  0.00156648  0.02874534  0.0012131   0.00328786  0.02249346\n",
      "   0.03608941  0.00253324  0.00932057  0.00156648  0.00365776  0.00103268\n",
      "   0.00728339  0.00365776  0.00450384  0.00275947  0.00195827  0.03296684\n",
      "   0.00954264  0.00156648  0.00383398  0.00195827  0.01495692  0.00415388\n",
      "   0.00365776  0.02087849  0.00655923  0.00859622  0.00484827  0.02462401\n",
      "   0.02439577  0.00484827  0.00655923  0.00655923  0.03888095  0.00658147\n",
      "   0.0016913   0.00365776  0.0200293   0.01395605  0.00156648  0.02316275\n",
      "   0.00561355  0.00484827  0.00484827  0.01243812  0.00484827  0.00272978\n",
      "   0.00728339  0.02706628  0.01198067  0.00484827  0.02462401  0.0184314\n",
      "   0.02462401  0.03888095  0.00275947  0.00651503  0.00728339  0.02087849\n",
      "   0.01495692  0.00728339  0.01495692  0.00484827  0.00195827  0.01393941\n",
      "   0.00651503  0.01081294  0.00561355  0.00432399]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.07\n",
      "D: [[ 0.00247107  0.03716651  0.02229027  0.00627     0.00813512  0.03682202\n",
      "   0.00134166  0.00428233  0.01313799  0.01076604  0.0072769   0.00134166\n",
      "   0.00407699  0.00431375  0.00218727  0.00718698  0.00199955  0.02208366\n",
      "   0.00060432  0.00438878  0.00472088  0.00627     0.02651609  0.00678069\n",
      "   0.00408551  0.00472088  0.00109813  0.00315726  0.0039975   0.00778151\n",
      "   0.00411696  0.00141802  0.026021    0.00109813  0.00297625  0.02512387\n",
      "   0.03266904  0.00282948  0.01041053  0.00141802  0.00408551  0.00115344\n",
      "   0.00813512  0.00408551  0.00407699  0.00308216  0.00218727  0.03682202\n",
      "   0.00863824  0.00141802  0.00428233  0.00218727  0.016706    0.0037602\n",
      "   0.00408551  0.02332005  0.00593758  0.00778151  0.00438878  0.02229027\n",
      "   0.02208366  0.00438878  0.00593758  0.00593758  0.03519601  0.00595771\n",
      "   0.00153101  0.00408551  0.01813102  0.01263336  0.00141802  0.0209675\n",
      "   0.00627     0.00438878  0.00438878  0.01389265  0.00438878  0.00247107\n",
      "   0.00813512  0.03023144  0.0108452   0.00438878  0.02229027  0.01668456\n",
      "   0.02229027  0.03519601  0.00308216  0.0072769   0.00813512  0.02332005\n",
      "   0.016706    0.00813512  0.016706    0.00438878  0.00218727  0.0126183\n",
      "   0.0072769   0.01207742  0.00627     0.00391419]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.]]\n",
      "current error:   0.07\n",
      "D: [[ 0.00276231  0.03362165  0.02491741  0.00567199  0.00735921  0.03331002\n",
      "   0.00121369  0.00387389  0.01188492  0.01203493  0.00658285  0.00121369\n",
      "   0.0045575   0.00482217  0.00197865  0.00803404  0.00180884  0.02468645\n",
      "   0.00054668  0.00490604  0.00427061  0.00567199  0.02398704  0.00613396\n",
      "   0.00369584  0.00427061  0.00122756  0.00352938  0.00361623  0.00869864\n",
      "   0.00460218  0.00158515  0.02908785  0.00122756  0.00269239  0.02272761\n",
      "   0.03651942  0.00255961  0.00941759  0.00158515  0.00369584  0.00104343\n",
      "   0.00735921  0.00369584  0.0045575   0.00278819  0.00197865  0.03331002\n",
      "   0.00781434  0.00158515  0.00387389  0.00197865  0.01511261  0.00340156\n",
      "   0.00369584  0.02109583  0.00663739  0.00869864  0.00490604  0.02491741\n",
      "   0.02468645  0.00490604  0.00663739  0.00663739  0.03934422  0.00538948\n",
      "   0.00171146  0.00369584  0.02026795  0.01412233  0.00158515  0.02343874\n",
      "   0.00567199  0.00490604  0.00490604  0.0125676   0.00490604  0.00276231\n",
      "   0.00735921  0.02734803  0.00981081  0.00490604  0.02491741  0.01509323\n",
      "   0.02491741  0.03934422  0.00278819  0.00658285  0.00735921  0.02109583\n",
      "   0.01511261  0.00735921  0.01511261  0.00490604  0.00197865  0.0141055\n",
      "   0.00658285  0.0109255   0.00567199  0.00354086]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1.\n",
      "   1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.07\n",
      "D: [[ 0.00250009  0.03756119  0.02255207  0.00633659  0.00822151  0.03721304\n",
      "   0.00109848  0.0043278   0.01075672  0.01089249  0.00735417  0.00109848\n",
      "   0.00412487  0.00436442  0.0022105   0.00727139  0.00163713  0.02234304\n",
      "   0.00061074  0.00444032  0.00477101  0.00633659  0.02679767  0.00685269\n",
      "   0.00412889  0.00477101  0.00111103  0.00319435  0.00403995  0.00787291\n",
      "   0.00416531  0.00143467  0.02632663  0.00111103  0.00243681  0.02539066\n",
      "   0.03305275  0.00285953  0.00852361  0.00143467  0.00412889  0.00116569\n",
      "   0.00822151  0.00412889  0.00412487  0.00252352  0.0022105   0.03721304\n",
      "   0.00872997  0.00143467  0.0043278   0.0022105   0.0168834   0.00380013\n",
      "   0.00412889  0.02356769  0.00600732  0.00787291  0.00444032  0.02255207\n",
      "   0.02234304  0.00444032  0.00600732  0.00600732  0.03560939  0.00602098\n",
      "   0.00154899  0.00412889  0.01834398  0.01278174  0.00143467  0.02121377\n",
      "   0.00633659  0.00444032  0.00444032  0.01404018  0.00444032  0.00250009\n",
      "   0.00822151  0.03055247  0.01096037  0.00444032  0.02255207  0.01366047\n",
      "   0.02255207  0.03560939  0.00252352  0.00735417  0.00822151  0.02356769\n",
      "   0.0168834   0.00822151  0.0168834   0.00444032  0.0022105   0.01276651\n",
      "   0.00735417  0.01220567  0.00633659  0.00320474]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1.  1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1.  1.  1. -1.  1.]]\n",
      "current error:   0.07\n",
      "D: [[ 0.0027889   0.03403655  0.02515721  0.00574198  0.00745002  0.03372107\n",
      "   0.00122537  0.0039217   0.0119993   0.01215075  0.0082037   0.00122537\n",
      "   0.00373781  0.00486858  0.00200307  0.00811136  0.00148351  0.02492403\n",
      "   0.00055343  0.00495326  0.00432331  0.00574198  0.02428305  0.00620966\n",
      "   0.00374145  0.00432331  0.00100677  0.0028946   0.00450663  0.00713414\n",
      "   0.00464648  0.00130005  0.02936779  0.00100677  0.00220814  0.02300807\n",
      "   0.03687089  0.0025912   0.00950823  0.00130005  0.00374145  0.0010563\n",
      "   0.00745002  0.00374145  0.00373781  0.00281503  0.00200307  0.03372107\n",
      "   0.00791077  0.00130005  0.0039217   0.00200307  0.01529911  0.00344353\n",
      "   0.00374145  0.02135617  0.00670126  0.00713414  0.00495326  0.02515721\n",
      "   0.02492403  0.00495326  0.00670126  0.00670126  0.03972287  0.00545598\n",
      "   0.00172793  0.00374145  0.02046301  0.01158234  0.00130005  0.01922313\n",
      "   0.00574198  0.00495326  0.00495326  0.01272269  0.00495326  0.0027889\n",
      "   0.00745002  0.02768552  0.00993188  0.00495326  0.02515721  0.01237861\n",
      "   0.02515721  0.03972287  0.00281503  0.0082037   0.00745002  0.02135617\n",
      "   0.01529911  0.00745002  0.01529911  0.00495326  0.00200307  0.01424125\n",
      "   0.0082037   0.01361563  0.00574198  0.00290401]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1.  1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1.\n",
      "   1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1. -1.]]\n",
      "current error:   0.07\n",
      "D: [[ 0.00249354  0.0386099   0.02249292  0.0065135   0.00845105  0.03825203\n",
      "   0.0010956   0.00350637  0.01072851  0.0137834   0.00733489  0.0010956\n",
      "   0.00424004  0.00435297  0.00227221  0.00725232  0.00168284  0.02228444\n",
      "   0.00049482  0.00442868  0.00490422  0.0065135   0.02171134  0.00555202\n",
      "   0.00334521  0.00490422  0.00114205  0.00328353  0.00402935  0.00809272\n",
      "   0.00415439  0.00147473  0.02625758  0.00114205  0.00250484  0.02609957\n",
      "   0.03296606  0.00293936  0.00850125  0.00147473  0.00334521  0.00094443\n",
      "   0.00845105  0.00334521  0.00424004  0.0025169   0.00227221  0.03825203\n",
      "   0.00897371  0.00147473  0.00350637  0.00227221  0.01735478  0.00390623\n",
      "   0.00334521  0.0242257   0.00599156  0.00809272  0.00442868  0.02249292\n",
      "   0.02228444  0.00442868  0.00599156  0.00599156  0.035516    0.00618908\n",
      "   0.00154493  0.00334521  0.01829586  0.01313861  0.00147473  0.02180606\n",
      "   0.0065135   0.00442868  0.00442868  0.01137528  0.00442868  0.00249354\n",
      "   0.00845105  0.0314055   0.01126638  0.00442868  0.02249292  0.01404187\n",
      "   0.02249292  0.035516    0.0025169   0.00733489  0.00845105  0.0242257\n",
      "   0.01735478  0.00845105  0.01735478  0.00442868  0.00227221  0.01273303\n",
      "   0.00733489  0.01217366  0.0065135   0.00329421]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.07\n",
      "D: [[ 0.00282176  0.0345868   0.02545366  0.00583481  0.00757046  0.03426622\n",
      "   0.00123981  0.00314101  0.0121407   0.01234719  0.00830038  0.00123981\n",
      "   0.00379823  0.00492595  0.00203545  0.00820694  0.00150749  0.02521774\n",
      "   0.00044326  0.00396722  0.00439321  0.00583481  0.0245692   0.00628283\n",
      "   0.00378554  0.00439321  0.00102305  0.00294139  0.00455973  0.00724947\n",
      "   0.00470123  0.00132107  0.02971386  0.00102305  0.00224384  0.02338003\n",
      "   0.03730537  0.00263309  0.00962027  0.00132107  0.00378554  0.00084602\n",
      "   0.00757046  0.00378554  0.00379823  0.0028482   0.00203545  0.03426622\n",
      "   0.00803866  0.00132107  0.00314101  0.00203545  0.01554644  0.0034992\n",
      "   0.00378554  0.02170142  0.00678023  0.00724947  0.00396722  0.02545366\n",
      "   0.02521774  0.00396722  0.00678023  0.00678023  0.04019096  0.00554419\n",
      "   0.00138395  0.00378554  0.02070415  0.01176959  0.00132107  0.0195339\n",
      "   0.00583481  0.00396722  0.00396722  0.01287261  0.00396722  0.00282176\n",
      "   0.00757046  0.02813309  0.01009244  0.00396722  0.02545366  0.01257873\n",
      "   0.02545366  0.04019096  0.0028482   0.00830038  0.00757046  0.02170142\n",
      "   0.01554644  0.00757046  0.01554644  0.00396722  0.00203545  0.01140626\n",
      "   0.00830038  0.01377607  0.00583481  0.00295096]]\n",
      "classEstimate:  [[-1.  1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1.  1.  1. -1. -1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1.  1. -1.]]\n",
      "current error:   0.07\n",
      "D: [[ 0.00253035  0.03908842  0.02282502  0.00659423  0.00678865  0.03872611\n",
      "   0.00111177  0.00281663  0.01088691  0.01395423  0.00744318  0.00111177\n",
      "   0.00429259  0.00441724  0.00182525  0.0073594   0.00170369  0.02261346\n",
      "   0.00039748  0.00448357  0.004965    0.00659423  0.0220319   0.00563399\n",
      "   0.0033946   0.004965    0.0011562   0.00332423  0.00408884  0.00819302\n",
      "   0.00421573  0.00149301  0.02664526  0.0011562   0.00253589  0.02642304\n",
      "   0.03345278  0.00236116  0.00862677  0.00149301  0.0033946   0.00075865\n",
      "   0.00678865  0.0033946   0.00429259  0.00255406  0.00182525  0.03872611\n",
      "   0.00908493  0.00149301  0.00281663  0.00182525  0.01756988  0.00395464\n",
      "   0.0033946   0.02452595  0.00608003  0.00819302  0.00448357  0.02282502\n",
      "   0.02261346  0.00448357  0.00608003  0.00608003  0.03604037  0.00626579\n",
      "   0.00124103  0.0033946   0.01856599  0.01330145  0.00149301  0.02207632\n",
      "   0.00659423  0.00448357  0.00448357  0.01154323  0.00448357  0.00253035\n",
      "   0.00678865  0.03179473  0.01140601  0.00448357  0.02282502  0.01421591\n",
      "   0.02282502  0.03604037  0.00255406  0.00744318  0.00678865  0.02452595\n",
      "   0.01756988  0.00678865  0.01756988  0.00448357  0.00182525  0.01289084\n",
      "   0.00744318  0.0123534   0.00659423  0.00333504]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.00282176  0.03542955  0.02545366  0.00597698  0.0061532   0.03510116\n",
      "   0.00123981  0.00255298  0.0121407   0.01264804  0.00830038  0.00123981\n",
      "   0.00389078  0.00492595  0.0016544   0.00820694  0.00154422  0.02521774\n",
      "   0.00036028  0.00406388  0.00450025  0.00597698  0.0245692   0.00628283\n",
      "   0.00378554  0.00450025  0.00104798  0.00301306  0.00455973  0.00742611\n",
      "   0.00470123  0.00135325  0.02971386  0.00104798  0.00229851  0.02394971\n",
      "   0.03730537  0.00214015  0.00962027  0.00135325  0.00378554  0.00068764\n",
      "   0.0061532   0.00378554  0.00389078  0.0028482   0.0016544   0.03510116\n",
      "   0.00823453  0.00135325  0.00255298  0.0016544   0.01592525  0.00358447\n",
      "   0.00378554  0.0222302   0.00678023  0.00742611  0.00406388  0.02545366\n",
      "   0.02521774  0.00406388  0.00678023  0.00678023  0.04019096  0.00567928\n",
      "   0.00112486  0.00378554  0.02070415  0.01205637  0.00135325  0.02000987\n",
      "   0.00597698  0.00406388  0.00406388  0.01287261  0.00406388  0.00282176\n",
      "   0.0061532   0.02881859  0.01033835  0.00406388  0.02545366  0.01288523\n",
      "   0.02545366  0.04019096  0.0028482   0.00830038  0.0061532   0.0222302\n",
      "   0.01592525  0.0061532   0.01592525  0.00406388  0.0016544   0.01168419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0.00830038  0.01377607  0.00597698  0.00302286]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1.  1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1. -1.\n",
      "   1. -1. -1.  1. -1. -1.  1. -1. -1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1.\n",
      "   1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1. -1. -1.  1. -1.]]\n",
      "current error:   0.07\n",
      "D: [[ 0.00253308  0.03998649  0.02284967  0.00674574  0.00694462  0.03961586\n",
      "   0.00111297  0.00288134  0.01089867  0.0113541   0.00745122  0.00111297\n",
      "   0.00439121  0.00442201  0.00186718  0.00736734  0.00174284  0.02263788\n",
      "   0.00032342  0.00364813  0.00507907  0.00674574  0.02205569  0.00564008\n",
      "   0.00339826  0.00507907  0.00094076  0.0034006   0.00409326  0.00838126\n",
      "   0.00422028  0.00121481  0.02667403  0.00094076  0.00259415  0.02703012\n",
      "   0.03348891  0.0019212   0.00863609  0.00121481  0.00339826  0.00061729\n",
      "   0.00694462  0.00339826  0.00439121  0.00255682  0.00186718  0.03961586\n",
      "   0.00929366  0.00121481  0.00288134  0.00186718  0.01797355  0.0040455\n",
      "   0.00339826  0.02508944  0.00608659  0.00838126  0.00364813  0.02284967\n",
      "   0.02263788  0.00364813  0.00608659  0.00608659  0.03607929  0.00640975\n",
      "   0.00100978  0.00339826  0.01858604  0.01360705  0.00121481  0.02258353\n",
      "   0.00674574  0.00364813  0.00364813  0.0115557   0.00364813  0.00253308\n",
      "   0.00694462  0.03252523  0.01166807  0.00364813  0.02284967  0.01454252\n",
      "   0.02284967  0.03607929  0.00255682  0.00745122  0.00694462  0.02508944\n",
      "   0.01797355  0.00694462  0.01797355  0.00364813  0.00186718  0.01318701\n",
      "   0.00745122  0.01236674  0.00674574  0.00341166]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1.  1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1.  1.  1. -1.  1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.00283126  0.03617649  0.0255394   0.00610299  0.00628292  0.03584118\n",
      "   0.00124399  0.0026068   0.01218159  0.01269064  0.00832833  0.00124399\n",
      "   0.00397281  0.00494254  0.00168927  0.00823459  0.00157678  0.02530268\n",
      "   0.0002926   0.00407757  0.00459513  0.00610299  0.01995418  0.00510268\n",
      "   0.00307447  0.00459513  0.00085113  0.00307659  0.00457509  0.00758267\n",
      "   0.00471706  0.00109906  0.02981394  0.00085113  0.00234697  0.02445463\n",
      "   0.03743103  0.00173815  0.00965268  0.00109906  0.00307447  0.00055848\n",
      "   0.00628292  0.00307447  0.00397281  0.00285779  0.00168927  0.03584118\n",
      "   0.00840814  0.00109906  0.0026068   0.00168927  0.01626099  0.00366004\n",
      "   0.00307447  0.02269887  0.00680307  0.00758267  0.00407757  0.0255394\n",
      "   0.02530268  0.00407757  0.00680307  0.00680307  0.04032634  0.00579901\n",
      "   0.00112865  0.00307447  0.02077388  0.01231054  0.00109906  0.02043172\n",
      "   0.00610299  0.00407757  0.00407757  0.01045465  0.00407757  0.00283126\n",
      "   0.00628292  0.02942615  0.01055631  0.00407757  0.0255394   0.01315688\n",
      "   0.0255394   0.04032634  0.00285779  0.00832833  0.00628292  0.02269887\n",
      "   0.01626099  0.00628292  0.01626099  0.00407757  0.00168927  0.01473931\n",
      "   0.00832833  0.01382248  0.00610299  0.00308659]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1.  1. -1.  1. -1. -1.  1.\n",
      "   1.  1. -1.  1.  1. -1. -1. -1.  1.  1. -1.  1. -1.  1. -1.  1. -1. -1.\n",
      "   1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1. -1.]]\n",
      "current error:   0.07\n",
      "D: [[ 0.00256102  0.04044426  0.02310166  0.00682296  0.00702412  0.04006939\n",
      "   0.00112525  0.00291433  0.01101886  0.01147932  0.00753339  0.00112525\n",
      "   0.00359361  0.00447078  0.00188856  0.00744859  0.00176279  0.02288754\n",
      "   0.00032712  0.00368837  0.00513722  0.00682296  0.02230819  0.00461563\n",
      "   0.00278101  0.00513722  0.00076989  0.00278293  0.0041384   0.00685891\n",
      "   0.00426682  0.00099416  0.0269682   0.00076989  0.00262385  0.02733956\n",
      "   0.03385824  0.0019432   0.00873133  0.00099416  0.00278101  0.00062436\n",
      "   0.00702412  0.00278101  0.00359361  0.00258502  0.00188856  0.04006939\n",
      "   0.00940005  0.00099416  0.00291433  0.00188856  0.01817931  0.00409181\n",
      "   0.00278101  0.02537667  0.00615372  0.00685891  0.00368837  0.02310166\n",
      "   0.02288754  0.00368837  0.00615372  0.00615372  0.03647719  0.00648313\n",
      "   0.00102092  0.00278101  0.01879102  0.01376283  0.00099416  0.02284207\n",
      "   0.00682296  0.00368837  0.00368837  0.01168799  0.00368837  0.00256102\n",
      "   0.00702412  0.03289758  0.01180165  0.00368837  0.02310166  0.01470901\n",
      "   0.02310166  0.03647719  0.00258502  0.00753339  0.00702412  0.02537667\n",
      "   0.01817931  0.00702412  0.01817931  0.00368837  0.00188856  0.01333244\n",
      "   0.00753339  0.01250312  0.00682296  0.00345072]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1.  1. -1.  1. -1.  1. -1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1.  1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.002855    0.03666847  0.02575353  0.00618598  0.00636837  0.03632859\n",
      "   0.00125442  0.00264225  0.01228373  0.01279705  0.00683009  0.00125442\n",
      "   0.00400612  0.00498398  0.00171225  0.00830363  0.00196514  0.02551483\n",
      "   0.00029658  0.00411176  0.00465762  0.00618598  0.02022554  0.00418472\n",
      "   0.00252138  0.00465762  0.00085826  0.00310238  0.00461345  0.00764625\n",
      "   0.00475661  0.00110828  0.03006392  0.00085826  0.00292504  0.0247872\n",
      "   0.03774487  0.00176178  0.00791619  0.00110828  0.00252138  0.00056607\n",
      "   0.00636837  0.00252138  0.00400612  0.00288175  0.00171225  0.03632859\n",
      "   0.00852248  0.00110828  0.00264225  0.00171225  0.01648213  0.00370981\n",
      "   0.00252138  0.02300755  0.00686011  0.00764625  0.00411176  0.02575353\n",
      "   0.02551483  0.00411176  0.00686011  0.00686011  0.04066445  0.00722733\n",
      "   0.00113811  0.00252138  0.02094806  0.01247796  0.00110828  0.02070958\n",
      "   0.00618598  0.00411176  0.00411176  0.01059682  0.00411176  0.002855\n",
      "   0.00636837  0.02982633  0.01069987  0.00411176  0.02575353  0.0133358\n",
      "   0.02575353  0.04066445  0.00288175  0.00683009  0.00636837  0.02300755\n",
      "   0.01648213  0.00636837  0.01648213  0.00411176  0.00171225  0.01486289\n",
      "   0.00683009  0.01133585  0.00618598  0.00312857]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1. -1. -1.  1.\n",
      "   1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1.  1.]]\n",
      "current error:   0.07\n",
      "D: [[ 0.00261129  0.0404431   0.02355509  0.00682277  0.00702392  0.04006824\n",
      "   0.00114733  0.00291425  0.01354821  0.01170463  0.00624704  0.00114733\n",
      "   0.00366414  0.00455852  0.00188851  0.00759479  0.00216743  0.02333676\n",
      "   0.00032711  0.00376076  0.00513707  0.00682277  0.02230755  0.00461549\n",
      "   0.00278093  0.00513707  0.000785    0.00283755  0.00421963  0.00699353\n",
      "   0.00435057  0.00101367  0.02749752  0.000785    0.00267535  0.02733878\n",
      "   0.03452278  0.00194314  0.00873108  0.00101367  0.00278093  0.00062434\n",
      "   0.00702392  0.00278093  0.00366414  0.00263575  0.00188851  0.04006824\n",
      "   0.00939978  0.00101367  0.00291425  0.00188851  0.01817879  0.0040917\n",
      "   0.00278093  0.02537594  0.0062745   0.00699353  0.00376076  0.02355509\n",
      "   0.02333676  0.00376076  0.0062745   0.0062745   0.03719314  0.00797131\n",
      "   0.00104096  0.00278093  0.01915983  0.01141278  0.00101367  0.01894171\n",
      "   0.00682277  0.00376076  0.00376076  0.01168766  0.00376076  0.00261129\n",
      "   0.00702392  0.03289664  0.01180131  0.00376076  0.02355509  0.01470859\n",
      "   0.02355509  0.03719314  0.00263575  0.00624704  0.00702392  0.02537594\n",
      "   0.01817879  0.00702392  0.01817879  0.00376076  0.00188851  0.01359412\n",
      "   0.00624704  0.01036817  0.00682277  0.0028615 ]]\n",
      "classEstimate:  [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.00238294  0.0369065   0.0260515   0.00622614  0.00640971  0.03656442\n",
      "   0.001047    0.00265941  0.01236347  0.01294511  0.00570076  0.001047\n",
      "   0.00405247  0.0041599   0.00172336  0.00693065  0.0019779   0.02581003\n",
      "   0.00029851  0.00415933  0.00468786  0.00622614  0.02035684  0.00421189\n",
      "   0.00253775  0.00468786  0.00086819  0.00313828  0.00385064  0.00773471\n",
      "   0.00397013  0.0011211   0.03041175  0.00086819  0.00295888  0.02494811\n",
      "   0.03818157  0.00177322  0.00796758  0.0011211   0.00253775  0.00056975\n",
      "   0.00640971  0.00253775  0.00405247  0.00240527  0.00172336  0.03656442\n",
      "   0.00857781  0.0011211   0.00265941  0.00172336  0.01658913  0.00373389\n",
      "   0.00253775  0.02315691  0.00693948  0.00773471  0.00415933  0.0260515\n",
      "   0.02581003  0.00415933  0.00693948  0.00693948  0.04113493  0.00727425\n",
      "   0.00115128  0.00253775  0.02119043  0.01262233  0.0011211   0.02094919\n",
      "   0.00622614  0.00415933  0.00415933  0.01066561  0.00415933  0.00238294\n",
      "   0.00640971  0.03001995  0.01076933  0.00415933  0.0260515   0.01626743\n",
      "   0.0260515   0.04113493  0.00240527  0.00570076  0.00640971  0.02315691\n",
      "   0.01658913  0.00640971  0.01658913  0.00415933  0.00172336  0.01503485\n",
      "   0.00570076  0.00946151  0.00622614  0.00316477]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.07\n",
      "D: [[ 0.00216381  0.04106514  0.02365588  0.00692771  0.00713196  0.04068452\n",
      "   0.00116498  0.00295907  0.01375659  0.01175472  0.00634313  0.00116498\n",
      "   0.00367982  0.00377737  0.00191755  0.0077116   0.00179602  0.02343662\n",
      "   0.00033214  0.00377685  0.00425677  0.00692771  0.02265065  0.00468648\n",
      "   0.00282371  0.00425677  0.00078836  0.00284969  0.00428453  0.00702345\n",
      "   0.00441748  0.00101801  0.02761518  0.00078836  0.00268679  0.02775927\n",
      "   0.03467051  0.00197303  0.00886537  0.00101801  0.00282371  0.00063394\n",
      "   0.00713196  0.00282371  0.00367982  0.00267629  0.00191755  0.04068452\n",
      "   0.00778902  0.00101801  0.00295907  0.00191755  0.01845839  0.00339054\n",
      "   0.00282371  0.02576624  0.00630135  0.00702345  0.00377685  0.02365588\n",
      "   0.02343662  0.00377685  0.00630135  0.00630135  0.03735229  0.00660533\n",
      "   0.00104541  0.00282371  0.01924182  0.01146162  0.00101801  0.01902276\n",
      "   0.00692771  0.00377685  0.00377685  0.01186742  0.00377685  0.00216381\n",
      "   0.00713196  0.03340261  0.00977901  0.00377685  0.02365588  0.01477152\n",
      "   0.02365588  0.03735229  0.00267629  0.00634313  0.00713196  0.02576624\n",
      "   0.01845839  0.00713196  0.01845839  0.00377685  0.00191755  0.01365229\n",
      "   0.00634313  0.01052764  0.00692771  0.00287374]]\n",
      "classEstimate:  [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.00197825  0.03754358  0.02610446  0.00633362  0.00652035  0.03719559\n",
      "   0.00106508  0.00270531  0.01257689  0.01297143  0.00579917  0.00106508\n",
      "   0.00406071  0.00345344  0.00175311  0.00705029  0.00198192  0.02586251\n",
      "   0.00030366  0.00416779  0.00469739  0.00633362  0.02070823  0.00428459\n",
      "   0.00258156  0.00469739  0.00086996  0.00314466  0.0039171   0.00775044\n",
      "   0.00403866  0.00112338  0.02524702  0.00086996  0.0029649   0.02537876\n",
      "   0.0382592   0.00180383  0.00810511  0.00112338  0.00258156  0.00057958\n",
      "   0.00652035  0.00258156  0.00406071  0.00244678  0.00175311  0.03719559\n",
      "   0.00712107  0.00112338  0.00270531  0.00175311  0.01687548  0.00309978\n",
      "   0.00258156  0.02355664  0.00695359  0.00775044  0.00416779  0.02610446\n",
      "   0.02586251  0.00416779  0.00695359  0.00695359  0.04121857  0.00728904\n",
      "   0.00115362  0.00258156  0.02123351  0.01264799  0.00112338  0.02099178\n",
      "   0.00633362  0.00416779  0.00416779  0.01084972  0.00416779  0.00197825\n",
      "   0.00652035  0.03053815  0.01079123  0.00416779  0.02610446  0.0163005\n",
      "   0.02610446  0.04121857  0.00244678  0.00579917  0.00652035  0.02355664\n",
      "   0.01687548  0.00652035  0.01687548  0.00416779  0.00175311  0.01506542\n",
      "   0.00579917  0.00962484  0.00633362  0.0031712 ]]\n",
      "classEstimate:  [[ 1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.00219065  0.0415745   0.02890721  0.00701363  0.00722042  0.03390799\n",
      "   0.00117943  0.00299577  0.01392722  0.01182492  0.0064218   0.00117943\n",
      "   0.0037018   0.00382422  0.00194134  0.00780725  0.00180675  0.0235766\n",
      "   0.00033626  0.00379941  0.0042822   0.00701363  0.0229316   0.00474461\n",
      "   0.00285873  0.0042822   0.00079306  0.00286671  0.00433767  0.0070654\n",
      "   0.00447227  0.00102409  0.02795771  0.00079306  0.00270284  0.02313561\n",
      "   0.04236696  0.0019975   0.00897533  0.00102409  0.00285873  0.00064181\n",
      "   0.00722042  0.00285873  0.0037018   0.00270949  0.00194134  0.03390799\n",
      "   0.00649166  0.00102409  0.00299577  0.00194134  0.01538391  0.0028258\n",
      "   0.00285873  0.02608583  0.00633898  0.0070654   0.00379941  0.02890721\n",
      "   0.0235766   0.00379941  0.00633898  0.00633898  0.03757539  0.00664478\n",
      "   0.00105166  0.00285873  0.01935675  0.01153007  0.00102409  0.01913638\n",
      "   0.00701363  0.00379941  0.00379941  0.01201462  0.00379941  0.00219065\n",
      "   0.00722042  0.02783897  0.00983742  0.00379941  0.02890721  0.01485975\n",
      "   0.02890721  0.03757539  0.00270949  0.0064218   0.00722042  0.02608583\n",
      "   0.01538391  0.00722042  0.01538391  0.00379941  0.00194134  0.01373383\n",
      "   0.0064218   0.01065822  0.00701363  0.00289091]]\n",
      "classEstimate:  [[-1.  1.  1. -1.  1. -1. -1.  1. -1.  1.  1.  1. -1. -1. -1. -1.  1.  1.\n",
      "   1.  1. -1. -1. -1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1.  1. -1.  1. -1.\n",
      "  -1. -1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1. -1. -1.  1. -1.\n",
      "  -1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1.  1.  1. -1.\n",
      "   1. -1. -1.  1.  1. -1.  1.  1. -1. -1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.00198814  0.04628956  0.02623492  0.00636527  0.0080393   0.03077341\n",
      "   0.0010704   0.00333553  0.01263974  0.01073178  0.00715011  0.00131319\n",
      "   0.00412163  0.0034707   0.00176187  0.00708552  0.00163972  0.02139709\n",
      "   0.0003744   0.00344818  0.00476785  0.00636527  0.02081172  0.00528271\n",
      "   0.00318294  0.00476785  0.00071975  0.0026017   0.00482962  0.00641225\n",
      "   0.00497948  0.00114023  0.02537319  0.00071975  0.00245298  0.02575947\n",
      "   0.0384504   0.00181284  0.00814562  0.00114023  0.00259446  0.00058248\n",
      "   0.00655294  0.00259446  0.00412163  0.00245901  0.00216151  0.03775357\n",
      "   0.00722789  0.00114023  0.00333553  0.00176187  0.01712863  0.00314628\n",
      "   0.00259446  0.02367436  0.00575298  0.00641225  0.00344818  0.02623492\n",
      "   0.02139709  0.00423031  0.00575298  0.00575298  0.04183689  0.00603052\n",
      "   0.00095444  0.00318294  0.02155204  0.01283773  0.00092942  0.02130668\n",
      "   0.00636527  0.00344818  0.00423031  0.01337722  0.00344818  0.00198814\n",
      "   0.0080393   0.03099625  0.01095311  0.00423031  0.02623492  0.01654503\n",
      "   0.03218564  0.03410178  0.00245901  0.00715011  0.0080393   0.02367436\n",
      "   0.01712863  0.00655294  0.01396177  0.00344818  0.00216151  0.01529142\n",
      "   0.00715011  0.01186699  0.00636527  0.00321877]]\n",
      "classEstimate:  [[-1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.00184005  0.04284168  0.02428081  0.00589115  0.00744049  0.0334668\n",
      "   0.00099067  0.00308708  0.01169827  0.01167107  0.00661754  0.00121538\n",
      "   0.00448236  0.00321218  0.00163064  0.00655776  0.00178324  0.02326984\n",
      "   0.00034651  0.00374998  0.00518515  0.00589115  0.01926156  0.00488923\n",
      "   0.00294586  0.00518515  0.00078275  0.00282941  0.00446988  0.00697347\n",
      "   0.00460859  0.00124003  0.02348327  0.00078275  0.00266767  0.02801402\n",
      "   0.03558642  0.00167781  0.00753889  0.00124003  0.00240121  0.00053909\n",
      "   0.00606484  0.00240121  0.00448236  0.00227585  0.00200051  0.04105789\n",
      "   0.0078605   0.00124003  0.00308708  0.00163064  0.01862779  0.00342165\n",
      "   0.00240121  0.02191098  0.0062565   0.00697347  0.00374998  0.02428081\n",
      "   0.02326984  0.00460056  0.0062565   0.0062565   0.0454986   0.00655833\n",
      "   0.00103797  0.00294586  0.01994673  0.01396133  0.00101076  0.02317151\n",
      "   0.00589115  0.00374998  0.00460056  0.01238082  0.00374998  0.00184005\n",
      "   0.00744049  0.0286875   0.01191176  0.00460056  0.02428081  0.01799311\n",
      "   0.02978829  0.03708648  0.00227585  0.00661754  0.00744049  0.02191098\n",
      "   0.01862779  0.00606484  0.01518375  0.00374998  0.00200051  0.01662977\n",
      "   0.00661754  0.01098308  0.00589115  0.00350049]]\n",
      "classEstimate:  [[ 1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.\n",
      "   1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.00207127  0.03853941  0.02733195  0.00529955  0.00837547  0.03010598\n",
      "   0.00111516  0.00347501  0.01316828  0.01049903  0.0074491   0.00136811\n",
      "   0.00403223  0.00361582  0.00146689  0.00738181  0.00160416  0.02619394\n",
      "   0.00039006  0.00337339  0.00466445  0.00529955  0.02168198  0.00550361\n",
      "   0.00331604  0.00466445  0.00070414  0.00254527  0.00503157  0.00627318\n",
      "   0.00518771  0.0011155   0.02643419  0.00070414  0.00239978  0.02520079\n",
      "   0.04005823  0.00188865  0.00848623  0.0011155   0.00270295  0.00060683\n",
      "   0.00682695  0.00270295  0.00403223  0.00256184  0.00179961  0.03693476\n",
      "   0.00707113  0.0011155   0.00347501  0.00146689  0.01675714  0.00307804\n",
      "   0.00270295  0.02466432  0.00562821  0.00627318  0.00337339  0.02733195\n",
      "   0.02619394  0.00413856  0.00562821  0.00562821  0.04092953  0.00589972\n",
      "   0.00093374  0.00331604  0.02245325  0.0125593   0.00090926  0.02084458\n",
      "   0.00529955  0.00337339  0.00413856  0.0139366   0.00337339  0.00207127\n",
      "   0.00837547  0.02580663  0.01071555  0.00413856  0.02733195  0.0161862\n",
      "   0.03353151  0.03336217  0.00256184  0.0074491   0.00837547  0.02466432\n",
      "   0.01675714  0.00682695  0.01365896  0.00337339  0.00179961  0.01495977\n",
      "   0.0074491   0.01236322  0.00529955  0.00314896]]\n",
      "classEstimate:  [[-1.  1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1.  1.  1. -1. -1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1.  1. -1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00188533  0.04275643  0.02487824  0.00587943  0.00762357  0.03340021\n",
      "   0.00101505  0.00316304  0.0119861   0.01164784  0.00678036  0.00124528\n",
      "   0.00447344  0.00329122  0.0013352   0.00671911  0.00177969  0.02384239\n",
      "   0.00035504  0.00374251  0.00517483  0.00587943  0.01973549  0.00500953\n",
      "   0.00301835  0.00517483  0.00078119  0.00282378  0.00457986  0.0069596\n",
      "   0.00472198  0.00123756  0.02406108  0.00078119  0.00266237  0.02795828\n",
      "   0.03646203  0.0017191   0.00772439  0.00123756  0.00246029  0.00055236\n",
      "   0.00621407  0.00246029  0.00447344  0.00233185  0.00163805  0.04097619\n",
      "   0.00784486  0.00123756  0.00316304  0.0013352   0.01859073  0.00341484\n",
      "   0.00246029  0.02736312  0.00512294  0.0069596   0.00374251  0.02487824\n",
      "   0.02384239  0.00459141  0.00512294  0.00512294  0.0372551   0.00654528\n",
      "   0.00084991  0.00301835  0.02043752  0.01393355  0.00100875  0.02312541\n",
      "   0.00587943  0.00374251  0.00459141  0.01268545  0.00374251  0.00188533\n",
      "   0.00762357  0.02863041  0.01188806  0.00459141  0.02487824  0.0179573\n",
      "   0.03052123  0.0303671   0.00233185  0.00678036  0.00762357  0.02736312\n",
      "   0.01859073  0.00621407  0.01515353  0.00374251  0.00163805  0.01659668\n",
      "   0.00678036  0.01125332  0.00587943  0.00349352]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: [[ 0.0020997   0.03879557  0.02770701  0.00533477  0.00691734  0.03030609\n",
      "   0.00113046  0.00287002  0.01334898  0.01056881  0.00755132  0.00138688\n",
      "   0.00405904  0.00366544  0.00121151  0.0074831   0.00161482  0.02655338\n",
      "   0.00032215  0.00339582  0.00469545  0.00533477  0.0219795   0.00557913\n",
      "   0.00336154  0.00469545  0.00070882  0.00256219  0.00510061  0.00631488\n",
      "   0.00525889  0.00112292  0.02679693  0.00070882  0.00241573  0.02536829\n",
      "   0.04060792  0.00155984  0.00860268  0.00112292  0.00274004  0.00050119\n",
      "   0.00563841  0.00274004  0.00405904  0.00259699  0.00148631  0.03718025\n",
      "   0.00711813  0.00112292  0.00287002  0.00121151  0.01686852  0.0030985\n",
      "   0.00274004  0.02482826  0.00570544  0.00631488  0.00339582  0.02770701\n",
      "   0.02655338  0.00416607  0.00570544  0.00570544  0.04149117  0.00593894\n",
      "   0.00077118  0.00336154  0.02276136  0.01264277  0.0009153   0.02098312\n",
      "   0.00533477  0.00339582  0.00416607  0.01412784  0.00339582  0.0020997\n",
      "   0.00691734  0.02597816  0.01078678  0.00416607  0.02770701  0.01629378\n",
      "   0.03399163  0.03381997  0.00259699  0.00755132  0.00691734  0.02482826\n",
      "   0.01686852  0.00563841  0.01374975  0.00339582  0.00148631  0.0150592\n",
      "   0.00755132  0.01253287  0.00533477  0.00316989]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1.  1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1.\n",
      "   1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1. -1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00190234  0.04328617  0.02510279  0.00595227  0.00771802  0.03381403\n",
      "   0.00102421  0.00260027  0.01209429  0.01179216  0.00684156  0.00125652\n",
      "   0.00452887  0.00332092  0.00135174  0.00677976  0.00180174  0.02405759\n",
      "   0.00029187  0.00307664  0.00523895  0.00595227  0.01991362  0.00505474\n",
      "   0.00304559  0.00523895  0.00079087  0.00285877  0.0046212   0.00704583\n",
      "   0.0047646   0.00125289  0.02427825  0.00079087  0.00269535  0.02830468\n",
      "   0.03679113  0.0017404   0.00779411  0.00125289  0.0024825   0.00045408\n",
      "   0.00629106  0.0024825   0.00452887  0.0023529   0.00165835  0.04148387\n",
      "   0.00794206  0.00125289  0.00260027  0.00135174  0.01882106  0.00345715\n",
      "   0.0024825   0.02770214  0.00516918  0.00704583  0.00307664  0.02510279\n",
      "   0.02405759  0.0037745   0.00516918  0.00516918  0.03759136  0.00662637\n",
      "   0.00069869  0.00304559  0.02062199  0.01410618  0.00102125  0.02341193\n",
      "   0.00595227  0.00307664  0.0037745   0.01279995  0.00307664  0.00190234\n",
      "   0.00771802  0.02898514  0.01203535  0.0037745   0.02510279  0.01817979\n",
      "   0.03079672  0.03064119  0.0023529   0.00684156  0.00771802  0.02770214\n",
      "   0.01882106  0.00629106  0.01534128  0.00307664  0.00165835  0.01364377\n",
      "   0.00684156  0.01135489  0.00595227  0.00353681]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.0020997   0.0395672   0.02770701  0.00544088  0.00705492  0.03090886\n",
      "   0.00113046  0.00237686  0.01334898  0.01077902  0.00755132  0.00138688\n",
      "   0.00413977  0.00366544  0.0012356   0.0074831   0.00164694  0.02655338\n",
      "   0.00026679  0.00281231  0.00478884  0.00544088  0.0219795   0.00557913\n",
      "   0.00336154  0.00478884  0.00072292  0.00261315  0.00510061  0.00644048\n",
      "   0.00525889  0.00114525  0.02679693  0.00072292  0.00246378  0.02587285\n",
      "   0.04060792  0.00159087  0.00860268  0.00114525  0.00274004  0.00041507\n",
      "   0.00575055  0.00274004  0.00413977  0.00259699  0.00151587  0.03791975\n",
      "   0.00725971  0.00114525  0.00237686  0.0012356   0.01720403  0.00316013\n",
      "   0.00274004  0.02532208  0.00570544  0.00644048  0.00281231  0.02770701\n",
      "   0.02655338  0.00345021  0.00570544  0.00570544  0.04149117  0.00605706\n",
      "   0.00063866  0.00336154  0.02276136  0.01289423  0.00093351  0.02140047\n",
      "   0.00544088  0.00281231  0.00345021  0.01412784  0.00281231  0.0020997\n",
      "   0.00705492  0.02649485  0.01100132  0.00345021  0.02770701  0.01661786\n",
      "   0.03399163  0.03381997  0.00259699  0.00755132  0.00705492  0.02532208\n",
      "   0.01720403  0.00575055  0.01402322  0.00281231  0.00151587  0.01247155\n",
      "   0.00755132  0.01253287  0.00544088  0.00323294]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1.  1. -1. -1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1.\n",
      "   1. -1. -1. -1.  1. -1.  1.  1. -1. -1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1. -1.  1. -1.  1. -1. -1. -1.  1. -1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00190961  0.04394128  0.02519864  0.00604236  0.00783483  0.03432578\n",
      "   0.00102812  0.00216168  0.01214047  0.01197062  0.00686769  0.00126132\n",
      "   0.00459741  0.0033336   0.00112374  0.00680564  0.00182901  0.02414945\n",
      "   0.00024264  0.0031232   0.00531824  0.00604236  0.01998966  0.00507404\n",
      "   0.00305722  0.00531824  0.00080284  0.00290203  0.00463885  0.00715246\n",
      "   0.0047828   0.00127186  0.02437095  0.00080284  0.00273614  0.02873305\n",
      "   0.03693161  0.00144684  0.00782387  0.00127186  0.00249198  0.00037749\n",
      "   0.00522995  0.00249198  0.00459741  0.00236188  0.00168345  0.0421117\n",
      "   0.00806225  0.00127186  0.00216168  0.00112374  0.0191059   0.00350947\n",
      "   0.00249198  0.02302963  0.00518892  0.00715246  0.0031232   0.02519864\n",
      "   0.02414945  0.00383162  0.00518892  0.00518892  0.0377349   0.00672666\n",
      "   0.00058085  0.00305722  0.02070073  0.01431967  0.00103671  0.02376625\n",
      "   0.00604236  0.0031232   0.00383162  0.01284882  0.0025577   0.00190961\n",
      "   0.00783483  0.0294238   0.01221749  0.00383162  0.02519864  0.01845493\n",
      "   0.03091431  0.03075819  0.00236188  0.00686769  0.00783483  0.02812139\n",
      "   0.0191059   0.00522995  0.01557346  0.0031232   0.00168345  0.01385026\n",
      "   0.00686769  0.01139825  0.00604236  0.00359034]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.0020997   0.04029344  0.02770701  0.00554074  0.00718441  0.03147618\n",
      "   0.00113046  0.00198223  0.01334898  0.01097687  0.00755132  0.00138688\n",
      "   0.00421575  0.00366544  0.00103045  0.0074831   0.00167717  0.02655338\n",
      "   0.0002225   0.00286393  0.00487674  0.00554074  0.0219795   0.00557913\n",
      "   0.00336154  0.00487674  0.00073619  0.00266112  0.00510061  0.00655869\n",
      "   0.00525889  0.00116627  0.02679693  0.00073619  0.002509    0.02634774\n",
      "   0.04060792  0.00132673  0.00860268  0.00116627  0.00274004  0.00034615\n",
      "   0.00479578  0.00274004  0.00421575  0.00259699  0.00154369  0.03861575\n",
      "   0.00739295  0.00116627  0.00198223  0.00103045  0.0175198   0.00321813\n",
      "   0.00274004  0.0211178   0.00570544  0.00655869  0.00286393  0.02770701\n",
      "   0.02655338  0.00351353  0.00570544  0.00570544  0.04149117  0.00616824\n",
      "   0.00053263  0.00336154  0.02276136  0.0131309   0.00095064  0.02179326\n",
      "   0.00554074  0.00286393  0.00351353  0.01412784  0.00234537  0.0020997\n",
      "   0.00718441  0.02698115  0.01120324  0.00351353  0.02770701  0.01692287\n",
      "   0.03399163  0.03381997  0.00259699  0.00755132  0.00718441  0.02578686\n",
      "   0.0175198   0.00479578  0.01428061  0.00286393  0.00154369  0.01270046\n",
      "   0.00755132  0.01253287  0.00554074  0.00329228]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1.  1. -1.  1. -1. -1.  1.\n",
      "  -1.  1. -1.  1.  1. -1. -1. -1.  1.  1. -1. -1. -1.  1. -1.  1. -1. -1.\n",
      "   1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1.\n",
      "   1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1. -1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00193055  0.04416291  0.02547494  0.00607283  0.00787435  0.03449891\n",
      "   0.00103939  0.00217258  0.01227359  0.01009257  0.00694299  0.00127515\n",
      "   0.00387613  0.00337015  0.00112941  0.00688027  0.00183823  0.02441424\n",
      "   0.00020457  0.00263321  0.00534506  0.00607283  0.02409024  0.00512968\n",
      "   0.00309074  0.00534506  0.00067688  0.00244674  0.00468971  0.00718854\n",
      "   0.00483524  0.00107232  0.02463817  0.00067688  0.00274994  0.02887797\n",
      "   0.03733656  0.00145414  0.00790965  0.00107232  0.0025193   0.00037939\n",
      "   0.00525633  0.0025193   0.00387613  0.00238778  0.00169194  0.04232411\n",
      "   0.00810292  0.00107232  0.00217258  0.00112941  0.01920227  0.00352717\n",
      "   0.0025193   0.02314579  0.00524581  0.00718854  0.00263321  0.02547494\n",
      "   0.02441424  0.00323048  0.00524581  0.00524581  0.03814865  0.00676059\n",
      "   0.00048972  0.00309074  0.02092771  0.01439189  0.00087406  0.02388612\n",
      "   0.00607283  0.00263321  0.00323048  0.01298971  0.00215643  0.00193055\n",
      "   0.00787435  0.02957222  0.01227912  0.00323048  0.02547494  0.01854801\n",
      "   0.03125328  0.03109544  0.00238778  0.00694299  0.00787435  0.02826323\n",
      "   0.01920227  0.00525633  0.01565201  0.00263321  0.00169194  0.01167732\n",
      "   0.00694299  0.01152323  0.00607283  0.00360844]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1.  1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1.  1.  1. -1.  1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.00213418  0.04031617  0.02816199  0.00554387  0.00718846  0.03149394\n",
      "   0.00114903  0.00198335  0.01356818  0.01115712  0.00767532  0.00140965\n",
      "   0.00353851  0.00372563  0.00103104  0.00760599  0.00167812  0.02698942\n",
      "   0.00018675  0.00291096  0.00487949  0.00554387  0.0219919   0.00468287\n",
      "   0.00282153  0.00487949  0.00061792  0.00223362  0.00518437  0.00656239\n",
      "   0.00534525  0.00097891  0.02723697  0.00061792  0.00251042  0.02636261\n",
      "   0.04127476  0.00132748  0.00874395  0.00097891  0.00229986  0.00034635\n",
      "   0.00479848  0.00229986  0.00353851  0.00263964  0.00154456  0.03863754\n",
      "   0.00739713  0.00097891  0.00198335  0.00103104  0.01752969  0.00321995\n",
      "   0.00229986  0.02112971  0.00579913  0.00656239  0.00291096  0.02816199\n",
      "   0.02698942  0.00357123  0.00579913  0.00579913  0.04217251  0.00617172\n",
      "   0.00054137  0.00282153  0.02313513  0.01313831  0.00079793  0.02180556\n",
      "   0.00554387  0.00291096  0.00357123  0.01185826  0.00238389  0.00213418\n",
      "   0.00718846  0.02699638  0.01120957  0.00357123  0.02816199  0.01693242\n",
      "   0.03454982  0.03437534  0.00263964  0.00767532  0.00718846  0.02580141\n",
      "   0.01752969  0.00479848  0.01428867  0.00291096  0.00154456  0.01290902\n",
      "   0.00767532  0.01273868  0.00554387  0.00329414]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1. -1. -1.  1.\n",
      "   1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00195494  0.04438565  0.02579683  0.00610346  0.00791406  0.03467291\n",
      "   0.00105253  0.00218354  0.01493774  0.0102201   0.00703072  0.00129126\n",
      "   0.00324133  0.00341274  0.00113511  0.0069672   0.0018475   0.02472273\n",
      "   0.0002056   0.00266648  0.00537202  0.00610346  0.02421174  0.00515555\n",
      "   0.00310633  0.00537202  0.00056603  0.00204603  0.00474897  0.00601125\n",
      "   0.00489633  0.0008967   0.02494949  0.00056603  0.00229958  0.02902362\n",
      "   0.03780832  0.00146148  0.00962656  0.0008967   0.00253201  0.00038131\n",
      "   0.00528284  0.00253201  0.00324133  0.00241795  0.00170047  0.04253757\n",
      "   0.00814378  0.0008967   0.00218354  0.00113511  0.01929912  0.00354496\n",
      "   0.00253201  0.02326252  0.0053121   0.00601125  0.00266648  0.02579683\n",
      "   0.02472273  0.0032713   0.0053121   0.0053121   0.03863068  0.00679468\n",
      "   0.00049591  0.00310633  0.02119214  0.0120349   0.00073091  0.01997423\n",
      "   0.00610346  0.00266648  0.0032713   0.01305522  0.00218368  0.00195494\n",
      "   0.00791406  0.02972136  0.01234105  0.0032713   0.02579683  0.01864156\n",
      "   0.03164818  0.03148835  0.00241795  0.00703072  0.00791406  0.02840578\n",
      "   0.01929912  0.00528284  0.01573095  0.00266648  0.00170047  0.01182487\n",
      "   0.00703072  0.01166883  0.00610346  0.00301748]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.00217219  0.0403501   0.02866357  0.00554853  0.00719451  0.03152044\n",
      "   0.00095683  0.00198501  0.0135796   0.01135583  0.00639148  0.00117386\n",
      "   0.00360153  0.00379199  0.0010319   0.00774145  0.00167953  0.02747011\n",
      "   0.00018691  0.0029628   0.00488359  0.00554853  0.02201041  0.00468681\n",
      "   0.0028239   0.00488359  0.00062893  0.0022734   0.00431719  0.00667927\n",
      "   0.00544045  0.00099635  0.02772207  0.00062893  0.0020905   0.02638479\n",
      "   0.04200987  0.0013286   0.00875131  0.00099635  0.0023018   0.00034664\n",
      "   0.00480252  0.0023018   0.00360153  0.00219811  0.00154586  0.03867005\n",
      "   0.00740335  0.00099635  0.00198501  0.0010319   0.01754444  0.00322266\n",
      "   0.0023018   0.02114749  0.00590242  0.00667927  0.0029628   0.02866357\n",
      "   0.02747011  0.00363484  0.00590242  0.00590242  0.04292361  0.00617691\n",
      "   0.00055101  0.0028239   0.02354718  0.01337231  0.00081214  0.02219392\n",
      "   0.00554853  0.0029628   0.00363484  0.01186824  0.00242634  0.00217219\n",
      "   0.00719451  0.02701909  0.011219    0.00363484  0.02866357  0.01694667\n",
      "   0.03516516  0.03498758  0.00219811  0.00639148  0.00719451  0.02582312\n",
      "   0.01754444  0.00480252  0.01430069  0.0029628   0.00154586  0.01313894\n",
      "   0.00639148  0.0106079   0.00554853  0.00274313]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1.\n",
      "   1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00196643  0.04506554  0.02594844  0.00619695  0.00803529  0.03520403\n",
      "   0.0008662   0.00221699  0.01229329  0.01028017  0.00713841  0.00106267\n",
      "   0.00326038  0.0034328   0.00115249  0.00700815  0.00152044  0.02486803\n",
      "   0.00020875  0.00268215  0.00545431  0.00619695  0.02458262  0.00523452\n",
      "   0.00315391  0.00545431  0.00056935  0.00205806  0.00482171  0.00604658\n",
      "   0.00492511  0.00090197  0.02509613  0.00056935  0.00189248  0.0294682\n",
      "   0.03803053  0.00148386  0.00792235  0.00090197  0.00257079  0.00038715\n",
      "   0.00536376  0.00257079  0.00326038  0.0019899   0.00172652  0.04318916\n",
      "   0.00826853  0.00090197  0.00221699  0.00115249  0.01959474  0.00359927\n",
      "   0.00257079  0.02361886  0.00534332  0.00604658  0.00268215  0.02594844\n",
      "   0.02486803  0.00329053  0.00534332  0.00534332  0.03885772  0.00689876\n",
      "   0.00049882  0.00315391  0.0213167   0.01210563  0.00073521  0.02009163\n",
      "   0.00619695  0.00268215  0.00329053  0.0132552   0.00219651  0.00196643\n",
      "   0.00803529  0.03017663  0.01253009  0.00329053  0.02594844  0.01534141\n",
      "   0.03183419  0.03167342  0.0019899   0.00713841  0.00803529  0.02884089\n",
      "   0.01959474  0.00536376  0.01597192  0.00268215  0.00172652  0.01189437\n",
      "   0.00713841  0.01184757  0.00619695  0.00248329]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.00217219  0.04116613  0.02866357  0.00566075  0.00734001  0.03215791\n",
      "   0.00079125  0.00202516  0.01122958  0.01135583  0.00652074  0.00097072\n",
      "   0.00360153  0.00379199  0.00105277  0.00774145  0.00138888  0.02747011\n",
      "   0.00019069  0.0029628   0.00498236  0.00566075  0.02245554  0.00478159\n",
      "   0.00288101  0.00498236  0.00062893  0.0022734   0.0044045   0.00667927\n",
      "   0.00544045  0.00099635  0.02772207  0.00062893  0.00172873  0.02691839\n",
      "   0.04200987  0.00135547  0.00723685  0.00099635  0.00234835  0.00035365\n",
      "   0.00489965  0.00234835  0.00360153  0.00181772  0.00157713  0.0394521\n",
      "   0.00755307  0.00099635  0.00202516  0.00105277  0.01789925  0.00328783\n",
      "   0.00234835  0.02157518  0.00590242  0.00667927  0.0029628   0.02866357\n",
      "   0.02747011  0.00363484  0.00590242  0.00590242  0.04292361  0.00630183\n",
      "   0.00055101  0.00288101  0.02354718  0.01337231  0.00081214  0.02219392\n",
      "   0.00566075  0.0029628   0.00363484  0.01210826  0.00242634  0.00217219\n",
      "   0.00734001  0.02756552  0.01144589  0.00363484  0.02866357  0.01401396\n",
      "   0.03516516  0.03498758  0.00181772  0.00652074  0.00734001  0.02634536\n",
      "   0.01789925  0.00489965  0.01458991  0.0029628   0.00157713  0.01313894\n",
      "   0.00652074  0.01082243  0.00566075  0.00226842]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00198765  0.04537912  0.02622852  0.00624007  0.0080912   0.03544898\n",
      "   0.00087222  0.00223242  0.01237883  0.01039112  0.00718808  0.00107006\n",
      "   0.00329557  0.00418006  0.00116051  0.00853372  0.00127089  0.02513645\n",
      "   0.00021021  0.0027111   0.00455909  0.00624007  0.02475367  0.00527095\n",
      "   0.00317586  0.00455909  0.0005755   0.00208027  0.00485526  0.00611185\n",
      "   0.00497827  0.00091171  0.025367    0.0005755   0.00158187  0.02967325\n",
      "   0.03844102  0.00149419  0.00797748  0.00091171  0.00258868  0.00038984\n",
      "   0.00540108  0.00258868  0.00329557  0.00200374  0.00173853  0.04348968\n",
      "   0.00691142  0.00091171  0.00223242  0.00116051  0.01973108  0.00300852\n",
      "   0.00258868  0.0237832   0.00540099  0.00611185  0.0027111   0.02622852\n",
      "   0.02513645  0.00332605  0.00540099  0.00540099  0.03927713  0.00576647\n",
      "   0.0005042   0.00317586  0.02154678  0.01223629  0.00074314  0.02030849\n",
      "   0.00624007  0.0027111   0.00332605  0.01334743  0.00222022  0.00198765\n",
      "   0.0080912   0.03038661  0.01047353  0.00332605  0.02622852  0.01282343\n",
      "   0.03217779  0.03201528  0.00200374  0.00718808  0.0080912   0.02904157\n",
      "   0.01973108  0.00540108  0.01608305  0.0027111   0.00173853  0.01202275\n",
      "   0.00718808  0.01193001  0.00624007  0.00207571]]\n",
      "classEstimate:  [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.00182185  0.04159386  0.02885442  0.00571956  0.00741628  0.03249204\n",
      "   0.00079947  0.0020462   0.01134626  0.01143144  0.00658849  0.00098081\n",
      "   0.00362551  0.00383139  0.00106371  0.00782189  0.00116488  0.02765301\n",
      "   0.00019267  0.00298253  0.0041788   0.00571956  0.02268886  0.00483127\n",
      "   0.00291095  0.0041788   0.00063311  0.00228854  0.00445026  0.00672374\n",
      "   0.00456301  0.00100298  0.02790665  0.00063311  0.00174024  0.02719808\n",
      "   0.04228959  0.00136955  0.00731204  0.00100298  0.00237275  0.00035732\n",
      "   0.00495055  0.00237275  0.00362551  0.0018366   0.00159351  0.03986203\n",
      "   0.00633491  0.00100298  0.0020462   0.00106371  0.01808523  0.00275757\n",
      "   0.00237275  0.02179935  0.00594172  0.00672374  0.00298253  0.02885442\n",
      "   0.02765301  0.00365904  0.00594172  0.00594172  0.04320941  0.00528547\n",
      "   0.00055468  0.00291095  0.02370396  0.01346135  0.00081754  0.0223417\n",
      "   0.00571956  0.00298253  0.00365904  0.01223407  0.0024425   0.00182185\n",
      "   0.00741628  0.02785194  0.00959989  0.00365904  0.02885442  0.01410727\n",
      "   0.03539931  0.03522054  0.0018366   0.00658849  0.00741628  0.0266191\n",
      "   0.01808523  0.00495055  0.0147415   0.00298253  0.00159351  0.01322642\n",
      "   0.00658849  0.01093488  0.00571956  0.00228352]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1. -1. -1.  1.\n",
      "   1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00166728  0.04584425  0.0264062   0.00630403  0.00817413  0.03581233\n",
      "   0.00073163  0.0022553   0.01250571  0.01046152  0.00602948  0.00089759\n",
      "   0.0033179   0.00350631  0.00117241  0.00715822  0.00128391  0.02530673\n",
      "   0.00021236  0.00272947  0.00460582  0.00630403  0.02500739  0.00532497\n",
      "   0.00320841  0.00460582  0.0005794   0.00209436  0.00407267  0.00615325\n",
      "   0.00417585  0.00091788  0.02553885  0.0005794   0.00159259  0.02997739\n",
      "   0.03870144  0.0015095   0.00805924  0.00091788  0.00261521  0.00039384\n",
      "   0.00545644  0.00261521  0.0033179   0.00168077  0.00175635  0.04393544\n",
      "   0.00698226  0.00091788  0.0022553   0.00117241  0.01993333  0.00303936\n",
      "   0.00261521  0.02402698  0.00543758  0.00615325  0.00272947  0.0264062\n",
      "   0.02530673  0.00334858  0.00543758  0.00543758  0.03954322  0.00582558\n",
      "   0.00050762  0.00320841  0.02169275  0.01231919  0.00074818  0.02044607\n",
      "   0.00630403  0.00272947  0.00334858  0.01348424  0.00223526  0.00166728\n",
      "   0.00817413  0.03069807  0.01058088  0.00334858  0.0264062   0.01554886\n",
      "   0.03239578  0.03223217  0.00168077  0.00602948  0.00817413  0.02933925\n",
      "   0.01993333  0.00545644  0.0162479   0.00272947  0.00175635  0.01210419\n",
      "   0.00602948  0.01000708  0.00630403  0.00208977]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1.  1. -1.  1. -1.  1. -1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1.  1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.00182549  0.0421878   0.02891203  0.00580124  0.00752218  0.03295601\n",
      "   0.00080106  0.00207542  0.01369244  0.01145427  0.00554858  0.00098276\n",
      "   0.00363275  0.00383904  0.0010789   0.0078375   0.00140575  0.02770823\n",
      "   0.00019542  0.00298848  0.00423847  0.00580124  0.02301285  0.00490026\n",
      "   0.00295251  0.00423847  0.00063438  0.00229311  0.00445915  0.00673717\n",
      "   0.00457212  0.00100499  0.02796237  0.00063438  0.00174371  0.02758646\n",
      "   0.04237402  0.00138911  0.00741645  0.00100499  0.00240663  0.00036243\n",
      "   0.00502125  0.00240663  0.00363275  0.00184027  0.00161627  0.04043124\n",
      "   0.00642537  0.00100499  0.00207542  0.0010789   0.01834348  0.00279694\n",
      "   0.00240663  0.02211063  0.00595358  0.00673717  0.00298848  0.02891203\n",
      "   0.02770823  0.00366634  0.00595358  0.00595358  0.04329568  0.0063784\n",
      "   0.00055579  0.00295251  0.02375129  0.01133663  0.00081918  0.01881533\n",
      "   0.00580124  0.00298848  0.00366634  0.01240876  0.00244738  0.00182549\n",
      "   0.00752218  0.02824965  0.00973697  0.00366634  0.02891203  0.01430871\n",
      "   0.03546998  0.03529086  0.00184027  0.00554858  0.00752218  0.02699921\n",
      "   0.01834348  0.00502125  0.014952    0.00298848  0.00161627  0.01325283\n",
      "   0.00554858  0.00920894  0.00580124  0.0019231 ]]\n",
      "classEstimate:  [[-1.  1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1.  1.  1. -1. -1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1.  1. -1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current error:   0.05\n",
      "D: [[ 0.0016808   0.04616177  0.02662034  0.0063477   0.00692594  0.03606037\n",
      "   0.00073757  0.00191091  0.01260712  0.01253323  0.00510878  0.00090487\n",
      "   0.00397494  0.00353474  0.00099338  0.00721627  0.00153817  0.02551195\n",
      "   0.00017993  0.00326999  0.00463772  0.0063477   0.02118875  0.00451185\n",
      "   0.00271848  0.00463772  0.00069414  0.00250911  0.0041057   0.00737179\n",
      "   0.00420972  0.00109965  0.02574595  0.00069414  0.00190797  0.03018502\n",
      "   0.03901528  0.001279    0.00682859  0.00109965  0.00221587  0.0003337\n",
      "   0.00462324  0.00221587  0.00397494  0.0016944   0.00148816  0.04423975\n",
      "   0.00703062  0.00109965  0.00191091  0.00099338  0.02007139  0.00306041\n",
      "   0.00221587  0.02419339  0.00548168  0.00737179  0.00326999  0.02662034\n",
      "   0.02551195  0.0040117   0.00548168  0.00548168  0.03986388  0.00697922\n",
      "   0.00051174  0.00271848  0.02186866  0.01240451  0.00089634  0.02058768\n",
      "   0.0063477   0.00326999  0.0040117   0.01142519  0.00267791  0.0016808\n",
      "   0.00692594  0.03091069  0.01065417  0.0040117   0.02662034  0.01565655\n",
      "   0.03265848  0.03249355  0.0016944   0.00510878  0.00692594  0.02954246\n",
      "   0.02007139  0.00462324  0.01636044  0.00326999  0.00148816  0.01450121\n",
      "   0.00510878  0.008479    0.0063477   0.00210425]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.00183139  0.04265442  0.02900537  0.0058654   0.00639971  0.03332052\n",
      "   0.00080365  0.00176572  0.01373665  0.01158096  0.00556649  0.00098594\n",
      "   0.00367293  0.00385143  0.0009179   0.00786281  0.0014213   0.02779768\n",
      "   0.00016626  0.00302154  0.00428535  0.0058654   0.02308714  0.00491608\n",
      "   0.00296204  0.00428535  0.0006414   0.00231847  0.00447354  0.00681168\n",
      "   0.00458688  0.0010161   0.02805264  0.0006414   0.001763    0.02789158\n",
      "   0.04251082  0.00118182  0.0074404   0.0010161   0.0024144   0.00030834\n",
      "   0.00427197  0.0024144   0.00367293  0.00184621  0.00137509  0.04087843\n",
      "   0.00649644  0.0010161   0.00176572  0.0009179   0.01854637  0.00282788\n",
      "   0.0024144   0.02235519  0.0059728   0.00681168  0.00302154  0.02900537\n",
      "   0.02779768  0.00370689  0.0059728   0.0059728   0.04343546  0.00644895\n",
      "   0.00047285  0.00296204  0.02382797  0.01146202  0.00082824  0.01902344\n",
      "   0.0058654   0.00302154  0.00370689  0.01244882  0.00247445  0.00183139\n",
      "   0.00639971  0.02856211  0.00984467  0.00370689  0.02900537  0.01446697\n",
      "   0.03558449  0.03540479  0.00184621  0.00556649  0.00639971  0.02729783\n",
      "   0.01854637  0.00427197  0.01511738  0.00302154  0.00137509  0.01339941\n",
      "   0.00556649  0.00923867  0.0058654   0.00194437]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1.\n",
      "   1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00167823  0.04693815  0.02657963  0.00645446  0.00704242  0.03666686\n",
      "   0.00073644  0.00194305  0.01258784  0.01061243  0.00612553  0.00090348\n",
      "   0.00336576  0.00352933  0.00101009  0.00720523  0.00130244  0.02547294\n",
      "   0.00018296  0.00276884  0.00471572  0.00645446  0.02540575  0.0054098\n",
      "   0.00325952  0.00471572  0.00058776  0.00212457  0.00492282  0.00624202\n",
      "   0.00420328  0.00093112  0.02570658  0.00058776  0.00161556  0.03069269\n",
      "   0.03895561  0.00130051  0.00681815  0.00093112  0.00265687  0.00033931\n",
      "   0.004701    0.00265687  0.00336576  0.00169181  0.00151318  0.04498379\n",
      "   0.00714887  0.00093112  0.00194305  0.00101009  0.02040896  0.00311188\n",
      "   0.00265687  0.02460029  0.00547329  0.00624202  0.00276884  0.02657963\n",
      "   0.02547294  0.00339688  0.00547329  0.00547329  0.03980292  0.0070966\n",
      "   0.00043331  0.00325952  0.02183521  0.01050345  0.00075897  0.01743249\n",
      "   0.00645446  0.00276884  0.00339688  0.01369904  0.00226751  0.00167823\n",
      "   0.00704242  0.03143056  0.01083335  0.00339688  0.02657963  0.01325709\n",
      "   0.03260853  0.03244386  0.00169181  0.00612553  0.00704242  0.03003932\n",
      "   0.02040896  0.004701    0.0166356   0.00276884  0.00151318  0.01227881\n",
      "   0.00612553  0.0101665   0.00645446  0.00178176]]\n",
      "classEstimate:  [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.00154241  0.0431396   0.02914601  0.00593212  0.0064725   0.03369953\n",
      "   0.00067684  0.00178581  0.01156915  0.01163711  0.00562981  0.00083037\n",
      "   0.00369074  0.00324372  0.00092835  0.00662214  0.00119703  0.02793246\n",
      "   0.00016815  0.00303619  0.0043341   0.00593212  0.02334975  0.004972\n",
      "   0.00299574  0.0043341   0.00064451  0.00232971  0.00452443  0.00684471\n",
      "   0.00386312  0.00102103  0.02818866  0.00064451  0.00177155  0.02820883\n",
      "   0.04271694  0.00119527  0.00626638  0.00102103  0.00244186  0.00031185\n",
      "   0.00432056  0.00244186  0.00369074  0.0015549   0.00139073  0.0413434\n",
      "   0.00657033  0.00102103  0.00178581  0.00092835  0.01875733  0.00286004\n",
      "   0.00244186  0.02260947  0.00600176  0.00684471  0.00303619  0.02914601\n",
      "   0.02793246  0.00372487  0.00600176  0.00600176  0.04364606  0.0065223\n",
      "   0.00047515  0.00299574  0.0239435   0.0115176   0.00083225  0.01911568\n",
      "   0.00593212  0.00303619  0.00372487  0.01259042  0.00248644  0.00154241\n",
      "   0.0064725   0.02888699  0.00995665  0.00372487  0.02914601  0.01453712\n",
      "   0.03575703  0.03557645  0.0015549   0.00562981  0.0064725   0.02760833\n",
      "   0.01875733  0.00432056  0.01528933  0.00303619  0.00139073  0.01346438\n",
      "   0.00562981  0.00934375  0.00593212  0.00195379]]\n",
      "classEstimate:  [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00169825  0.0474982   0.02669626  0.00653147  0.00712645  0.03710435\n",
      "   0.00074523  0.00196624  0.01273803  0.010659    0.00619862  0.00091426\n",
      "   0.00338053  0.00357144  0.00102214  0.0072912   0.00109642  0.02558472\n",
      "   0.00018514  0.00278099  0.00396981  0.00653147  0.02570889  0.00547435\n",
      "   0.00329841  0.00396981  0.00059033  0.0021339   0.00498155  0.00626941\n",
      "   0.00425343  0.00093521  0.0310367   0.00059033  0.00162265  0.02583786\n",
      "   0.04703284  0.00131603  0.0068995   0.00093521  0.00268858  0.00034336\n",
      "   0.00475709  0.00268858  0.00338053  0.001712    0.00153124  0.04552053\n",
      "   0.00601809  0.00093521  0.00196624  0.00102214  0.01718076  0.00261966\n",
      "   0.00268858  0.02489381  0.00549731  0.00626941  0.00278099  0.02669626\n",
      "   0.02558472  0.00341179  0.00549731  0.00549731  0.03997758  0.0059741\n",
      "   0.00043521  0.00329841  0.02193103  0.01054954  0.0007623   0.01750899\n",
      "   0.00653147  0.00278099  0.00341179  0.0138625   0.00227746  0.00169825\n",
      "   0.00712645  0.03180558  0.00911978  0.00341179  0.02669626  0.01331526\n",
      "   0.03275163  0.03258623  0.001712    0.00619862  0.00712645  0.03039774\n",
      "   0.01718076  0.00475709  0.01400425  0.00278099  0.00153124  0.01233269\n",
      "   0.00619862  0.0102878   0.00653147  0.00178958]]\n",
      "classEstimate:  [[-1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.00153786  0.04301231  0.02417498  0.00591461  0.00645341  0.04142466\n",
      "   0.00067484  0.00178054  0.01153501  0.0119001   0.0056132   0.00082792\n",
      "   0.00377415  0.00323415  0.00092561  0.0066026   0.00122409  0.02856371\n",
      "   0.00016766  0.0031048   0.00443204  0.00591461  0.02328086  0.00495733\n",
      "   0.0029869   0.00443204  0.00065907  0.00238236  0.00451108  0.0069994\n",
      "   0.00385172  0.0010441   0.02810549  0.00065907  0.00181158  0.02884633\n",
      "   0.0425909   0.00119174  0.00624789  0.0010441   0.00243466  0.00031093\n",
      "   0.00430781  0.00243466  0.00377415  0.00155031  0.00138662  0.05082079\n",
      "   0.00671882  0.0010441   0.00178054  0.00092561  0.01918123  0.00292468\n",
      "   0.00243466  0.02254276  0.0061374   0.0069994   0.0031048   0.02417498\n",
      "   0.02856371  0.00380905  0.0061374   0.0061374   0.04463243  0.0066697\n",
      "   0.00048589  0.0029869   0.01985979  0.01177789  0.00085106  0.01954768\n",
      "   0.00591461  0.0031048   0.00380905  0.01255328  0.00254264  0.00153786\n",
      "   0.00645341  0.02880176  0.01018166  0.00380905  0.02417498  0.01486565\n",
      "   0.02965845  0.03638046  0.00155031  0.0056132   0.00645341  0.02752687\n",
      "   0.01918123  0.00430781  0.01563486  0.0031048   0.00138662  0.01376867\n",
      "   0.0056132   0.00931619  0.00591461  0.00199795]]\n",
      "classEstimate:  [[ 1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00170691  0.04774035  0.02683236  0.00656477  0.00716278  0.0376918\n",
      "   0.00074903  0.00197626  0.01280297  0.01082776  0.00623022  0.00091892\n",
      "   0.00343405  0.00358965  0.00102735  0.00732838  0.00111378  0.02598978\n",
      "   0.00018609  0.00282502  0.00403266  0.00656477  0.02583995  0.00550226\n",
      "   0.00331522  0.00403266  0.00059968  0.00216768  0.00500695  0.00636867\n",
      "   0.00427511  0.00095002  0.03119492  0.00059968  0.00164834  0.02624693\n",
      "   0.04727262  0.00132274  0.00693468  0.00095002  0.00270228  0.00034511\n",
      "   0.00478134  0.00270228  0.00343405  0.00172072  0.00153905  0.04624122\n",
      "   0.00611337  0.00095002  0.00197626  0.00102735  0.01745277  0.00266113\n",
      "   0.00270228  0.02502072  0.00558434  0.00636867  0.00282502  0.02683236\n",
      "   0.02598978  0.00346581  0.00558434  0.00558434  0.04061051  0.00606868\n",
      "   0.0004421   0.00331522  0.01807018  0.01071656  0.00077437  0.0177862\n",
      "   0.00656477  0.00282502  0.00346581  0.01393317  0.00231351  0.00170691\n",
      "   0.00716278  0.03196773  0.00926417  0.00346581  0.02683236  0.01352607\n",
      "   0.02698587  0.03310214  0.00172072  0.00623022  0.00716278  0.03055271\n",
      "   0.01745277  0.00478134  0.01422597  0.00282502  0.00153905  0.01252794\n",
      "   0.00623022  0.01034025  0.00656477  0.00181791]]\n",
      "classEstimate:  [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00154452  0.04319866  0.02998481  0.00594024  0.00648137  0.03410606\n",
      "   0.00067777  0.00178825  0.01158499  0.01209988  0.00563752  0.0008315\n",
      "   0.00383751  0.00324816  0.00092962  0.0066312   0.00124464  0.02904324\n",
      "   0.00016838  0.00315693  0.00450645  0.00594024  0.02338172  0.00497881\n",
      "   0.00299984  0.00450645  0.00067014  0.00242236  0.00453062  0.0071169\n",
      "   0.00386841  0.00106163  0.02822725  0.00067014  0.001842    0.0293306\n",
      "   0.04277543  0.0011969   0.00627496  0.00106163  0.00244521  0.00031228\n",
      "   0.00432648  0.00244521  0.00383751  0.00155703  0.00139263  0.04184215\n",
      "   0.00683161  0.00106163  0.00178825  0.00092962  0.01579243  0.00297378\n",
      "   0.00244521  0.02264043  0.00624043  0.0071169   0.00315693  0.02998481\n",
      "   0.02904324  0.00387299  0.00624043  0.00624043  0.04538171  0.00678167\n",
      "   0.00049404  0.00299984  0.02019319  0.01197561  0.00086535  0.01987584\n",
      "   0.00594024  0.00315693  0.00387299  0.01260766  0.00258532  0.00154452\n",
      "   0.00648137  0.02892654  0.01035259  0.00387299  0.02998481  0.01511521\n",
      "   0.03015635  0.0369912   0.00155703  0.00563752  0.00648137  0.02764613\n",
      "   0.01579243  0.00432648  0.01287261  0.00315693  0.00139263  0.01399981\n",
      "   0.00563752  0.00935655  0.00594024  0.00203149]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00140762  0.04785278  0.02732701  0.00658023  0.00717965  0.03778056\n",
      "   0.00075079  0.00198091  0.01283313  0.01102737  0.00624489  0.00092109\n",
      "   0.00349736  0.00359811  0.00102977  0.00734563  0.00113431  0.0264689\n",
      "   0.00018653  0.0028771   0.004107    0.00658023  0.02590081  0.00551521\n",
      "   0.00332303  0.004107    0.00061074  0.00220764  0.00501874  0.00648607\n",
      "   0.00352552  0.00096753  0.02572524  0.00061074  0.00167873  0.0324906\n",
      "   0.03898389  0.00132585  0.00695101  0.00096753  0.00270865  0.00034592\n",
      "   0.0047926   0.00270865  0.00349736  0.00172478  0.00154267  0.04635012\n",
      "   0.00622607  0.00096753  0.00198091  0.00102977  0.01749387  0.00271019\n",
      "   0.00270865  0.02507965  0.00568729  0.00648607  0.0028771   0.02732701\n",
      "   0.0264689   0.0035297   0.00568729  0.00568729  0.04135916  0.00618055\n",
      "   0.00045025  0.00332303  0.0184033   0.01091412  0.00078865  0.01811408\n",
      "   0.00658023  0.0028771   0.0035297   0.01396598  0.00235616  0.00140762\n",
      "   0.00717965  0.03204301  0.00943495  0.0035297   0.02732701  0.01377543\n",
      "   0.02748335  0.03371237  0.00172478  0.00624489  0.00717965  0.03062466\n",
      "   0.01749387  0.0047926   0.01425948  0.0028771   0.00154267  0.01275889\n",
      "   0.00624489  0.0103646   0.00658023  0.00185142]]\n",
      "classEstimate:  [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00130094  0.04422604  0.02976813  0.00608151  0.00663551  0.0349172\n",
      "   0.00069389  0.00183078  0.01186051  0.01201244  0.00577159  0.00085128\n",
      "   0.00380977  0.00332541  0.00095173  0.00678891  0.00123564  0.02883336\n",
      "   0.00017239  0.00313411  0.00447388  0.00608151  0.0239378   0.00509722\n",
      "   0.00307118  0.00447388  0.00066529  0.00240485  0.00463837  0.00706547\n",
      "   0.00325832  0.00105396  0.02377554  0.00066529  0.00182869  0.03002816\n",
      "   0.04246632  0.00122537  0.0064242   0.00105396  0.00250336  0.00031971\n",
      "   0.00442937  0.00250336  0.00380977  0.00159406  0.00142575  0.04283727\n",
      "   0.0057542   0.00105396  0.00183078  0.00095173  0.01616802  0.00250478\n",
      "   0.00250336  0.02317888  0.00619534  0.00706547  0.00313411  0.02976813\n",
      "   0.02883336  0.00384501  0.00619534  0.00619534  0.04505377  0.00673266\n",
      "   0.00049047  0.00307118  0.02004727  0.01188908  0.0008591   0.01973221\n",
      "   0.00608151  0.00313411  0.00384501  0.01290751  0.00256664  0.00130094\n",
      "   0.00663551  0.02961449  0.01027778  0.00384501  0.02976813  0.01500598\n",
      "   0.02993843  0.0367239   0.00159406  0.00577159  0.00663551  0.02830363\n",
      "   0.01616802  0.00442937  0.01317876  0.00313411  0.00142575  0.01389864\n",
      "   0.00577159  0.00957907  0.00608151  0.00201681]]\n",
      "classEstimate:  [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00141818  0.04821177  0.02749508  0.00662959  0.00723351  0.03806399\n",
      "   0.00075642  0.00199577  0.0129294   0.01109519  0.00629174  0.000928\n",
      "   0.00351887  0.0036251   0.0010375   0.00740074  0.00114129  0.02663169\n",
      "   0.00018792  0.0028948   0.00413226  0.00662959  0.02609512  0.00555659\n",
      "   0.00334796  0.00413226  0.00061449  0.00222122  0.00505639  0.00652596\n",
      "   0.00355197  0.00097348  0.02591823  0.00061449  0.00168905  0.02773525\n",
      "   0.04629346  0.0013358   0.00700316  0.00097348  0.00272897  0.00034852\n",
      "   0.00482855  0.00272897  0.00351887  0.00173772  0.00155424  0.04669784\n",
      "   0.00531482  0.00097348  0.00199577  0.0010375   0.01493345  0.00231352\n",
      "   0.00272897  0.0252678   0.00572227  0.00652596  0.0028948   0.02749508\n",
      "   0.02663169  0.00355141  0.00572227  0.00572227  0.04161353  0.00621857\n",
      "   0.00045302  0.00334796  0.01851649  0.01098124  0.0007935   0.01822549\n",
      "   0.00662959  0.0028948   0.00355141  0.01407075  0.00237065  0.00141818\n",
      "   0.00723351  0.0322834   0.00949298  0.00355141  0.02749508  0.01386015\n",
      "   0.02765238  0.03391971  0.00173772  0.00629174  0.00723351  0.03085441\n",
      "   0.01493345  0.00482855  0.01217245  0.0028948   0.00155424  0.01283736\n",
      "   0.00629174  0.01044235  0.00662959  0.00186281]]\n",
      "classEstimate:  [[-1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.06\n",
      "D: [[ 0.00128695  0.04375039  0.02495076  0.00601611  0.00656414  0.04238627\n",
      "   0.00068642  0.00181109  0.01173295  0.01235508  0.00570952  0.00084212\n",
      "   0.00391844  0.00328964  0.00094149  0.0067159   0.00127089  0.02416726\n",
      "   0.00017053  0.00322351  0.00460149  0.00601611  0.02368035  0.0050424\n",
      "   0.00303815  0.00460149  0.00068427  0.00247345  0.00458849  0.007267\n",
      "   0.00322328  0.00108402  0.02351983  0.00068427  0.00188085  0.03088467\n",
      "   0.04200959  0.00121219  0.0063551   0.00108402  0.00247643  0.00031627\n",
      "   0.00438173  0.00247643  0.00391844  0.00157691  0.00141042  0.05200052\n",
      "   0.00591833  0.00108402  0.00181109  0.00094149  0.01662919  0.00257623\n",
      "   0.00247643  0.02292959  0.00637205  0.007267    0.00322351  0.02495076\n",
      "   0.02416726  0.00395468  0.00637205  0.00637205  0.04633887  0.0069247\n",
      "   0.00050446  0.00303815  0.02061909  0.01222819  0.0008836   0.02029505\n",
      "   0.00601611  0.00322351  0.00395468  0.01276869  0.00263985  0.00128695\n",
      "   0.00656414  0.02929598  0.01057094  0.00395468  0.02495076  0.01543401\n",
      "   0.03079239  0.03777139  0.00157691  0.00570952  0.00656414  0.02799923\n",
      "   0.01662919  0.00438173  0.01355466  0.00322351  0.00141042  0.01429508\n",
      "   0.00570952  0.00947605  0.00601611  0.00207434]]\n",
      "classEstimate:  [[ 1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.\n",
      "   1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00143122  0.03974395  0.02774793  0.00546518  0.00730003  0.03850475\n",
      "   0.00076338  0.00201413  0.0130483   0.01122366  0.0063496   0.00093653\n",
      "   0.00355961  0.00365844  0.00085527  0.0074688   0.00115451  0.02687659\n",
      "   0.00018965  0.00292832  0.00418011  0.00546518  0.02633509  0.00560769\n",
      "   0.00337875  0.00418011  0.00062161  0.00224694  0.00510289  0.00660153\n",
      "   0.00358463  0.00098475  0.02615658  0.00062161  0.00170861  0.02805641\n",
      "   0.04671918  0.00134808  0.00706756  0.00098475  0.00275406  0.00035172\n",
      "   0.00487296  0.00275406  0.00355961  0.0017537   0.00128126  0.04723857\n",
      "   0.00537636  0.00098475  0.00201413  0.00085527  0.01510638  0.00234031\n",
      "   0.00275406  0.02550016  0.00578853  0.00660153  0.00292832  0.02774793\n",
      "   0.02687659  0.00359253  0.00578853  0.00578853  0.04209539  0.00629057\n",
      "   0.00045827  0.00337875  0.02293065  0.0111084   0.00080268  0.01843653\n",
      "   0.00546518  0.00292832  0.00359253  0.01420015  0.0023981   0.00143122\n",
      "   0.00730003  0.02661321  0.0096029   0.00359253  0.02774793  0.01402064\n",
      "   0.03424444  0.03431248  0.0017537   0.0063496   0.00730003  0.03113815\n",
      "   0.01510638  0.00487296  0.0123134   0.00292832  0.00128126  0.01298601\n",
      "   0.0063496   0.01053838  0.00546518  0.00188438]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1.  1. -1. -1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1.\n",
      "   1. -1. -1. -1.  1. -1.  1.  1. -1. -1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1. -1.  1. -1.  1. -1. -1. -1.  1. -1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00131232  0.04370369  0.02544271  0.00600969  0.00802735  0.04234103\n",
      "   0.00069996  0.0018468   0.01196428  0.01234189  0.00582209  0.00085873\n",
      "   0.00391426  0.0033545   0.00078422  0.00684831  0.00126953  0.02464376\n",
      "   0.0001739   0.00322007  0.00459658  0.00600969  0.02414725  0.00514182\n",
      "   0.00309805  0.00459658  0.00068354  0.00247081  0.00467896  0.00725925\n",
      "   0.00328683  0.00108286  0.02398356  0.00068354  0.00187884  0.03085171\n",
      "   0.04283788  0.00123609  0.0064804   0.00108286  0.00252526  0.0003225\n",
      "   0.00446813  0.00252526  0.00391426  0.001608    0.00140891  0.05194501\n",
      "   0.00591201  0.00108286  0.0018468   0.00078422  0.01661144  0.00257348\n",
      "   0.00252526  0.02338168  0.00530763  0.00725925  0.00322007  0.02544271\n",
      "   0.02464376  0.00395046  0.00530763  0.00530763  0.03859823  0.00691731\n",
      "   0.00042019  0.00309805  0.02102563  0.01221514  0.00088266  0.02027338\n",
      "   0.00600969  0.00322007  0.00395046  0.01302044  0.00219888  0.00131232\n",
      "   0.00802735  0.02926471  0.01055965  0.00395046  0.02544271  0.01541753\n",
      "   0.03139951  0.0314619   0.001608    0.00582209  0.00802735  0.03424048\n",
      "   0.01661144  0.00446813  0.0135402   0.00322007  0.00140891  0.01427983\n",
      "   0.00582209  0.00966288  0.00600969  0.00207212]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1.  1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1.  1.  1. -1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00143908  0.04016584  0.02790019  0.0055232   0.00737753  0.03891349\n",
      "   0.00076757  0.0016973   0.0131199   0.01353398  0.00638444  0.00094167\n",
      "   0.0035974   0.00367851  0.00072074  0.00750978  0.00116676  0.02702407\n",
      "   0.00015982  0.00353109  0.00422449  0.0055232   0.02219251  0.00472558\n",
      "   0.00284726  0.00422449  0.00062821  0.00227079  0.00513089  0.00667161\n",
      "   0.0036043   0.00099521  0.0263001   0.00062821  0.00172675  0.02835424\n",
      "   0.04697554  0.00113603  0.00710634  0.00099521  0.00232084  0.0002964\n",
      "   0.00410643  0.00232084  0.0035974   0.00176332  0.00129486  0.04774002\n",
      "   0.00543343  0.00099521  0.0016973   0.00072074  0.01526673  0.00236516\n",
      "   0.00232084  0.02148892  0.00582029  0.00667161  0.00353109  0.02790019\n",
      "   0.02702407  0.00433203  0.00582029  0.00582029  0.04232638  0.00635735\n",
      "   0.00046078  0.00284726  0.02305647  0.01122632  0.00081121  0.01863224\n",
      "   0.0055232   0.00353109  0.00433203  0.01196643  0.00241126  0.00143908\n",
      "   0.00737753  0.02689571  0.00970484  0.00433203  0.02790019  0.01416947\n",
      "   0.03443235  0.03450076  0.00176332  0.00638444  0.00737753  0.03146869\n",
      "   0.01526673  0.00410643  0.01244411  0.00353109  0.00129486  0.01565909\n",
      "   0.00638444  0.01059621  0.0055232   0.00190438]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1.  1. -1.  1. -1. -1.  1.\n",
      "   1.  1. -1.  1.  1. -1. -1. -1.  1.  1. -1.  1. -1.  1. -1.  1. -1. -1.\n",
      "   1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1. -1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00131966  0.04416203  0.02558501  0.00607271  0.00811153  0.04278508\n",
      "   0.00070387  0.00186617  0.0120312   0.01241092  0.00585466  0.00086353\n",
      "   0.00329888  0.00337327  0.00079244  0.00688662  0.00128284  0.0247816\n",
      "   0.00017572  0.00323808  0.00464479  0.00607271  0.02440049  0.00433345\n",
      "   0.002611    0.00464479  0.00057608  0.00208236  0.00470513  0.00611799\n",
      "   0.00330522  0.00091262  0.02411771  0.00057608  0.00189854  0.03117527\n",
      "   0.04307748  0.00124905  0.00651665  0.00091262  0.00212826  0.00032588\n",
      "   0.00451499  0.00212826  0.00329888  0.001617    0.00142369  0.05248979\n",
      "   0.00597402  0.00091262  0.00186617  0.00079244  0.01678566  0.00260047\n",
      "   0.00212826  0.0236269   0.00533732  0.00611799  0.00323808  0.02558501\n",
      "   0.0247816   0.00397255  0.00533732  0.00533732  0.03881411  0.00698986\n",
      "   0.00042255  0.002611    0.02114323  0.01234325  0.00074389  0.020486\n",
      "   0.00607271  0.00323808  0.00397255  0.013157    0.00221118  0.00131966\n",
      "   0.00811153  0.02957163  0.0106704   0.00397255  0.02558501  0.01557923\n",
      "   0.03157514  0.03163787  0.001617    0.00585466  0.00811153  0.03459958\n",
      "   0.01678566  0.00451499  0.0136822   0.00323808  0.00142369  0.01435969\n",
      "   0.00585466  0.00971693  0.00607271  0.00209385]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00144152  0.04071984  0.02794752  0.00559938  0.00747928  0.03945021\n",
      "   0.00076887  0.00172071  0.01314216  0.01144356  0.00639527  0.00094327\n",
      "   0.00304175  0.00368475  0.00073068  0.00752252  0.00118285  0.02706992\n",
      "   0.00016202  0.00298569  0.00428275  0.00559938  0.02665362  0.0047336\n",
      "   0.00285209  0.00428275  0.00053117  0.00192005  0.0051396   0.00564113\n",
      "   0.00361042  0.00084149  0.02634473  0.00053117  0.00175056  0.02874532\n",
      "   0.04705524  0.0011517   0.0071184   0.00084149  0.00232478  0.00030048\n",
      "   0.00416307  0.00232478  0.00304175  0.00176631  0.00131272  0.04839848\n",
      "   0.00550837  0.00084149  0.00172071  0.00073068  0.0154773   0.00239778\n",
      "   0.00232478  0.02178531  0.00583017  0.00564113  0.00298569  0.02794752\n",
      "   0.02706992  0.00366291  0.00583017  0.00583017  0.04239819  0.00644503\n",
      "   0.00038961  0.00285209  0.02309559  0.01138116  0.00068591  0.01888923\n",
      "   0.00559938  0.00298569  0.00366291  0.01437191  0.00203883  0.00144152\n",
      "   0.00747928  0.02726668  0.0098387   0.00366291  0.02794752  0.01436491\n",
      "   0.03449077  0.0345593   0.00176631  0.00639527  0.00747928  0.03190272\n",
      "   0.0154773   0.00416307  0.01261574  0.00298569  0.00131272  0.01324043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0.00639527  0.01061419  0.00559938  0.00193065]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1.  1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1. -1.\n",
      "   1. -1. -1.  1. -1. -1.  1. -1. -1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1.\n",
      "   1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1. -1. -1.  1. -1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00132812  0.04452108  0.02574905  0.00612209  0.00817748  0.04313294\n",
      "   0.00070839  0.00188134  0.01210834  0.01054336  0.00589219  0.00086907\n",
      "   0.0033257   0.00339489  0.00079889  0.00693077  0.00129327  0.02494048\n",
      "   0.00014928  0.00275082  0.00468255  0.00612209  0.02455693  0.00436123\n",
      "   0.00262774  0.00468255  0.00048939  0.00209929  0.00473529  0.00616773\n",
      "   0.00332641  0.00077529  0.02427233  0.00048939  0.00191398  0.03142873\n",
      "   0.04335366  0.0010611   0.00655843  0.00077529  0.0021419   0.00027685\n",
      "   0.00455169  0.0021419   0.0033257   0.00162736  0.00143526  0.05291654\n",
      "   0.00602259  0.00077529  0.00188134  0.00079889  0.01692213  0.00262161\n",
      "   0.0021419   0.02381899  0.00537154  0.00616773  0.00275082  0.02574905\n",
      "   0.02494048  0.00337477  0.00537154  0.00537154  0.03906296  0.00704669\n",
      "   0.00035896  0.00262774  0.02127879  0.0124436   0.00063195  0.02065256\n",
      "   0.00612209  0.00275082  0.00337477  0.01324135  0.00187844  0.00132812\n",
      "   0.00817748  0.02981205  0.01075715  0.00337477  0.02574905  0.01570589\n",
      "   0.03177757  0.03184071  0.00162736  0.00589219  0.00817748  0.03488088\n",
      "   0.01692213  0.00455169  0.01379344  0.00275082  0.00143526  0.01447644\n",
      "   0.00589219  0.00977923  0.00612209  0.00211088]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1.  1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1.  1.  1. -1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00145879  0.04086092  0.02828248  0.00561878  0.0075052   0.0395869\n",
      "   0.00077808  0.00172667  0.01329967  0.01158071  0.00647192  0.00095457\n",
      "   0.00305229  0.00372891  0.00073321  0.00761268  0.00118695  0.02739436\n",
      "   0.00013701  0.00302147  0.00429759  0.00561878  0.02253806  0.00400269\n",
      "   0.0024117   0.00429759  0.00044916  0.0019267   0.0052012   0.00566067\n",
      "   0.00365369  0.00071156  0.02666048  0.00044916  0.00175663  0.02884491\n",
      "   0.04761921  0.00097386  0.00720371  0.00071156  0.00196581  0.00025409\n",
      "   0.00417749  0.00196581  0.00305229  0.00178748  0.00131727  0.04856617\n",
      "   0.00552746  0.00071156  0.00172667  0.00073321  0.01553093  0.00240608\n",
      "   0.00196581  0.02186079  0.00590004  0.00566067  0.00302147  0.02828248\n",
      "   0.02739436  0.00370682  0.00590004  0.00590004  0.04290635  0.00646736\n",
      "   0.00039428  0.0024117   0.0233724   0.01142059  0.00058     0.01895467\n",
      "   0.00561878  0.00302147  0.00370682  0.01215275  0.00206326  0.00145879\n",
      "   0.0075052   0.02736115  0.00987278  0.00370682  0.02828248  0.01441468\n",
      "   0.03490415  0.0349735   0.00178748  0.00647192  0.0075052   0.03201326\n",
      "   0.01553093  0.00417749  0.01265945  0.00302147  0.00131727  0.01590077\n",
      "   0.00647192  0.0107414   0.00561878  0.00193734]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1.  1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1.\n",
      "   1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1. -1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00134655  0.04457666  0.02610636  0.00612973  0.00818769  0.04318678\n",
      "   0.00071822  0.00159382  0.01227636  0.01263382  0.00597396  0.00088113\n",
      "   0.00332986  0.003442    0.00079988  0.00702694  0.00129489  0.02528657\n",
      "   0.00012646  0.00278899  0.0046884   0.00612973  0.02080392  0.00369471\n",
      "   0.00222614  0.0046884   0.00049     0.00210191  0.004801    0.00617543\n",
      "   0.00337257  0.00077626  0.02460915  0.00049     0.00191637  0.03146796\n",
      "   0.04395527  0.00106242  0.00664944  0.00077626  0.00181456  0.00023454\n",
      "   0.00455738  0.00181456  0.00332986  0.00164995  0.00143705  0.05298259\n",
      "   0.0060301   0.00077626  0.00159382  0.00079988  0.01694325  0.00262488\n",
      "   0.00181456  0.02384872  0.00544608  0.00617543  0.00278899  0.02610636\n",
      "   0.02528657  0.0034216   0.00544608  0.00544608  0.03960503  0.00705548\n",
      "   0.00036394  0.00222614  0.02157407  0.01245914  0.00063274  0.02067834\n",
      "   0.00612973  0.00278899  0.0034216   0.01121769  0.00190451  0.00134655\n",
      "   0.00818769  0.02984927  0.01077058  0.0034216   0.02610636  0.01572549\n",
      "   0.03221854  0.03228255  0.00164995  0.00597396  0.00818769  0.03492442\n",
      "   0.01694325  0.00455738  0.01381066  0.00278899  0.00143705  0.01467733\n",
      "   0.00597396  0.00991493  0.00612973  0.00211351]]\n",
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00146976  0.04112881  0.02849512  0.00565562  0.0075544   0.03984644\n",
      "   0.00078393  0.00147054  0.01339966  0.01165664  0.00652058  0.00096175\n",
      "   0.0030723   0.00375695  0.00073802  0.00766992  0.00119473  0.02760032\n",
      "   0.00011668  0.00257327  0.00432577  0.00565562  0.0227075   0.00403278\n",
      "   0.00242984  0.00432577  0.0004521   0.00193934  0.0052403   0.00569778\n",
      "   0.00368116  0.00071622  0.02686091  0.0004521   0.00176814  0.02903402\n",
      "   0.04797722  0.00098025  0.00725787  0.00071622  0.00198059  0.0002164\n",
      "   0.00420488  0.00198059  0.0030723   0.00180092  0.0013259   0.04888458\n",
      "   0.0055637   0.00071622  0.00147054  0.00073802  0.01563275  0.00242186\n",
      "   0.00198059  0.02200411  0.0059444   0.00569778  0.00257327  0.02849512\n",
      "   0.02760032  0.00315695  0.0059444   0.0059444   0.04322892  0.00650977\n",
      "   0.00033579  0.00242984  0.02354812  0.01149547  0.0005838   0.01907894\n",
      "   0.00565562  0.00257327  0.00315695  0.01224412  0.0017572   0.00146976\n",
      "   0.0075544   0.02754053  0.00993751  0.00315695  0.02849512  0.01450918\n",
      "   0.03516657  0.03523644  0.00180092  0.00652058  0.0075544   0.03222314\n",
      "   0.01563275  0.00420488  0.01274245  0.00257327  0.0013259   0.01354209\n",
      "   0.00652058  0.01082216  0.00565562  0.00195004]]\n",
      "classEstimate:  [[-1.  1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1.  1.  1. -1. -1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1.  1. -1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00136142  0.04468493  0.02639458  0.00614462  0.00699752  0.04329167\n",
      "   0.00072615  0.00136214  0.0124119   0.0126645   0.00603991  0.00089085\n",
      "   0.00333794  0.00348     0.00068361  0.00710452  0.00129803  0.02556575\n",
      "   0.00010808  0.00279577  0.00469979  0.00614462  0.02103361  0.0037355\n",
      "   0.00225072  0.00469979  0.00049119  0.00210702  0.00485401  0.00619043\n",
      "   0.0034098   0.00077815  0.02488085  0.00049119  0.00192102  0.03154439\n",
      "   0.04444055  0.00090799  0.00672285  0.00077815  0.00183459  0.00020044\n",
      "   0.00389491  0.00183459  0.00333794  0.00166816  0.00122816  0.05311128\n",
      "   0.00604475  0.00077815  0.00136214  0.00068361  0.0169844   0.00263126\n",
      "   0.00183459  0.02390665  0.00550621  0.00619043  0.00279577  0.02639458\n",
      "   0.02556575  0.00342991  0.00550621  0.00550621  0.04004228  0.00707262\n",
      "   0.00031104  0.00225072  0.02181225  0.0124894   0.00063428  0.02072856\n",
      "   0.00614462  0.00279577  0.00342991  0.01134154  0.00190914  0.00136142\n",
      "   0.00699752  0.02992177  0.01079674  0.00342991  0.02639458  0.01576369\n",
      "   0.03257424  0.03263896  0.00166816  0.00603991  0.00699752  0.03500925\n",
      "   0.0169844   0.00389491  0.0138442   0.00279577  0.00122816  0.01471298\n",
      "   0.00603991  0.0100244   0.00614462  0.00211865]]\n",
      "classEstimate:  [[ 1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00146998  0.04824834  0.02849943  0.00663462  0.00755554  0.04031424\n",
      "   0.00078405  0.00147076  0.01340169  0.01179349  0.00652156  0.0009619\n",
      "   0.00310837  0.00375752  0.00073813  0.00767108  0.00120876  0.02380743\n",
      "   0.0001167   0.00260348  0.00437655  0.00663462  0.02271094  0.00403339\n",
      "   0.0024302   0.00437655  0.00045741  0.0019621   0.00524109  0.00576468\n",
      "   0.00368172  0.00072463  0.02686498  0.00045741  0.0017889   0.02937489\n",
      "   0.04798448  0.0009804   0.00725897  0.00072463  0.00198089  0.00021643\n",
      "   0.00420552  0.00198089  0.00310837  0.00180119  0.0013261   0.04945849\n",
      "   0.00562901  0.00072463  0.00147076  0.00073813  0.01581628  0.00245029\n",
      "   0.00198089  0.02581309  0.00512751  0.00576468  0.00260348  0.02849943\n",
      "   0.02380743  0.00319402  0.00512751  0.00512751  0.03728832  0.00658619\n",
      "   0.00028965  0.0024302   0.02031209  0.01163043  0.00059065  0.01930293\n",
      "   0.00663462  0.00260348  0.00319402  0.01224597  0.00177783  0.00146998\n",
      "   0.00755554  0.03230789  0.01005418  0.00319402  0.02849943  0.01467952\n",
      "   0.03033391  0.03039418  0.00180119  0.00652156  0.00755554  0.03780107\n",
      "   0.01581628  0.00420552  0.01289205  0.00260348  0.0013261   0.01370108\n",
      "   0.00652156  0.01082379  0.00663462  0.00197293]]\n",
      "classEstimate:  [[-1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00133478  0.04381067  0.02587817  0.0060244   0.00686062  0.044858\n",
      "   0.00071194  0.00133549  0.01216906  0.01312271  0.00592174  0.00087342\n",
      "   0.00345871  0.00341192  0.00067024  0.00696552  0.001345    0.02649073\n",
      "   0.00010597  0.00289692  0.00486983  0.0060244   0.02062208  0.00366242\n",
      "   0.00220668  0.00486983  0.00050896  0.00218325  0.00475904  0.00641441\n",
      "   0.00334309  0.0008063   0.02439405  0.00050896  0.00199053  0.03268569\n",
      "   0.04357107  0.00089022  0.00659132  0.0008063   0.0017987   0.00019652\n",
      "   0.00381871  0.0017987   0.00345871  0.00163553  0.00120413  0.05503288\n",
      "   0.00626345  0.0008063   0.00133549  0.00067024  0.01759891  0.00272646\n",
      "   0.0017987   0.02343892  0.00570542  0.00641441  0.00289692  0.02587817\n",
      "   0.02649073  0.00355401  0.00570542  0.00570542  0.04149103  0.00732851\n",
      "   0.00032229  0.00220668  0.01844387  0.01294127  0.00065723  0.02147854\n",
      "   0.0060244   0.00289692  0.00355401  0.01111964  0.00197821  0.00133478\n",
      "   0.00686062  0.02933635  0.01118737  0.00355401  0.02587817  0.01633403\n",
      "   0.02754393  0.03381986  0.00163553  0.00592174  0.00686062  0.0343243\n",
      "   0.01759891  0.00381871  0.01434509  0.00289692  0.00120413  0.0152453\n",
      "   0.00592174  0.00982827  0.0060244   0.0021953 ]]\n",
      "classEstimate:  [[ 1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.\n",
      "   1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00147657  0.03997237  0.02862705  0.00549659  0.00758938  0.04092794\n",
      "   0.00078756  0.00147735  0.0134617   0.01197302  0.00655077  0.0009662\n",
      "   0.00315569  0.00377434  0.00061152  0.00770543  0.00122716  0.02930468\n",
      "   0.00011722  0.00264312  0.00444318  0.00549659  0.02281264  0.00405145\n",
      "   0.00244109  0.00444318  0.00046437  0.00199197  0.00526456  0.00585243\n",
      "   0.0036982   0.00073566  0.02698528  0.00046437  0.00181614  0.02982206\n",
      "   0.04819936  0.00098479  0.00729148  0.00073566  0.00198976  0.0002174\n",
      "   0.00422435  0.00198976  0.00315569  0.00180926  0.00109864  0.0502114\n",
      "   0.0057147   0.00073566  0.00147735  0.00061152  0.01605705  0.00248759\n",
      "   0.00198976  0.02592869  0.00520557  0.00585243  0.00264312  0.02862705\n",
      "   0.02930468  0.00324264  0.00520557  0.00520557  0.03785596  0.00668645\n",
      "   0.00029406  0.00244109  0.02040305  0.01180747  0.00059965  0.01959678\n",
      "   0.00549659  0.00264312  0.00324264  0.01230081  0.0018049   0.00147657\n",
      "   0.00758938  0.02676616  0.01020723  0.00324264  0.02862705  0.01490299\n",
      "   0.03046975  0.03085687  0.00180926  0.00655077  0.00758938  0.03797035\n",
      "   0.01605705  0.00422435  0.0130883   0.00264312  0.00109864  0.01390965\n",
      "   0.00655077  0.01087227  0.00549659  0.00200297]]\n",
      "classEstimate:  [[-1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.04\n",
      "D: [[ 0.00136398  0.03692445  0.02644422  0.00507747  0.00701068  0.04461029\n",
      "   0.00072751  0.0013647   0.01243524  0.01305025  0.00605127  0.00089253\n",
      "   0.00343961  0.00348655  0.00056489  0.00711788  0.00133757  0.02707017\n",
      "   0.00010828  0.00288092  0.00484294  0.00507747  0.02107316  0.00374253\n",
      "   0.00225495  0.00484294  0.00050615  0.00217119  0.00486314  0.00637898\n",
      "   0.00341621  0.00080185  0.02492764  0.00050615  0.00197954  0.0325052\n",
      "   0.04452412  0.0009097   0.00673549  0.00080185  0.00183804  0.00020082\n",
      "   0.00390224  0.00183804  0.00343961  0.0016713   0.00101487  0.05472899\n",
      "   0.00622887  0.00080185  0.0013647   0.00056489  0.01750173  0.00271141\n",
      "   0.00183804  0.02395161  0.00567392  0.00637898  0.00288092  0.02644422\n",
      "   0.02707017  0.00353439  0.00567392  0.00567392  0.04126192  0.00728804\n",
      "   0.00032051  0.00225495  0.02223874  0.01286981  0.0006536   0.02135993\n",
      "   0.00507747  0.00288092  0.00353439  0.01136286  0.00196729  0.00136398\n",
      "   0.00701068  0.02472522  0.01112559  0.00353439  0.02644422  0.01624383\n",
      "   0.03321116  0.03363311  0.0016713   0.00605127  0.00701068  0.03507509\n",
      "   0.01750173  0.00390224  0.01426588  0.00288092  0.00101487  0.01516112\n",
      "   0.00605127  0.01004325  0.00507747  0.00218318]]\n",
      "classEstimate:  [[ 1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.0015296   0.04140815  0.02965532  0.00569403  0.00786198  0.0402518\n",
      "   0.00081585  0.00153042  0.01394524  0.01177522  0.00678607  0.00100091\n",
      "   0.00310356  0.00390992  0.00063348  0.0079822   0.00120689  0.02442538\n",
      "   0.00012143  0.00259945  0.00436977  0.00569403  0.02363206  0.00419698\n",
      "   0.00252877  0.00436977  0.0004567   0.00195907  0.00545366  0.00575575\n",
      "   0.00383104  0.00072351  0.02795458  0.0004567   0.00178613  0.02932939\n",
      "   0.04993065  0.00102016  0.00755338  0.00072351  0.00206123  0.00022521\n",
      "   0.00437608  0.00206123  0.00310356  0.00187424  0.0011381   0.04938189\n",
      "   0.0056203   0.00072351  0.00153042  0.00063348  0.01579178  0.0024465\n",
      "   0.00206123  0.02686003  0.00511957  0.00575575  0.00259945  0.02965532\n",
      "   0.02442538  0.00318907  0.00511957  0.00511957  0.03723057  0.00657599\n",
      "   0.0002892   0.00252877  0.02006599  0.01161241  0.00058974  0.01927303\n",
      "   0.00569403  0.00259945  0.00318907  0.01274265  0.00177508  0.0015296\n",
      "   0.00786198  0.02772758  0.01003861  0.00318907  0.02965532  0.01465679\n",
      "   0.02996638  0.0303471   0.00187424  0.00678607  0.00786198  0.03933422\n",
      "   0.01579178  0.00437608  0.01287208  0.00259945  0.0011381   0.01367985\n",
      "   0.00678607  0.01126279  0.00569403  0.00196988]]\n",
      "classEstimate:  [[-1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.04\n",
      "D: [[ 0.00139047  0.03764156  0.02695779  0.00517608  0.00714684  0.04472744\n",
      "   0.00074164  0.00139121  0.01267674  0.01308452  0.00616879  0.00090986\n",
      "   0.00344865  0.00355426  0.00057586  0.00725612  0.00134108  0.02714126\n",
      "   0.00011039  0.00288849  0.00485565  0.00517608  0.02148242  0.00381521\n",
      "   0.00229875  0.00485565  0.00050748  0.0021769   0.00495758  0.00639574\n",
      "   0.00348256  0.00080395  0.02541176  0.00050748  0.00198473  0.03259056\n",
      "   0.04538883  0.00092736  0.00686631  0.00080395  0.00187374  0.00020472\n",
      "   0.00397802  0.00187374  0.00344865  0.00170376  0.00103458  0.05487271\n",
      "   0.00624522  0.00080395  0.00139121  0.00057586  0.01754769  0.00271853\n",
      "   0.00187374  0.02441677  0.00568882  0.00639574  0.00288849  0.02695779\n",
      "   0.02714126  0.00354367  0.00568882  0.00568882  0.04137027  0.00730718\n",
      "   0.00032136  0.00229875  0.01824073  0.01290361  0.00065531  0.02141602\n",
      "   0.00517608  0.00288849  0.00354367  0.01158354  0.00197245  0.00139047\n",
      "   0.00714684  0.02520541  0.01115481  0.00354367  0.02695779  0.01628649\n",
      "   0.02724056  0.03372143  0.00170376  0.00616879  0.00714684  0.03575628\n",
      "   0.01754769  0.00397802  0.01430334  0.00288849  0.00103458  0.01520093\n",
      "   0.00616879  0.0102383   0.00517608  0.00218891]]\n",
      "classEstimate:  [[ 1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.0015296   0.04140815  0.02965532  0.00569403  0.00786198  0.04099814\n",
      "   0.00081585  0.00153042  0.01394524  0.01199355  0.00678607  0.00100091\n",
      "   0.0031611   0.00390992  0.00063348  0.0079822   0.00122927  0.02487827\n",
      "   0.00012143  0.00264765  0.0044508   0.00569403  0.02363206  0.00419698\n",
      "   0.00252877  0.0044508   0.00046517  0.00199539  0.00545366  0.00586247\n",
      "   0.00383104  0.00073692  0.02795458  0.00046517  0.00181925  0.02987321\n",
      "   0.04993065  0.00102016  0.00755338  0.00073692  0.00206123  0.00022521\n",
      "   0.00437608  0.00206123  0.0031611   0.00187424  0.0011381   0.05029752\n",
      "   0.00572451  0.00073692  0.00153042  0.00063348  0.01608459  0.00249186\n",
      "   0.00206123  0.02686003  0.00521449  0.00586247  0.00264765  0.02965532\n",
      "   0.02487827  0.0032482   0.00521449  0.00521449  0.03792089  0.00669792\n",
      "   0.00029456  0.00252877  0.01671985  0.01182773  0.00060067  0.01963039\n",
      "   0.00569403  0.00264765  0.0032482   0.01274265  0.00180799  0.0015296\n",
      "   0.00786198  0.02772758  0.01022474  0.0032482   0.02965532  0.01492855\n",
      "   0.02496929  0.03090979  0.00187424  0.00678607  0.00786198  0.03933422\n",
      "   0.01608459  0.00437608  0.01311075  0.00264765  0.0011381   0.0139335\n",
      "   0.00678607  0.01126279  0.00569403  0.0020064 ]]\n",
      "classEstimate:  [[-1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.04\n",
      "D: [[ 0.00139116  0.03766045  0.02697132  0.00517868  0.00715042  0.04552885\n",
      "   0.00074201  0.0013919   0.0126831   0.01331897  0.00617189  0.00091032\n",
      "   0.00351044  0.00355604  0.00057615  0.00725976  0.00136511  0.02262662\n",
      "   0.00011044  0.00294024  0.00494266  0.00517868  0.0214932   0.00381713\n",
      "   0.0022999   0.00494266  0.00051657  0.0022159   0.00496007  0.00651033\n",
      "   0.00348431  0.00081836  0.02542451  0.00051657  0.0020203   0.03317451\n",
      "   0.0454116   0.00092783  0.00686975  0.00081836  0.00187468  0.00020482\n",
      "   0.00398002  0.00187468  0.00351044  0.00170461  0.0010351   0.05585591\n",
      "   0.00635712  0.00081836  0.0013919   0.00057615  0.01786211  0.00276724\n",
      "   0.00187468  0.02442902  0.00579075  0.00651033  0.00294024  0.02697132\n",
      "   0.02262662  0.00360716  0.00579075  0.00579075  0.04211154  0.00743811\n",
      "   0.00032711  0.0022999   0.01856757  0.01313481  0.00066706  0.02179975\n",
      "   0.00517868  0.00294024  0.00360716  0.01158935  0.00200779  0.00139116\n",
      "   0.00715042  0.02521806  0.01135468  0.00360716  0.02697132  0.01657831\n",
      "   0.02772865  0.03432565  0.00170461  0.00617189  0.00715042  0.03577422\n",
      "   0.01786211  0.00398002  0.01455963  0.00294024  0.0010351   0.0154733\n",
      "   0.00617189  0.01024343  0.00517868  0.00222813]]\n",
      "classEstimate:  [[ 1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.0015296   0.04140815  0.02965532  0.00569403  0.00786198  0.04175019\n",
      "   0.00081585  0.00153042  0.01394524  0.01221356  0.00678607  0.00100091\n",
      "   0.00321909  0.00390992  0.00063348  0.0079822   0.00125182  0.02074873\n",
      "   0.00012143  0.00269622  0.00453244  0.00569403  0.02363206  0.00419698\n",
      "   0.00252877  0.00453244  0.0004737   0.00203199  0.00545366  0.00597001\n",
      "   0.00383104  0.00075044  0.02795458  0.0004737   0.00185262  0.03042119\n",
      "   0.04993065  0.00102016  0.00755338  0.00075044  0.00206123  0.00022521\n",
      "   0.00437608  0.00206123  0.00321909  0.00187424  0.0011381   0.05122015\n",
      "   0.00582951  0.00075044  0.00153042  0.00063348  0.01637964  0.00253757\n",
      "   0.00206123  0.02686003  0.00531015  0.00597001  0.00269622  0.02965532\n",
      "   0.02074873  0.00330779  0.00531015  0.00531015  0.0386165   0.00682079\n",
      "   0.00029996  0.00252877  0.01702655  0.01204469  0.00061169  0.01999048\n",
      "   0.00569403  0.00269622  0.00330779  0.01274265  0.00184116  0.0015296\n",
      "   0.00786198  0.02772758  0.0104123   0.00330779  0.02965532  0.01520239\n",
      "   0.02542732  0.03147679  0.00187424  0.00678607  0.00786198  0.03933422\n",
      "   0.01637964  0.00437608  0.01335125  0.00269622  0.0011381   0.01418909\n",
      "   0.00678607  0.01126279  0.00569403  0.00204321]]\n",
      "classEstimate:  [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.03\n",
      "D: [[ 0.00139026  0.03763591  0.03295877  0.00517531  0.00714577  0.03794679\n",
      "   0.00074153  0.001391    0.01267484  0.01357409  0.00616786  0.00090973\n",
      "   0.00357768  0.00355373  0.00057577  0.00725503  0.00139126  0.02306003\n",
      "   0.00011037  0.00299656  0.00503733  0.00517531  0.0214792   0.00381464\n",
      "   0.0022984   0.00503733  0.00052647  0.00225835  0.00495684  0.00663504\n",
      "   0.00348204  0.00083404  0.02540794  0.00052647  0.00205899  0.03380996\n",
      "   0.04538201  0.00092722  0.00686527  0.00083404  0.00187346  0.00020469\n",
      "   0.00397743  0.00187346  0.00357768  0.0017035   0.00103442  0.04655405\n",
      "   0.00647889  0.00083404  0.001391    0.00057577  0.01488747  0.00282024\n",
      "   0.00187346  0.02441311  0.00590167  0.00663504  0.00299656  0.03295877\n",
      "   0.02306003  0.00367626  0.00590167  0.00590167  0.04291818  0.00758059\n",
      "   0.00033338  0.0022984   0.01892322  0.01338641  0.00067983  0.02221732\n",
      "   0.00517531  0.00299656  0.00367626  0.0115818   0.00204625  0.00139026\n",
      "   0.00714577  0.02520163  0.01157218  0.00367626  0.03295877  0.01689586\n",
      "   0.02825979  0.03498315  0.0017035   0.00616786  0.00714577  0.03575091\n",
      "   0.01488747  0.00397743  0.01213497  0.00299656  0.00103442  0.01576969\n",
      "   0.00616786  0.01023676  0.00517531  0.00227081]]\n",
      "classEstimate:  [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00152904  0.0413929   0.03021622  0.00569193  0.00785909  0.04173481\n",
      "   0.00081555  0.00152985  0.0139401   0.01244457  0.00678357  0.00100054\n",
      "   0.00327998  0.00390847  0.00063325  0.00797926  0.00127549  0.02114117\n",
      "   0.00012139  0.00274721  0.00461817  0.00569193  0.02362335  0.00419543\n",
      "   0.00252784  0.00461817  0.00048266  0.00207043  0.00545165  0.00608293\n",
      "   0.00382963  0.00076463  0.02794428  0.00048266  0.00188766  0.03099659\n",
      "   0.04160571  0.00101978  0.0075506   0.00076463  0.00206047  0.00022512\n",
      "   0.00437447  0.00206047  0.00327998  0.00187355  0.00113768  0.05120128\n",
      "   0.00593978  0.00076463  0.00152985  0.00063325  0.01637361  0.00258557\n",
      "   0.00206047  0.02685013  0.00541058  0.00608293  0.00274721  0.03021622\n",
      "   0.02114117  0.00337035  0.00541058  0.00541058  0.0393469   0.00694979\n",
      "   0.00030564  0.00252784  0.0173486   0.0122725   0.00062326  0.02036859\n",
      "   0.00569193  0.00274721  0.00337035  0.01273795  0.00187598  0.00152904\n",
      "   0.00785909  0.02771737  0.01060924  0.00337035  0.03021622  0.01548994\n",
      "   0.02590826  0.03207215  0.00187355  0.00678357  0.00785909  0.03931973\n",
      "   0.01637361  0.00437447  0.01334633  0.00274721  0.00113768  0.01445747\n",
      "   0.00678357  0.01125864  0.00569193  0.00208185]]\n",
      "classEstimate:  [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.02\n",
      "D: [[ 0.00141158  0.03821313  0.03295877  0.00525468  0.00725536  0.03852877\n",
      "   0.0007529   0.00141233  0.01286923  0.01357409  0.00626246  0.00092368\n",
      "   0.00357768  0.00360823  0.0005846   0.0073663   0.00139126  0.02306003\n",
      "   0.00011206  0.00299656  0.00503733  0.00525468  0.02180862  0.00387314\n",
      "   0.00233365  0.00503733  0.00052647  0.00225835  0.00503286  0.00663504\n",
      "   0.00353544  0.00083404  0.02579762  0.00052647  0.00205899  0.03380996\n",
      "   0.0384096   0.00094145  0.00697057  0.00083404  0.00190219  0.00020783\n",
      "   0.00403843  0.00190219  0.00357768  0.00172963  0.00105029  0.04726804\n",
      "   0.00647889  0.00083404  0.00141233  0.0005846   0.0151158   0.00282024\n",
      "   0.00190219  0.02478753  0.00590167  0.00663504  0.00299656  0.03295877\n",
      "   0.02306003  0.00367626  0.00590167  0.00590167  0.04291818  0.00758059\n",
      "   0.00033338  0.00233365  0.01892322  0.01338641  0.00067983  0.02221732\n",
      "   0.00525468  0.00299656  0.00367626  0.01175943  0.00204625  0.00141158\n",
      "   0.00725536  0.02558814  0.01157218  0.00367626  0.03295877  0.01689586\n",
      "   0.02825979  0.03498315  0.00172963  0.00626246  0.00725536  0.03629922\n",
      "   0.0151158   0.00403843  0.01232108  0.00299656  0.00105029  0.01576969\n",
      "   0.00626246  0.01039376  0.00525468  0.00227081]]\n",
      "classEstimate:  [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00154289  0.04176779  0.0303738   0.00574348  0.00793027  0.0421128\n",
      "   0.00082294  0.00154371  0.01406636  0.01250947  0.00684501  0.0010096\n",
      "   0.00329708  0.00394387  0.00063898  0.00805153  0.00128214  0.02125142\n",
      "   0.00012249  0.00276154  0.00464225  0.00574348  0.0238373   0.00423343\n",
      "   0.00255073  0.00464225  0.00048518  0.00208122  0.00550103  0.00611465\n",
      "   0.00386431  0.00076862  0.02819737  0.00048518  0.00189751  0.03115823\n",
      "   0.04198253  0.00102902  0.00761898  0.00076862  0.00207913  0.00022716\n",
      "   0.00441409  0.00207913  0.00329708  0.00189052  0.00114799  0.05166501\n",
      "   0.00597075  0.00076862  0.00154371  0.00063898  0.01393026  0.00259905\n",
      "   0.00207913  0.02709331  0.0054388   0.00611465  0.00276154  0.0303738\n",
      "   0.02125142  0.00338793  0.0054388   0.0054388   0.03955209  0.00698604\n",
      "   0.00030723  0.00255073  0.01743907  0.0123365   0.00062651  0.02047481\n",
      "   0.00574348  0.00276154  0.00338793  0.01285332  0.00188576  0.00154289\n",
      "   0.00793027  0.0279684   0.01066457  0.00338793  0.0303738   0.01557071\n",
      "   0.02604336  0.0322394   0.00189052  0.00684501  0.00793027  0.03967585\n",
      "   0.01393026  0.00441409  0.01135473  0.00276154  0.00114799  0.01453286\n",
      "   0.00684501  0.01136061  0.00574348  0.00209271]]\n",
      "classEstimate:  [[-1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.03\n",
      "D: [[ 0.00142642  0.03861481  0.02808093  0.00530992  0.00733162  0.04585713\n",
      "   0.00076082  0.00142718  0.01300451  0.01362171  0.00632829  0.00093339\n",
      "   0.00359023  0.00364616  0.00059075  0.00744373  0.00139614  0.02314093\n",
      "   0.00011324  0.00300707  0.005055    0.00530992  0.02203787  0.00391386\n",
      "   0.00235818  0.005055    0.00052832  0.00226627  0.00508577  0.00665831\n",
      "   0.0035726   0.00083696  0.0260688   0.00052832  0.00206622  0.03392856\n",
      "   0.03881335  0.00095134  0.00704384  0.00083696  0.00192218  0.00021001\n",
      "   0.00408088  0.00192218  0.00359023  0.00174781  0.00106133  0.05625864\n",
      "   0.00650162  0.00083696  0.00142718  0.00059075  0.01516883  0.00283013\n",
      "   0.00192218  0.02504809  0.00592237  0.00665831  0.00300707  0.02808093\n",
      "   0.02314093  0.00368915  0.00592237  0.00592237  0.04306873  0.00760718\n",
      "   0.00033455  0.00235818  0.01612262  0.01343337  0.00068222  0.02229526\n",
      "   0.00530992  0.00300707  0.00368915  0.01188304  0.00205343  0.00142642\n",
      "   0.00733162  0.02585712  0.01161277  0.00368915  0.02808093  0.01695513\n",
      "   0.0240774   0.03510587  0.00174781  0.00632829  0.00733162  0.03668079\n",
      "   0.01516883  0.00408088  0.0123643   0.00300707  0.00106133  0.01582501\n",
      "   0.00632829  0.01050302  0.00530992  0.00227878]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classEstimate:  [[ 1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.04\n",
      "D: [[ 0.00155997  0.03556959  0.03071013  0.00489117  0.00675344  0.04224076\n",
      "   0.00083205  0.00131463  0.01422211  0.01254748  0.0069208   0.00102078\n",
      "   0.0033071   0.00398754  0.00054416  0.00814068  0.00128604  0.02530759\n",
      "   0.00010431  0.00276993  0.00465636  0.00489117  0.02410125  0.00428031\n",
      "   0.00257898  0.00465636  0.00048665  0.00208755  0.00556194  0.00613323\n",
      "   0.0039071   0.00077096  0.0285096   0.00048665  0.00190327  0.0312529\n",
      "   0.04244741  0.00087632  0.00770335  0.00077096  0.00210216  0.00019345\n",
      "   0.00375905  0.00210216  0.0033071   0.00191146  0.00097763  0.05182199\n",
      "   0.00598889  0.00077096  0.00131463  0.00054416  0.01397259  0.00260695\n",
      "   0.00210216  0.02307275  0.00647688  0.00613323  0.00276993  0.03071013\n",
      "   0.02530759  0.00339822  0.00647688  0.00647688  0.04710122  0.00700726\n",
      "   0.00030817  0.00257898  0.01763217  0.01237399  0.00062842  0.02053702\n",
      "   0.00489117  0.00276993  0.00339822  0.01299564  0.00189149  0.00155997\n",
      "   0.00675344  0.02381798  0.01069697  0.00339822  0.03071013  0.01561802\n",
      "   0.02633174  0.0383928   0.00191146  0.0069208   0.00675344  0.03378808\n",
      "   0.01397259  0.00375905  0.01138923  0.00276993  0.00097763  0.01457702\n",
      "   0.0069208   0.01148641  0.00489117  0.00209907]]\n",
      "classEstimate:  [[-1.  1.  1.  1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1.  1. -1.  1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1.  1. -1. -1.\n",
      "   1.  1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1.  1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1.\n",
      "   1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1. -1.  1. -1.]]\n",
      "current error:   0.03\n",
      "D: [[  1.44065860e-03   3.87814395e-02   2.83612634e-02   5.33282833e-03\n",
      "    7.36326150e-03   4.60550034e-02   7.68411601e-04   1.43333439e-03\n",
      "    1.31343348e-02   1.36804846e-02   6.39146493e-03   9.42706124e-04\n",
      "    3.60572301e-03   3.68255723e-03   5.93297753e-04   7.51804500e-03\n",
      "    1.40216587e-03   2.33719423e-02   9.63332398e-05   2.55807372e-03\n",
      "    5.07681580e-03   5.33282833e-03   2.22578719e-02   3.95292888e-03\n",
      "    2.38172320e-03   5.07681580e-03   4.49430843e-04   1.92788066e-03\n",
      "    5.13653824e-03   6.68704472e-03   3.60826901e-03   8.40572327e-04\n",
      "    2.63290430e-02   4.49430843e-04   2.07513326e-03   3.40749682e-02\n",
      "    3.92008197e-02   9.55446684e-04   7.11415761e-03   8.40572327e-04\n",
      "    1.94137250e-03   1.78656176e-04   4.09848859e-03   1.94137250e-03\n",
      "    3.60572301e-03   1.76525884e-03   1.06590671e-03   5.65014032e-02\n",
      "    6.52967575e-03   8.40572327e-04   1.43333439e-03   5.93297753e-04\n",
      "    1.52342798e-02   2.84234724e-03   1.94137250e-03   2.51561717e-02\n",
      "    5.98149653e-03   6.68704472e-03   2.55807372e-03   2.83612634e-02\n",
      "    2.33719423e-02   3.13830733e-03   5.98149653e-03   5.98149653e-03\n",
      "    4.34986899e-02   7.64000408e-03   2.84595584e-04   2.38172320e-03\n",
      "    1.62835744e-02   1.34913316e-02   6.85161061e-04   2.23914660e-02\n",
      "    5.33282833e-03   2.55807372e-03   3.13830733e-03   1.20016725e-02\n",
      "    1.74682330e-03   1.44065860e-03   7.36326150e-03   2.59686936e-02\n",
      "    1.16628822e-02   3.13830733e-03   2.83612634e-02   1.70282966e-02\n",
      "    2.43177599e-02   3.54563285e-02   1.76525884e-03   6.39146493e-03\n",
      "    7.36326150e-03   3.68390676e-02   1.52342798e-02   4.09848859e-03\n",
      "    1.24176528e-02   2.55807372e-03   1.06590671e-03   1.34620979e-02\n",
      "    6.39146493e-03   1.06078684e-02   5.33282833e-03   2.28860857e-03]]\n",
      "classEstimate:  [[ 1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "   1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.\n",
      "   1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1. -1.  1.  1.  1. -1.  1.]]\n",
      "current error:   0.04\n",
      "D: [[ 0.00156173  0.0359912   0.03074477  0.00494914  0.00798208  0.04274144\n",
      "   0.00083299  0.00155379  0.01423816  0.0126962   0.00692861  0.00102193\n",
      "   0.0033463   0.00399204  0.00055061  0.00814987  0.00130128  0.02533615\n",
      "   0.00010443  0.00237403  0.00471155  0.00494914  0.02412845  0.00428514\n",
      "   0.00258189  0.00471155  0.0004171   0.00178917  0.00556822  0.00620593\n",
      "   0.00391151  0.00078009  0.02854176  0.0004171   0.00192583  0.03162335\n",
      "   0.0424953   0.00103574  0.00771204  0.00078009  0.00210453  0.00019367\n",
      "   0.00444293  0.00210453  0.0033463   0.00191361  0.00098922  0.05243624\n",
      "   0.00605988  0.00078009  0.00155379  0.00055061  0.01413821  0.00263785\n",
      "   0.00210453  0.02727032  0.00555114  0.00620593  0.00237403  0.03074477\n",
      "   0.02533615  0.00291251  0.00555114  0.00555114  0.04036905  0.00709032\n",
      "   0.00026412  0.00258189  0.01765206  0.01252066  0.00063587  0.02078045\n",
      "   0.00494914  0.00237403  0.00291251  0.01301031  0.00162114  0.00156173\n",
      "   0.00798208  0.0241003   0.01082376  0.00291251  0.03074477  0.01580315\n",
      "   0.02636145  0.03290532  0.00191361  0.00692861  0.00798208  0.03993506\n",
      "   0.01413821  0.00444293  0.01152423  0.00237403  0.00098922  0.01249353\n",
      "   0.00692861  0.01149937  0.00494914  0.00212395]]\n",
      "classEstimate:  [[-1.  1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1.  1. -1. -1.  1.  1. -1.  1.  1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.03\n",
      "D: [[  1.44730982e-03   3.90809043e-02   2.84922013e-02   4.58653426e-03\n",
      "    7.39725612e-03   4.64106337e-02   7.71959195e-04   1.43995179e-03\n",
      "    1.31949732e-02   1.37861233e-02   6.42097296e-03   9.47058398e-04\n",
      "    3.63356589e-03   3.69955881e-03   5.10269655e-04   7.55275422e-03\n",
      "    1.41299320e-03   2.34798456e-02   9.67779900e-05   2.57782681e-03\n",
      "    5.11601826e-03   4.58653426e-03   2.23606318e-02   3.97117871e-03\n",
      "    2.39271911e-03   5.11601826e-03   4.52901285e-04   1.94276748e-03\n",
      "    5.16025255e-03   6.73868114e-03   3.62492762e-03   8.47063108e-04\n",
      "    2.64505986e-02   4.52901285e-04   2.09115715e-03   3.43380903e-02\n",
      "    3.93818016e-02   9.59857778e-04   7.14700216e-03   8.47063108e-04\n",
      "    1.95033540e-03   1.79480993e-04   4.11741044e-03   1.95033540e-03\n",
      "    3.63356589e-03   1.77340867e-03   9.16740117e-04   5.69376991e-02\n",
      "    6.58009699e-03   8.47063108e-04   1.43995179e-03   5.10269655e-04\n",
      "    1.53519168e-02   2.86429544e-03   1.95033540e-03   2.52723124e-02\n",
      "    5.14442564e-03   6.73868114e-03   2.57782681e-03   2.84922013e-02\n",
      "    2.34798456e-02   3.16254090e-03   5.14442564e-03   5.14442564e-03\n",
      "    4.38345807e-02   7.69899911e-03   2.86793191e-04   2.39271911e-03\n",
      "    1.63587523e-02   1.35955097e-02   6.90451778e-04   2.25643697e-02\n",
      "    4.58653426e-03   2.57782681e-03   3.16254090e-03   1.20570817e-02\n",
      "    1.76031203e-03   1.44730982e-03   7.39725612e-03   2.61692202e-02\n",
      "    1.17529413e-02   3.16254090e-03   2.84922013e-02   1.71597867e-02\n",
      "    2.44300298e-02   3.57301172e-02   1.77340867e-03   6.42097296e-03\n",
      "    7.39725612e-03   3.70091458e-02   1.53519168e-02   4.11741044e-03\n",
      "    1.25135402e-02   2.57782681e-03   9.16740117e-04   1.35660503e-02\n",
      "    6.42097296e-03   1.06568427e-02   4.58653426e-03   2.30628089e-03]]\n",
      "classEstimate:  [[ 1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "current error:   0.05\n",
      "D: [[ 0.00157204  0.04244887  0.03094764  0.0049818   0.00803475  0.04299902\n",
      "   0.00083849  0.00156405  0.01433211  0.01277272  0.00697433  0.00102868\n",
      "   0.00336647  0.00401838  0.00055424  0.00820364  0.00130913  0.02175386\n",
      "   0.00010512  0.00238833  0.00473994  0.0049818   0.02428765  0.00431341\n",
      "   0.00259892  0.00473994  0.00041961  0.00179996  0.00560496  0.00624333\n",
      "   0.00393732  0.0007848   0.02873009  0.00041961  0.00193744  0.03181392\n",
      "   0.0427757   0.00104258  0.00776293  0.0007848   0.00211841  0.00019495\n",
      "   0.00447225  0.00211841  0.00336647  0.00192624  0.00099574  0.05275225\n",
      "   0.0060964   0.0007848   0.00156405  0.00055424  0.01422341  0.00265374\n",
      "   0.00211841  0.02745026  0.00476626  0.00624333  0.00238833  0.03094764\n",
      "   0.02175386  0.00293006  0.00476626  0.00476626  0.04061233  0.00713305\n",
      "   0.00026571  0.00259892  0.01515623  0.01259611  0.0006397   0.02090568\n",
      "   0.0049818   0.00238833  0.00293006  0.01309615  0.00163091  0.00157204\n",
      "   0.00803475  0.02424554  0.01088899  0.00293006  0.03094764  0.01589838\n",
      "   0.02653539  0.03310362  0.00192624  0.00697433  0.00803475  0.04019857\n",
      "   0.01422341  0.00447225  0.01159368  0.00238833  0.00099574  0.01256882\n",
      "   0.00697433  0.01157524  0.0049818   0.00213675]]\n",
      "classEstimate:  [[-1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1.  1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "current error:   0.03\n",
      "done training\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done teting\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "classifier = train(df.values[:, :6],df.values[:, 6],150)\n",
    "print('done training\\n')\n",
    "#testing\n",
    "test(X_test,classifier)\n",
    "print('done teting\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tylerkistler/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEJCAYAAACdePCvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4FFXWwOFf9ZJ9h4AKQgDhisiggjuOCIo7yrghOKKI\ngoiKuLOLoII6iKMgKiOojNsoKo6juI0o6riAoh9wlVWQLYFAIHsv3x/V6XRn7YTudJM67/PMQ3dV\nddXpmlin7711TxlerxchhBDWY4t2AEIIIaJDEoAQQliUJAAhhLAoSQBCCGFRkgCEEMKiJAEIIYRF\nOSK1Y6WUDZgD9ABKgeFa63UB6+8AhgO5vkUjtNY6UvEIIYQIFrEEAFwKJGitT1VKnQI8DlwSsL4n\ncK3W+ocIxiCEEKIWkewC6g18AKC1/gboVWV9T+B+pdSXSqn7IxiHEEKIGkSyBZAG7At471ZKObTW\nLt/7V4GngQJgsVLqIq31e7XtzOVyex0Oe+SiFUKI5smobUUkE0ABkBrw3lZx8VdKGcATWut9vvf/\nBo4Hak0A+flFjQ4kOzuV3Nz9jf58pEhcDSNxNUysxgWxG1tzjCs7O7XWdZHsAloOXADgGwP4OWBd\nGvCLUirFlwz6AjIWIIQQTSiSLYDFwDlKqa8wmyDXK6UGAyla62eVUuOAzzDvEPpEa/1+BGMRQghR\nRcQSgNbaA4yssnhtwPqXgJcidXwhhBB1k4lgQghhUZIAhBDCoiQBCCGERVkjAcyfT9p1Q0CefiaE\nEH6RvAsodgwfTjxg27Edz+FHRDsaIYSICdZIABWMWifECRHTVqz4nkmT7icnpwMALpeLK664mn79\nzuG33zRffrmM66+/MazH/Pzzz+jW7VhatswOafvS0lKuuGIAgwYNYfDga2vcZsCAc3n33Q9r3cfl\nl19M69aHYRgGxcXF9O17NkOGDG1U/FXV9H3+/vdZaL2GPXt2U1JSQk5Oe5KSUpk2bUbI+92+fRsb\nNqzn9NPPCFo+cOAFtGnTNmjZ7bffSefO6uC+SBhZKgF4DWv0eInmqWfPXjzwwMMAFBUVMXr0TbRr\n147OnVVELipvvPEKOTnjQk4An3/+Kf369ef9999j0KBrsNka99/b3/72FPHx8ZSXlzNkyOVccMHF\nZGZmNWpfgWr6PrfeegcA77+/hM2bNzFp0rgGz7j9/vtv2b59W7UEAPDEE3NwOGL3Mhu7kUWAgRcZ\nBRAHK3nKBOKXvF25wGaQ5Tm4v6zSiy+lcMq0kLdPSkrikkv+wmeffcL+/ft55503eeCBh3nooQfY\nunULpaWlDBt2Haef3o/ly7/ghReew+v10qXL0dx99/0MHTqII49sj9Pp4O67x/PII1PZt88s3TVm\nzN3s3LmDdet+Zdq0ScyZM5933nmTjz76EMMw6NevP1dcMahaTEuWvM1tt91Jfv4evv56OaeffgZu\nt5uZM6ezceMG2rRpS1lZGQC//vorU6dOw+PxsHfvXu666z66d+8RtL+SkhIcDgfx8Qm4XC4eeugB\ntm37A7fbzaBBQ+jXrz+//rqWWbMexW63ExcXxz33TCAzM5NJk+6jsLCQkpISbrppFC6XK+j7OJ3O\nes/xnDmz+fnnVXg8HgYP/itnntmXN954laVL/4PNZuPYY7szcuSt/POfL1JWVsaxx/6J007rXe9+\nlyx5mw8/fB+3282wYTcxc+Z02rY9kk6dOjNw4OXMmGGeF4A77riH9u1z6Nu3L0cc0ZZOnTozevSY\neo8RKkslANzuaEcgRNhkZWXx66/+uZUUFRXy448rmDdvAYZhsHbtj7hcLmbNmslzzy0kMzOLRYsW\nsmvXLoqLi7nuuhvo0uVo5sx5kp49T2LgwMvZsuV3HnroAebOnc9RR3Xh7rvHsXXrFj755CPmzHke\ngDvuuIWTTz6Fdu1y/MfesuV3SkqK6dy5CxdeOIBXX13E6aefwbJln1FWVsazzy5gx44d/Pe/nwCw\nbt06Ro++g06djmLp0g94//0l/gQwduxoDMNg8+ZNnHrq6SQmJvLWW6+TkZHBpEkPUlRUyLBh19Cz\n50nMmDGd++6bQOfOii+++C9PPfU3hg0bwb59+3j88SfJz89ny5bNnHZab//3CeXi/+WXy8jNzWXu\n3PmUlpZw003X0avXSbz//rvcf/8kOndWLF78L2w2G4MHX8v27dtqvPiPGTPK/9rpdDJr1tMApKen\nM336o7hcLnbt2sk//rGI1NRU7r//TgYNuobTTuvN2rVrmDFjGnPmPM+OHTt4/vmXSU2tva5PY1gr\nAbhc9W8jRD0Kp0wL+rWenZ3KnigUENuxYwfZ2a3875OSkrnttjuZOXM6RUWFXHbZQPbt20tqaqq/\nCyWwP73iAr5hwzpWrPieTz5ZCsD+/QVBx9mwYT07d+7g9ttv9q3fz5YtW4ISwJIlb1NcXMLYsbcC\nXn7+eRVbt25hy5bf6dq1GwCHHXYYrVq1BqBVq1Y8//zzxMfHU1RURHJysn9fgV1Ad911O0uX/odN\nmzbRq9dJ/u+Zk9OBP/7YSl5err/7q0ePE3jmmafo2LETl1zyF6ZMGY/L5eLyy6u3VuqzYcM61qxZ\nzejRNwHgdrvZuXMHEyZM5ZVXXmLHju10794Dbz13FtbWBRR47jIyMv0X9k2bNnLccccDcPTRXdm+\nfRtgJvtwX/zBaglAWgCimSgsPMCSJYuZNm0GeXl5AOTl5aH1Gh5++DFKS0u5/PKLeOut9zlw4AAF\nBftIS0vniScepX//8wEwfDdFtG+fQ//+x9C//3nk5+9hia97y2az4fF4aNeuPTk5HXn88ScxDIPX\nXltEp06d/bG4XC4++WQpL7ywiLS0dAAWLpzP4sVv0KPHCXzyyYfA1eTl5ZKbaz4AcPr06Ywb9wA5\nOR2YP3+e/0IXyOl0kpWVRXl5OTk5OaxatZIzzzyLoqJC1q9fzxFHHEHLltmsW/cbRx3VmR9/XMGR\nR7Zj/fp1FBUV8uijs8nLy+Pmm4dx+uln+L9PKNq3z6FXr5O46677cLvdLFjwPIcf3oZ5857innvG\nExcXx+2338zq1b9gGEa9iaAqI+CGlMCxkpycDvz000pOPbU3a9eu9if4xo6n1MdSCcDwSAIQh64f\nfvie0aNvwm6343a7ueGGEbRrl+NPAC1atGDPnt2MHDkMm83GsGHDcDqdjB17L3ffPQabzUaXLsr/\ni7zCtdcO45FHHuTdd9/yda+Yv3qPPfZPTJs2mVmznqJXrxMZNeoGysrK6dq1G9nZlQOpy5cvQ6mu\n/os/wIUXDuC6665m+PCb+e67/3HjjUM57LDDycjIAGDAgAFMnHgvqalpZGe3Yt++vf7Pjh07GpvN\nhtvtplWr1vTvfz6GYTBjxjRuvvkG3/jGjWRmZnHvveOZNWsmXq8Xu93OffdNpGXLbF544Vk+/fRj\nPB4PN9wwotr3CYy1Jn/+81msXLmCUaOGU1xcRJ8+/UhMTCQnpwO33DKcxMQkWrVqzdFHH0NcXByL\nFi2kc2dF375nB+0nsAsIYNCgIXUed/ToO5g58yFefnkhbreb++6bUOf2B8toaOaKltzc/Y0ONLtV\nGgB7vvwOd5fYuQWrOdYejySJq2FiNS6I3diaY1zZ2am13v9urfsipQtICCH8rJUAZBBYCCH8LJUA\nZAxACCEqWSoBSBeQEEJUkgQghBAWZakEYEgCEEIIP0vNA5AWgDhUSTXQgxfuaqANOe/z58/jo48+\npGXLlv5lJ554MkOH3tC4LxMmkgCEOERINdCDE+5qoA0974MGDebSSy9vWNAR1vwTQODUb0kAIgym\nTIlnyZLK/3RsNvB4kuv4RP0uvtjFlCmlIW8v1UAjWw10xYrvmTv37zidTgYMGEh8fDxvvfUGLpcL\nwzB46KHH2LBhnf+8Dxo0kO7de/D775vJyspi2rSZ2O32kP6/vOyyi2jfPoecnA7s37+fffv2UVCw\nj5kzn2DhwvmsWvUjTqedPn3O4corr2b69ClB26SlpYV0nJo0/wQQcO+/3AYqmhOpBhq5aqAAZWVl\nPPfcQgBefPEfPProbBISEpg5czrffvt1UEti27Y/mD17Lq1bH8bNNw9jzZrVHHts96D9vfrqP/n4\n46X+90OHDuPEE0/xVQN9mfT0DKZPn0LPnr246qohLF/+Bdu3b+PZZxeQmZnIFVdcRc+eJwL4tzlY\nlkoAuCQBiIM3ZUpp0K91c5p+YZPHIdVAI1cN1Dw/7f2vMzOzmDZtMklJSWzevIljj/1T0Lbp6Rm0\nbn2Y77u1pqysemuuti6g9PQM0tMzqh138+aN9OhxHIZh4HQ66datO5s2bagW28Fo9gnAcJVXvpEu\nINFMSDXQyFYDNb+/eX4OHDjA/PnzePPN9wCzBVS1hlpgdc+GqjpWYvieXNi+fQfef/9drrpqCOXl\n5fzyyyrOP/8i4Cv/Nger2SeAoBaAJABxCJNqoE1XDTRQcnIy3bv3YOTI67HbHaSmppKXl8vhhx/R\noP//qnYBtWvXnnvuGV/r9qeffgYrV/7AiBHXAx769OmLUkc36Jj1afbVQI2dO2nZ3fy1UvDcAkov\n+UtY4zoYzbHyYCRJXA0Tq3FB7MbWHOOydDVQwx04BiDF4IQQokKzTwCUyxiAEELUpNkngKAWQAMG\ngIQQorlr9gmA8oB5ANICEEIIv+afAOQuICGEqFGzTwBB8wBkEFgIIfysNQ9ASkGIQ1RgNVDDMCgs\nLOSII9owefK0kEsbAGzfvo3Jk8fx7LMLqq1bvfoXRo0azty586vNFQDYvHkTjz76EE899Wyt+x46\n9Gq6dDFn5hYXFzNy5C2ceOIpIcdXlzfffI3LLrsqaNntt9+M2+3m9983k5mZSWpqWoOrbK5Y8T0Z\nGZl07NjJv2zr1i3ccMM11Yq91fbdD1XNPwHIGIBoJgKrgQJMmTKeL7/8nLPOOjss+1+y5G0GDbqG\nt956g/HjqyeAUOTkdPBfJH//fTPjx9/NSy+9Hpb4Fi78R7UEMHv2XACmT59Cv379OeWU0xq83/fe\ne4fzz78oKAEAdOx4VLO74FfV7BNA0F1AbrkLSBy85F8nEL/z7coFdoMs98FNqCxtfSmFXaaFvH15\neTm7d+eRmmpWgnzmmaf46aeVeDwerrpqCH37ns23337LrFmz8Xg8FBcX19laKCoq4ocfvuOll15n\n6NBB7N27l4yMDPLy8pg6dQJer5esrBb+7T/77ONq1TGr2r9/v78G0fbt23j44am43W4Mw+CBBybT\nokUbli79D6+//gpOp5Mjj2zHPfeMZ9u2P3j44Qew2x14PB4mT57GBx/8m4KCfTz22CPcddd99Z6f\ngoICHnnkQfbvL8AwDO644x5ycjowbdpktm/fRmlpKVddNYS2bdvy3Xf/Y/36dTz22Gyys1Pr3ffU\nqRMpLDTLawwZMpQXX3wBh8PBpZdeTlpaGvPnzyMuLo6MjAzuv38ya9b8H889N9e/Tf/+59V7jKYS\nsQSglLIBc4AeQCkwXGu9robtngX2aK3r/3+1MVwyEUw0DxWlIPbuzccwDAYM+Au9ep3E118vZ/v2\nP5g7dz6lpaWMGHE9J554Mr/99huTJj1Iy5bZvPjiP/jss4/9dYCq+uSTpZx5Zl/i4+Pp2/cc3nvv\nba655jpefHE+Z599LgMGDOSTT5ayePG/ALP6Z9XqmN2792DTpo2MHn0Tbreb337TjBlzNwBPP/0E\nV1wxiDPO6MNvv2nGjRvHzJmzmT9/Hi+8sIikpGSefPJx3nnnTcCga9dujBp1Oz/9tJLCwgMMHXoD\nb775ekgXfzBrEZ1yymkMGDDQ33X10EOP8X//9zPPPPMCXq+HH374jmOOOZYTTzyZ88+/KKiwHphF\n8kaPvsn//phjzJjAfJjL5ZcP4rvv/ofL5eLZZxfg8Xi48spLeOaZF2jZsiWvvPIyL730Ar16neTf\nJtZEsgVwKZCgtT5VKXUK8DhwSeAGSqkRQHfg80gFETgILOWgRTgUdpkW9Gs9OzuVPU1QPqCiC2jf\nvr3cccct/lo0GzasQ+u1/ouVy+Vix45ttG7dmieeeJTExCRyc3dVq7cfaMmSt7Hb7YwdeyulpSXs\n2rWLwYOvZcuW37n44oEAdO/ew58AaquOGdgFtHt3HsOGDaFXr5PYtGkTPXqcAJgPUtmxYwfbtv1B\nhw4dSUoyK4H26HEC3333DbfeOpZFixZy5523kpycwogRtzT4XG3YsI5Vq1aydOl/AHzF8NK45Zbb\nmTHjQYqKijjvvAvr3EddXUCBlVArKnPu2bOHtLR0/1O/jjvueF544Xl69TopbNU7wy2SCaA38AGA\n1vobpVSvwJVKqdOAk4F5QHgrHAUKLAEtYwCiGUhPz2DixAe57baRHH30P2nfPofjj+/FvfeOx+Px\nsGDB87Rp05ZBg27l1VcXk5SUzLRpk2vd3/r16/B4PEG/UMeMGcVXX31BTk5H/u//VtG5cxfWrFkN\nhFYdEyAtLZ24uATcbre/mmfv3mfy22+ali1bcvjhbdi0aSPFxcUkJib6q3l++eXn9OhxPMOG3cRH\nH33AokULGTduco3HqE379jl0734c/fqdw+7debz//nvs2rWT9evX8fDDj1NSUsJll13IuedegGEY\nDdo3BFf/rKjmmZmZSUHBPvbs2U1WVgtWrjS/T+A2sSaSCSAN2Bfw3q2UcmitXUqpw4HJwEDgylB2\nlpmZhMMR2hN2giRVfsXkBAfJIfTxNaVQ+hyjQeJqmEjHlZGRRHy803+c7OweDB16LXPnzmL27Nms\nXfszt98+gqKiIs4++2zatz+MAQMGcNttI0hMTKRly5YcOLCXrKxknE57ULzz5v2byy4bGLRsyJCr\n+de//sVjjz3G3XffzbJln9K2bVvi4hzk5BxGr149GT16OA6Hg7S0NIqLC8jKSmbz5o2MHTvK/0zf\nq6++iuOO68rEieOZOHEi//rXK7hcLqZPn07nzkcyZsztjB07CpvNRrt27bjxxuvZuXMn9957L//8\np9mtcv/995OdnUrnzkcxY8YDPPZY9fGGhAQn6emJ/u9w551jGD9+PP/+92IKCwu57bbb6Nq1I6+8\nsptbb70RwzAYMWIErVunc/LJvZg37+907dqJ7OxUsrNTKSpKZuPG9YwdOyroODNmzCA+3kFGRhLZ\n2am+/18c/uNOm/YgEyfeg81mIyMjg0ceeYTVq1cHbdNYkfgbi1g1UKXU34BvtNav+95v1Vq39b2+\nDRgK7AcOA5KASVrrBbXtr7HVQOPfeYu0G68DoHDs3RTdN7Exu4mI5lh5MJIkroaJ1bggdmNrjnHV\nVQ00ki2A5cDFwOu+MYCfK1ZorZ8EngRQSl0HHF3Xxf+gBBSDM+SJYEII4RfJBLAYOEcp9RVgANcr\npQYDKVrrpru5VkpBCCFEjSKWALTWHmBklcVra9huQaRiADAkAQghRI1ic2g6nKQUhBBC1MgCCSBg\nDEBaAEII4dfsE4DhLjanmhkEzwkQQgiLa/a1gByZv8B9wDSkC0gcsqQaaPirgb7//hLS0tLo3fvM\nercdPfomSktLiI9P8C8bPPhaTjutd8O/SAxp9gmgvOcJJGx4A9KRQWBxSJNqoOGtBnrBBRc36PgT\nJkylffucBn0m1jX7BOBNzDBfxMsYgAiPKV9NYMn6ymqgNpuBx3NwEyov7nQpU06TaqDhqgY6f/48\nfvllFcXFxdx330Q++ODfrF27moKCfRx1VBfGjZvM/PnzaNGiBe3a5bBo0Ys4nQ527drBmWf2C/l5\nAitWfM/cuX/H6XQyYMBAFi1ayJFHtsfpdHDXXeN48MGJFBYW4na7ufHGm+nZ80T++tcr/dsEJvRo\naP4JwG4WmiIeqQYqDmlSDTT0aqAA7dt3YMyYuygsPEBqaipPPDEHj8fDX/96Jbm5u4K23blzOwsW\nvEJ6ejy9e/euMQFMmzYpqAvowQdnAFBWVsZzzy0E4Pnnn+G6626gS5ejeeqpJ+jV62SuvPJqcnN3\nMWrUcF5//R2Ki4v920Rbs08A2JPMf+Mh4c3XcR1/AsU3jar7M0LUYcpp04J+rTdV+QCpBtowFRU4\n4+MTyM/PZ/LkcSQlJVFcXIyryo/Bjh2PwuFwkJSUFHSRD1RTF9DGjVSr9FlRKXTz5o3+2v/Z2a1I\nSkomP39P0DbR1uwTQFALAEiZcJ8kAHFIk2qgobHZzBI433yznF27djJ16sPk5+ezbNln1fZl1Fot\nJ/TjVO7LfN++fQd++ulHunQ5mtzcXezfX0BaWnrQNtFmgQTgawHUnNSFOCR16NCRyy+/iieeeJQH\nH3yElSt/YNSo4RQXF/HnP59FUlIyAwYMYNSoG0lMTCAzswV5ebk17mvJksWce+4FQcsuvnggb775\nOpMnT2fq1Al8/PFSjjiiDQDJycl0796DkSOvx253kJqa6t93RReQzWajuLiYAQMupU2bttxyyxhm\nzJjGK6+87K8GmpGRwbBhI7jtthEYho22bY9k5MjR5OXlMm3aZBYunI/H4+HWW8cCZuti6tSJTJr0\nYIPOVdeu3ViwYD633GJWAT3iiDa1nou6VO0C6tevf52Dwtdeez0PPzyV//73E0pLS7nnnvE4HLF1\nyY1YNdBwa2w1UHvhb2R91RM+Beb79rWrIIyRNV5zrDwYSRJXw8RqXBC7sTXHuOqqBtrsJ4JVtABW\nxR8b5UiEECK2WCYBbIjvxE5a1bO1EEJYhwUSgDkInJJwAE/z/7pCCBGy5n9FtMVR5nKSHF+IDU+0\noxFCiJjR/BMAUFiaTHJ8YeWCkpLoBSOEEDHCUgmgogvIKIiNu4CEECKarJEASpKDxgBs+/dFOSIh\nhIg+SySAA6UpJMcX4sYOSAtACCHAIgmgsDSZpLgiPJjzISQBCCGERRLAgZIUbDYv7V7YAr0h44pL\naNGxDYlPPxnt0IQQImoskQDm//cGfth4ArY4L3Q2l9kO7CflgQnRDUwIIaLIEgngre8u4+qnXgHA\n1e2YKEcjhBCxwRIJAMDtMQeAvXGxVY1PCCGixTIJwOXxXfjj7NENRAghYoRlEkBFCwCntACEEAIs\nlABcbvPC73VKC0AIIcBCCaCyBVD5lb3x8VGKRgghos96CcARkACSk6MUjRBCRF+zTwAVT7z0DwIH\nJYCUKEQkhBCxodknAJfL/NffArBXPh5TWgBCCCuzTAKoGATGEZAAEhOjEJEQQsQGyyQAfwvA8EYv\nGCGEiCHWSwBed+VKtzwiUghhXc0+AZSXV3T5GHiwYXhdHJg41VxSkR2EEMKCIjYtVillA+YAPYBS\nYLjWel3A+suA+wAvsEhrPTsScbgDfvB7cYDXTfGtY0h6+gnwuGv/oBBCNHORbAFcCiRorU/FvNA/\nXrFCKWUHHgHOBk4FRimlWkYiiPLyytde7OD1/eq32Sv7h4QQwoIimQB6Ax8AaK2/AXpVrNBau4Gu\nWut9QAvADpRFIojAa7zXawev2e/vtduDmwdCCGExIXcBKaUytdb5Ddh3GhD49HW3UsqhtXYBaK1d\nSqm/AE8D/wYK69pZZmYSDkfD6/jk5VW+9hoO4uwesrNTIc4JXt/rKIr28WsjcTWMxNVwsRqbleKq\nNwEopY4DXgWSlFKnAp8DV2qtV9Tz0QIgMGJbxcW/gtb6LaXU28AC4Frghdp2lp9fVF+oNdq1ywaY\nE748Xjuu8nLyc/eTZdig3MWe3P2N2m84ZGenkhvF49dG4moYiavhYjW25hhXXYkjlC6gJ4GBwG6t\n9R/AzcAzIXxuOXABgFLqFODnihVKqTSl1OdKqXittQfz139E7skM7ALyYPffBipdQEIIqwulCyhJ\na71GKQWA1vojpdRjIXxuMXCOUuorwACuV0oNBlK01s8qpRYBy5RS5cAq4OXGfYW6VR0DMCoGgVt6\nMIwinPlf1fg5jzMLd8rRkQhJCCFiQigJYI9Sqgfm7ZoopYYAe+r7kO+X/cgqi9cGrH8WeDb0UBun\nch4AeHCA14NRvgf7rZsw7JDx/Xm1fnbPKV/iTv1TpEMUQoioCCUB3AwsBLoppfYCvwFDIhpVGAX2\n8ni8dvCWYyvZjmEH7yY7RWeNrfYZ577vidvzGfaSPyQBCCGarVASQILWurdSKhmwa60LfH36h4TA\neQBmC6AEw1VgLlhto+jGidU+k7DlOeL2fIbhrvPGJCGEOKTVmgCUUqdj3p//vFLqBsx+fJRSDsxB\n4C5NEuFBCpoJ7BsDsFUkgKKaC8N57UkAGO7G3XkkhBCHgrpaAOcAZwKHA1MDlruAeZEMKpyCWgBe\nB+CubAEU1nzjkdduPigmdfVoktY/7F9eevhVFHaeEqFIhRCiadWaALTWUwCUUn/VWr/UZBGFmcsV\nOAhs3gbqTwAHaksASf7XtvLdeOIPw1ayhfidb0kCEEI0G6GMAXyrlJoNpGB2A9mBDlrrP0c0sjAJ\nmgfgtWMEJACjCPOZkYYR/CF75ZPCyrL6UHD862R+dTK2sh1NELEQQjSNUCaCvQbsBY4HfgRaAb9E\nMqhwqpoA8LoDxgCocTJYYAvA60jz/2u4CiofMiyEEIe4UBKATWs9GbOw2wrMKp8nRzSqMAoeAzCr\ngRouX4miYmqsCOoNaAF4Han+fw2vGzwyMCyEaB5CSQBFSql44Fegp9a6FEiIbFjh43YHjAF4HcFj\nALW2AAITQLr5WV9LwFZeELlghRCiCYUyBvAysARz8tfXSqnzgD8iGlUYBbYA3F47Bt7KFkARGG4X\nVTt1AruAPP4uIDMRmMnj8AhGLIQQTSOUFsAy4DKtdS7QB7N8w8BIBhVOwTOBzXxnK99jduWXEEIL\nIC3oX3/yEEKIQ1woLYDXtNZdAbTWW4GtkQ0pvMrKvJC8Ewpbm2MAgFGeD+UO8Lpw/LwKT2YW7s5d\nMAoLIc6JNy7e//mqCcBevBFXxkmVB3AXmxVGHSlN96WEECIMQkkAq5VSk4D/YQ6bAqC1XhaxqMLo\nZ+NVuHsYzPset78FkA8uJ+Ai4/IB1T5TdlpvuMV8XXHhr+gKSvvlRvbZUylrdQEAWV/1xF6yldxz\nZGxACHE6fKZWAAAZQklEQVRoCSUBZAFn+f5XwQv0jUhEYdbx2J1msem0rXg8vhaAaz9edzxGLZ+J\n++pLfwLw+Pr+KxIBQPyud/0JwF7iaxB5ysHmjMRXEEKIiKg3AWitz6pvm1iWme77ivYy3BVdQN4y\nvO7KgV53TgfsmzbW+HlvlUFgAHdSB9/KyuFjW1kengQZHBZCHDoi+VD4mOC0xZkv7GW4PZX5zuut\n/LXu6lx7XbuqYwAAXsPcZ+CAsK1sV1jiFUKIptLsE0CcvSIBlOPxBnzdwGSQmVXr51NuuR3n8i+C\nykUYnhIAbGW5lcsCXgshxKGg3gSglKr6VK9DisMW2AUU0OMVkAAK759IeY/jKT3vgsr1LwMrIf69\nj8kYeCHlaT3x2nxlomtIANICEEIcakJpAYyOeBQRFFfRBWQr9w8CAxCQDDxt2rL3o88pePFVXMcc\nay78DxD45GN7AvknLTVfu82boYyAi76tLC8C0QshROSEchfQFqXUp1S/DXRq7R+JHY6KO3PsZbg8\nlf3+gWMAgbyJtVS5KC8HWyIgLQAhRPMQSgL4JuB1bXdOxqw4e2UCcAeMAXg9tSSAhMQalye8ugh3\nlxbmPrd9TMrnN5PQfjH4duNctQyj5W68mVnEv/UGZWf1w5vVInxfRAghwiyU20AfUEplY1YAdQBf\na613RjyyMKm8C6g86C4giKtxe29CzS2A1Dtvg1TgGbB7t5J41KLg42z6kYRFL+Fp1460m4dT3usk\n9r7/cRi+gRBCREYog8DnYj4H4HpgKLBKKXVRpAMLF2dAF1DgGICXWiZt1dICAKCs+qJixzV4PXGQ\nBrYd27Bv3GAe9/tvGxuyEEI0iVAGgacDvbXWl2mtBwKnAtMiG1b4OCu6gGzluIIGgWvrAqqj0nUN\nCaDk+GvxxLeCdLDlya2gQohDRygJwKm19k+T1VpvCPFzMSGwBRDUBVTbGEBiHS2AGh4G5onLxpPQ\n2mwB5O6CYnlgjBDi0BDKIPDvSqkxwHzf++HA5siFFF7BM4EDft27zBzmdQSfgjpbADXwViQAB9gO\n7MSWJ7eDCiEODaH8kr8Bs9tnA7DR9/qmSAYVToEzgYNKQVQ8KMZZpSVQ1xhADbz2VDxx2QDYSndh\nyw3oBpLnBwshYlgoLYDbtNZXRTySCAmcCRw0BlBu3tHqdQbfDdTQFgCG4U8Ahncvtp3bK1cd2I83\nNa22TwohRFSF0gK4WCl1yN3/XyFwJnDQGEDFgK7z4LqAwOwGAjDSwKHX+pfbcmVymBAidoXSAtgN\nrFVKrSB4JvCwiEUVRo6AiWAud0ALwJcAqrYAGjPXzRPXynwxBIyCykHg9H+fT9m2ATh++QVKSoI+\n4/pTD9i/l+TD2uJNSKBo3CRzRWEhqXfcguewIzD27cW2Zze2HTsaHFOtEhJwHdsdXG7sGzdg7Ntb\nfRuHjQyXJ3zHDBeJq2FCjMtzRBsKnn0B4uPr3VY0L6EkgIURjyKC4mq7C6jU1z9fdQzAG/p/yPu7\nzgagPL0nHm8WRuoeSAEMMOxgd+wk8ZnnINfXsrD5ElBJMc6fVgJQ8VSC4tvuwJuSSsIbr5Lw9lvB\nITmdUC1RNYLHjVFSgvN/X1fuOz4e7FX+DAxwxOLwhcTVMKHEVV6G8dNKnCt/oPyU05okLBE7QkkA\nQ7TW/SMeSYQ4AwaBg8YAysz/MrxVEoBRw0Pia1LoGUtJ2+sB8CTmsLv/pspjfvMVGc+fB1cBRwK5\nsPu7n/G2bg1Ayh2jSVz0YtD+7GtW4zrx5BrnEux/ci6ll10ZUlx1MXbupGX3zkHL9r7xLq5TTg1a\nlp2dSl7u/oM+XrhJXA0TSlzxr79C2ugR2Ff/nyQACwplDCBBKXVkxCOJkMB5AC53Zb4zSmppAXhC\nawF445NrXec6uits8b3xnTlvq1b+9e6ux1T7jGPNajPMX9dWW+fq2i2kmOoTGENlLF3Dsm9xaKr4\nW6z4+xPWEkoLIBvYpJTahTkGYABerXXHiEYWJv4EYCsPGgPwlpkX+mpjACEmAIzan//rzcisTAA9\ngTJI/P1p/3p75/VwPlAOfAmUQPzbb2IUFuL89n/V9uc+qnO1ZY1iGGYXVWfM4h5/hoS9L0PVYYC8\neBILS8NzzHCSuBomlLgSy/FeaBDneZu0V7bXvI3NwN2uPUZJKe6OnZoutmiIybgMSLoa8/Hs4RVK\nAjgv7EdtQjbDht2w47aXUVBaWZ2z/IQ+xP9rGWXnXxi0vatnLwBKrhhEwhuvmss6HYVj/Tpzg41A\nByhv06vO47rSO+HYux46AZ0g5ddxwRtc4/vXCfwH4r5cRtyXy2reWVwY+v99PA9lYGuxF94DLqoh\nLp+UsB0xvCSuhgkprsFgZzd23q99mwO+f38NQ1A+h/Q5a2q2XDhySth3a3hDmKyklBoMdMOsC3S5\n1vrFej4Sdrm5+xs9zNb+2dYUb+7GuZu/4NXZH+GJa4E7uRuOVT/i6t4D7IE1grzm8qOPwbbtD7wp\nqRAfh7F7N4bHjTfJjmOvpqzr+XUe09ibj33nTziKfsWTnQ1xwXdY2LetJiV3KqVJ51HYcqq/iByA\n6/gTsO3aiSerBV5nXI1dN42V/ZE5L8Fjz8bmzqWw4zhcqX8K2iY9PZF9+4pr+nhUSVwNE2pcRv6e\noL+/IB43SX+fheH7r+/APeNwH/unmreNQGxNLSbjMgzSO59H7t7G3Y2fnZ1a6wfrbQEopR4B2mJ2\nZswArldK9dBa31nP52zAHKAHUAoM11qvC1h/NTAGcAE/A6O01hG5ly7OHkexvRyX20F5iz7+5a7j\nTqi+sWHg6nE8AJ4Olb1c3rR0/+uyw+vv/fJmZOLK6IOLPjVvkH0uKZ89it32B251NG51dNBqT+vD\n6j1GgwUke5vbHGwuOWIwnsR2VWJLpSw+9gY1Ja4GCjWuVoCqfXXiHQsw8vPNNzqFsr4X1L5xuGNr\narEalzMVCH9coXQBnQucAKzQWhcopc4BVgF1JgDgUiBBa32qUuoU4HHgEgClVCJmRdHuWusipdQr\nwEXAu438HnVy2pzmbaCh3eDTNAw7pHfDnr8KW8kf5vuD4IlrHfTg+iC+C7+96LfgzzjS8CQcsuP7\noqkE/F05fvwB284wzEtxHcC2+0D92zW1GIzLa9igZWQ6pkJJABW/yit+PsYHLKtLb+ADAK31N0qp\nwE7zUuA0rXXFrCkHUEKExNnjwFbOf//rYMaMOO69t4a6ztGQ0R1jz/e0+OLg78QpPuIaDnSbU+O6\npPUPkrzxsWrL3clda08aQvi4unYjbvkXACQsfpOExW+GZb+x+ry8mIxryhQYNTbsuw0lAbwOvAZk\n+aqC/hX4ZwifSwP2Bbx3K6UcWmuXr6tnJ4BS6lbMcZeP6tpZZmYSDkfjfiXH2ePAbl70H388nsce\ni5EZj847wFMOXtfB7eePf5O4dxmJ2ak1r/+oysW/52zI+wZnp2Fk1/KZ2pZHm8TVMGGJ643XYNYs\naNMGvvmm/u1FeNlscM45EfkbC+WRkDN8TwXbDLQDJmut3wth3wWYD1GsYNNa+690vjGCmUAX4DKt\ndZ2DvPn5ja+z77Q7wV7Zf5YbI5N2srO7k9u55l/tDZF+4FLidn9K3rateJ3pwSu9XrID3hZ0e4bS\nrMGQZU5io4ZzkZ2dGjPnKJDE1TBhi8uRAndPNF8PDk8FmGZ/zsLsYOKqK3GE0gJAa/0h8GEDj7sc\nuBh43TcG8HOV9fMwu4IujdTgbwWzBVBe/4aHKFdKN+J2f4q9cA2ujFOC1tlKtwW9d6dUn4QmhLCm\nkBJAIy0GzlFKfYU5eex63+2kKcD3mM8Z+AL4VCkFMFtrvTgSgZgtgBjp948Al++inrr6Vn9p6gqG\nK/hXgyu5jts9hBCWErEE4PtVP7LK4sA6B032WMnAMQAAtzv41v9DXXnmGXicmTgKNRTqauu9tiTc\niUfiSukG9oY98EYI0XxFsgUQMyruAqqwZ49BdnYslm9sHE9iO3b3OWSe0imEiBGHzMPdD4bT5gSb\nBwxzIkBurtz6KIQQlkgA/ucCt/oFgLw8SQBCCGGJBNAiyTe14xLzFrbduyUBCCGEJRLArHNnAZB+\nmFnPpDTWqr0KIUQUWCIBtEpuRaeMo/A6CgEoLZUWgBBCWCIBACQ7Uyj1mrOJpQUghBAWSgBJjiTK\nvIWAV1oAQgiBlRKAMwkvXnAWSwtACCGwUgJw+B7i7iykrPlWhRBCiJBZJwE4k8wXcYWUlEgXkBBC\nWCYBJDt9LYC4A9ICEEIILJQAAruAZAxACCGslAACuoDkLiAhhLBSApAWgBBCBLFMAggeA5AWgBBC\nWCYBBN8FFN1YhBAiFlgnAcg8ACGECGKdBOBrAdgTD8ggsBBCYKkEYLYAzAQQ5WCEECIGWCYBVAwC\n2xLkLiAhhAALJYB4WzwAtrhSuQtICCGwUAJw2OwA2OwuuQtICCGwVAJwAmB3lksLQAghsFQCcABg\nOFwyBiCEEFgqAZgtAJujnNJS8HqjHJAQQkSZhRKAOQZg2F14PAYuV5QDEkKIKLNMAnD6WgCGoxyQ\nB8MLIYRlEoDd8I0B2Myf/j/+aOfAgWhGJIQQ0WWZBFDRAsButgD+8pckLrggKYoRCSFEdFkmAVTc\nBYS9svN/7Vp7lKIRQojos0wCMAwDu2EHW3m0QxFCiJhgmQQAvlaATW7/EUIIsFwCcEoCEEIIH4sl\nAAdeQ7qAhBACwBGpHSulbMAcoAdQCgzXWq+rsk0S8BFwg9Z6baRiqeCULiAhhPCLZAvgUiBBa30q\ncB/weOBKpVQvYBnQKYIxBLEbDjzSAhBCCCCyCaA38AGA1voboFeV9fHAQCDiv/wrOG1OvEZwC2DW\nrDipCySEsKSIdQEBacC+gPdupZRDa+0C0FovB1BKhbSzzMwkHI7G37efnZ1KnNNJoS24BsTDD8dz\n9tnx9O3b6F0flOzs1OgcuB4SV8NIXA0Xq7FZKa5IJoACIDBiW8XFvzHy84saHUh2diq5ufuxee24\nvdW7gLZtKyI3193o/R9sXLFG4moYiavhYjW25hhXXYkjkl1Ay4ELAJRSpwA/R/BYIXHYHLipnoPs\nMiFYCGFBkWwBLAbOUUp9BRjA9UqpwUCK1vrZCB63Vg6bE08NCcBmqZthhRDCFLEEoLX2ACOrLK42\n4Ku17hOpGKpyGDV3AUkLQAhhRZb67SstACGEqGSpS5/D5sDlLQeC7/t0N/34rxBCRJ2lEoD/mQCG\nJ2i5JAAhhBVZKgHYfc8FrngoTIVymRwshLAgSyUAfwugSj0gl8uIQjRCCBFdlkoA9oqnglV5KIxL\n6sMJISzIUgmg9hZAFIIRQogos1QCcBg1jwFIAhBCWJG1EoCMAQghhJ/FEkDNYwByF5AQwoosmgCC\nWwAyD0AIYUXWTAAyD0AIISyWAIyaWwAyBiCEsCJrJQDfIPD0R/aTmVlZD0juAhJCWJHFEoDZAjju\nhFLOOKPyqi8JQAhhRZZKAE5fAnB5XHgC6sHJILAQwooslQDstSQAGQQWQliRpRJARSmIck95UAKQ\nQWAhhBVZKgFUtADcHhdeb+VFX8YAhBBWZKkE4B8D8LqrtACiFJAQQkSRpRJAxTyAl1cvkAQghLA8\nSyWA1smHA/DR5g854/yt/uUyBiCEsCJLJYCLOg7ghFY9ATj7ot0sXlwEyF1AQghrslQCMAyDkw4/\nFYBiVyFHHWX2A8k8ACGEFVkqAQAkOZMAKCwvxO57Poy0AIQQVmS9BOBIBqDIVYjTadYDkkFgIYQV\nWS4BJPtaAEXlRf4WgAwCCyGsyIIJIAWAIlcRTt8TIqUFIISwIsslgCRHxRjAARy+xwNIAhBCWJH1\nEoB/ENjsAjIMryQAIYQlWS8BBAwCAzgcUF4uYwBCCOuxXgIIGAQGcDplHoAQwposlwD8g8C+BGC3\nyzwAIYQ1WS4BBA4CAzidXmkBCCEsyXoJoKILyBXYApAxACGE9VgwAfgGgcvNQWCnU24DFUJYkyNS\nO1ZK2YA5QA+gFBiutV4XsP5iYBLgAv6htX4uUrEEirPFYTfs/haAwyEJQAhhTRFLAMClQILW+lSl\n1CnA48AlAEopJzALOBEoBJYrpd7VWu+MYDyAWRE02ZnCvtK9bNn/O970JIoOwLe6ONKHriZjVzJ7\n8wub/Lj1kbgaRuJquFiNLRbjsttt9G+hIrLvSCaA3sAHAFrrb5RSvQLWdQXWaa3zAZRSXwJ/Bt6I\nYDx+Kc4Ufs3X9HzpWLjMXHbRJ01xZCGEaLjeH0zgrdH3hH2/kUwAacC+gPdupZRDa+2qYd1+IL2u\nnWVnpx7USG12dqr/9R93ba1jSyGEsIZIDgIXAKkB722+i39N61KBvRGMRQghRBWRTADLgQsAfGMA\nPwesWwN0VkplKaXiMLt/vo5gLEIIIaowvF5vRHYccBfQnwADuB44AUjRWj8bcBeQDfMuoKcjEogQ\nQogaRSwBCCGEiG2WmwgmhBDCJAlACCEsKpK3gUZVfTORoxTTCsw7oAA2AtOBBYAX+AW4RWvtacJ4\nTgZmaK37KKWOqikWpdSNwAjMGdvTtNbvNXFcxwPvAb/5Vs/VWr/WlHH5Ji7+A8gB4oFpwGqifL5q\niWsLUT5fvtjswHOAwjxHI4ESon/OaorLSWycs1bAD8A5vmMuIMLnqjm3APwzkYH7MGciR41SKgEw\ntNZ9fP+7HvgbMEFrfQbmQPklTRjPPcDzQIJvUbVYlFKHAbcBpwPnAg8rpeKbOK6ewN8CzttrUYjr\nGmC379ycBzxFbJyvmuKKhfMFcDGA1vp0YALmj51YOGc1xRX1c+ZL5vOAipIETXKumm0LgLpnIkdD\nDyBJKbUU87yPw/zD+9y3/j9Af2BxE8WzHvgL8JLvfU2xuIHlWutSoFQptQ7zrq7vmjgupZS6BPMX\n2hjgpCaO6w3gX77XBuavr1g4X7XFFe3zhdb6baVUxa/T9pjzfM4myueslrhi4Zw9BjwD3O973yR/\nX825BVDjTORoBQMUYf6ffC5ms3MRZoug4jasemdDh5PW+k0g8FE4NcXS4BnbEYjrW+BurfWfgQ3A\n5KaOS2t9QGu9XymVinnBnUAMnK9a4or6+QqIz6WUWgj8ndr/3qPxN1Y1rqieM6XUdUCu1vrDgMVN\ncq6acwKoayZyNPwKvKy19mqtfwV2A60D1kd7NnTg2ENFLLEwY3ux1vqHitfA8dGISyl1JPAZ8JLW\n+p/EyPmqIa6YOF8VtNZDgS6Y/e6JNcQQldiqxLU0yudsGHCOUuq/wHHAi0CrGo4d9piacwKoayZy\nNAzDNw6hlDoCM5svVUr18a0/H/giOqEBsLKGWL4FzlBKJSil0jGL+P3SxHF9qJQ6yfe6H+YgWZPG\npZRqDSwF7tVa/8O3OOrnq5a4on6+fLH9VSlV0Z1RhJkwv4+Bc1ZTXG9F85xprf+stT5Ta90H+BG4\nFvhPU5yr5jwGsBgzq35F5UzkaJoPLPBVPvViJoQ84DlfOYw1VPbnRsOdVWPRWruVUk9i/vHZgPFa\n65Imjutm4O9KqXJgB3CT1rqgieMaB2QCE5VSE33LbgeejPL5qimuscCsKJ8vgLeAF5RSyzDvshmD\neZ6i/TdWU1xbiP7fWFVN8t+jzAQWQgiLas5dQEIIIeogCUAIISxKEoAQQliUJAAhhLAoSQBCCGFR\nkgCECIFS6iSl1Azf6wFKqanh3KcQ0dCc5wEIEU7H4Ju5rbV+F3g3nPsUIhpkHoBoNnwzJ8dhzvDs\nijn7e7DWuqyW7c8DpmJOCNoI3Ki13q2UegyzJK8beAeYDawCUjBnc/8B9NFaX6eU2gS8BlyEWYxt\nHOYkns7AnVrr15VSx2LWnUnBnOL/OOZ0/8B9Pgw8gTkT1YtZ2mGG7zvNBOyYsz5f9L33AvnA1Vrr\nvIM7c8KqpAtINDenAaMxE0A7zOJ71SilsoFHgHO11scDHwIzlFLtgfO11j18++qMWcd+EvCu1np6\nDbvbprXuBqzALD3eH7NUc0XJgeGYtdtPBM4Cpmut91bZ50jgSMzqjicBlymlLvR9vgvQ11e/ZgIw\nUmvdC1iC+ZxtIRpFEoBobn7RWm/1PVhnDZBVy3YnYyaIz5RSP2Imjc6Yv+6LlVLLgTswa7LXN93+\nP75/NwOf+4oObsYs0wBmiyDBV4NmOuav/qr6Agu01m6tdRFmlcp+vnVaa11RBfJdYLFS6ilgjdZ6\naT2xCVErSQCiuQm8WHsx60DVxA58qbU+Tmt9HHAicLnv4n0yMBFoAXytlOpSzzEDu5hqqjj7OjAQ\n8yli42rZR9X/Fg0qx+gqHhKC1noW0AdYB8xUSo2vJzYhaiUJQFjV/4BTAy7uE4FHlfkIys+BZVrr\nuzAv2grzwt7YmybOASZprd8BzgT/owkD9/kpMFQpZVdKJQFDMMs8B1FK/Q9I1Vo/AcxCuoDEQZAE\nICxJa70DsyLr60qpnzEvpHdqrVcCXwO/KPMZzpswu3i+BU5RSj3SiMNNAb707e9c3z47VNnnPGAr\n8BOwEnNsoKanw43DrCr7A3AT5sNLhGgUuQtICCEsSuYBiGZLKZWI+Wu+JpN89/MLYVnSAhBCCIuS\nMQAhhLAoSQBCCGFRkgCEEMKiJAEIIYRFSQIQQgiLkgQghBAW9f/u4F/uyO3AtQAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110bf23c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "n_estimators = 400\n",
    "# A learning rate of 1. may not be optimal for both SAMME and SAMME.R\n",
    "learning_rate = 1.\n",
    "\n",
    "dt_stump = DecisionTreeClassifier(max_depth=1, min_samples_leaf=1)\n",
    "dt_stump.fit(x_train, y_train)\n",
    "dt_stump_err = 1.0 - dt_stump.score(X_test, Y_test)\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=9, min_samples_leaf=1)\n",
    "dt.fit(x_train, y_train)\n",
    "dt_err = 1.0 - dt.score(X_test, Y_test)\n",
    "\n",
    "\n",
    "ada_discrete = AdaBoostClassifier(\n",
    "    base_estimator=dt_stump,\n",
    "    learning_rate=learning_rate,\n",
    "    n_estimators=n_estimators,\n",
    "    algorithm=\"SAMME\")\n",
    "ada_discrete.fit(x_train, y_train)\n",
    "\n",
    "ada_real = AdaBoostClassifier(\n",
    "    base_estimator=dt_stump,\n",
    "    learning_rate=learning_rate,\n",
    "    n_estimators=n_estimators,\n",
    "    algorithm=\"SAMME.R\")\n",
    "ada_real.fit(x_train, y_train)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ada_discrete_err = np.zeros((n_estimators,))\n",
    "for i, y_pred in enumerate(ada_discrete.staged_predict(X_test)):\n",
    "    ada_discrete_err[i] = zero_one_loss(y_pred, Y_test)\n",
    "\n",
    "ada_discrete_err_train = np.zeros((n_estimators,))\n",
    "for i, y_pred in enumerate(ada_discrete.staged_predict(x_validation)):\n",
    "    ada_discrete_err_train[i] = zero_one_loss(y_pred, y_validation)\n",
    "\n",
    "ada_real_err = np.zeros((n_estimators,))\n",
    "for i, y_pred in enumerate(ada_real.staged_predict(X_test)):\n",
    "    ada_real_err[i] = zero_one_loss(y_pred, Y_test)\n",
    "\n",
    "ada_real_err_train = np.zeros((n_estimators,))\n",
    "for i, y_pred in enumerate(ada_real.staged_predict(x_validation)):\n",
    "    ada_real_err_train[i] = zero_one_loss(y_pred, y_validation)\n",
    "\n",
    "ax.plot(np.arange(n_estimators) + 1, ada_discrete_err,\n",
    "        label='Discrete AdaBoost Test Error',\n",
    "        color='red')\n",
    "ax.plot(np.arange(n_estimators) + 1, ada_discrete_err_train,\n",
    "        label='Discrete AdaBoost Train Error',\n",
    "        color='blue')\n",
    "ax.plot(np.arange(n_estimators) + 1, ada_real_err,\n",
    "        label='Real AdaBoost Test Error',\n",
    "        color='orange')\n",
    "ax.plot(np.arange(n_estimators) + 1, ada_real_err_train,\n",
    "        label='Real AdaBoost Train Error',\n",
    "        color='green')\n",
    "\n",
    "ax.set_ylim((0.0, 0.5))\n",
    "ax.set_xlabel('n_estimators')\n",
    "ax.set_ylabel('error rate')\n",
    "\n",
    "leg = ax.legend(loc='upper right', fancybox=True)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
